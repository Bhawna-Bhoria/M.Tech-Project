{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "359c36e6-9058-4580-8c08-afdcc6e7166d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ENCODER DECODER MODEL FOR WORD LEVEL EMBEDDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41168d79-e491-4903-99aa-2816ceb9b9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOADING THE REQUIRED LIBRARIES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm import tqdm \n",
    "import tensorflow as tf\n",
    "from  tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from  sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a818d2a-bd68-4303-abc2-fb50cacae425",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# The GPU id to use, \"0\" to  \"7\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2,3,4,6,7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff994d53-cd7b-41d8-a184-076a1bddec14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  5\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c65967b5-534d-45ed-9333-bed5684fa811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enc_input</th>\n",
       "      <th>dec_input</th>\n",
       "      <th>dec_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>परन्तु वे दोनों उन बातों को ज़्यादा समय तक अप ...</td>\n",
       "      <td>परन्तु वे दोनों उन बातों को ज़्यादा समय तक अपन...</td>\n",
       "      <td>परन्तु वे दोनों उन बातों को ज़्यादा समय तक अपन...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>देश में हिन्दी को विस्थापित कर का षड़यंत्र चल ...</td>\n",
       "      <td>देश में हिन्दी को विस्थापित करने का षड़यंत्र च...</td>\n",
       "      <td>देश में हिन्दी को विस्थापित करने का षड़यंत्र च...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>तीन साल पहले कातिलाना हमले के प्रकरण में एफआर ...</td>\n",
       "      <td>तीन साल पहले कातिलाना हमले के प्रकरण में एफआर ...</td>\n",
       "      <td>तीन साल पहले कातिलाना हमले के प्रकरण में एफआर ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>रामायण रिविजिटेड अ टेल ऑफ लव एंड एडवेंचर नाम स...</td>\n",
       "      <td>रामायण रिविजिटेड अ टेल ऑफ लव एंड एडवेंचर नाम स...</td>\n",
       "      <td>रामायण रिविजिटेड अ टेल ऑफ लव एंड एडवेंचर नाम स...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>तब तक के लिए हमें विराम ले की अनुमति दीजिए ।</td>\n",
       "      <td>तब तक के लिए हमें विराम लेने की अनुमति दीजिए ।</td>\n",
       "      <td>तब तक के लिए हमें विराम लेने की अनुमति दीजिए ।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>देव स्थेन तक सड़क बनाने की परियोजना चल रही है ।</td>\n",
       "      <td>देव स्थान तक सड़क बनाने की परियोजना चल रही है ।</td>\n",
       "      <td>देव स्थान तक सड़क बनाने की परियोजना चल रही है ।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>वर्ड वाचर व प्रसिद्ध चित्रकार अनूप साह आरएनएस ...</td>\n",
       "      <td>वर्ड वाचर व प्रसिद्ध चित्रकार अनूप साह ने आरएन...</td>\n",
       "      <td>वर्ड वाचर व प्रसिद्ध चित्रकार अनूप साह ने आरएन...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>दो दिन पहले ज्ञानजी पोस्ट ठेली जिसमें</td>\n",
       "      <td>दो दिन पहले ज्ञानजी ने पोस्ट ठेली जिसमें</td>\n",
       "      <td>दो दिन पहले ज्ञानजी ने पोस्ट ठेली जिसमें</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>दुर्घटना की स्थिति में बीमा कम्पनी द्वारा दी ज...</td>\n",
       "      <td>दुर्घटना की स्थिति में बीमा कम्पनी द्वारा दी ज...</td>\n",
       "      <td>दुर्घटना की स्थिति में बीमा कम्पनी द्वारा दी ज...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>देर से जाऊंगा तो दुकां बंद हो जाएंगी ।</td>\n",
       "      <td>देर से जाऊंगा तो दुकानें बंद हो जाएंगी ।</td>\n",
       "      <td>देर से जाऊंगा तो दुकानें बंद हो जाएंगी ।</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           enc_input  \\\n",
       "0  परन्तु वे दोनों उन बातों को ज़्यादा समय तक अप ...   \n",
       "1  देश में हिन्दी को विस्थापित कर का षड़यंत्र चल ...   \n",
       "2  तीन साल पहले कातिलाना हमले के प्रकरण में एफआर ...   \n",
       "3  रामायण रिविजिटेड अ टेल ऑफ लव एंड एडवेंचर नाम स...   \n",
       "4       तब तक के लिए हमें विराम ले की अनुमति दीजिए ।   \n",
       "5    देव स्थेन तक सड़क बनाने की परियोजना चल रही है ।   \n",
       "6  वर्ड वाचर व प्रसिद्ध चित्रकार अनूप साह आरएनएस ...   \n",
       "7              दो दिन पहले ज्ञानजी पोस्ट ठेली जिसमें   \n",
       "8  दुर्घटना की स्थिति में बीमा कम्पनी द्वारा दी ज...   \n",
       "9             देर से जाऊंगा तो दुकां बंद हो जाएंगी ।   \n",
       "\n",
       "                                           dec_input  \\\n",
       "0  परन्तु वे दोनों उन बातों को ज़्यादा समय तक अपन...   \n",
       "1  देश में हिन्दी को विस्थापित करने का षड़यंत्र च...   \n",
       "2  तीन साल पहले कातिलाना हमले के प्रकरण में एफआर ...   \n",
       "3  रामायण रिविजिटेड अ टेल ऑफ लव एंड एडवेंचर नाम स...   \n",
       "4    तब तक के लिए हमें विराम लेने की अनुमति दीजिए ।    \n",
       "5   देव स्थान तक सड़क बनाने की परियोजना चल रही है ।    \n",
       "6  वर्ड वाचर व प्रसिद्ध चित्रकार अनूप साह ने आरएन...   \n",
       "7           दो दिन पहले ज्ञानजी ने पोस्ट ठेली जिसमें   \n",
       "8  दुर्घटना की स्थिति में बीमा कम्पनी द्वारा दी ज...   \n",
       "9          देर से जाऊंगा तो दुकानें बंद हो जाएंगी ।    \n",
       "\n",
       "                                          dec_output  \n",
       "0  परन्तु वे दोनों उन बातों को ज़्यादा समय तक अपन...  \n",
       "1  देश में हिन्दी को विस्थापित करने का षड़यंत्र च...  \n",
       "2  तीन साल पहले कातिलाना हमले के प्रकरण में एफआर ...  \n",
       "3  रामायण रिविजिटेड अ टेल ऑफ लव एंड एडवेंचर नाम स...  \n",
       "4    तब तक के लिए हमें विराम लेने की अनुमति दीजिए ।   \n",
       "5   देव स्थान तक सड़क बनाने की परियोजना चल रही है ।   \n",
       "6  वर्ड वाचर व प्रसिद्ध चित्रकार अनूप साह ने आरएन...  \n",
       "7           दो दिन पहले ज्ञानजी ने पोस्ट ठेली जिसमें  \n",
       "8  दुर्घटना की स्थिति में बीमा कम्पनी द्वारा दी ज...  \n",
       "9          देर से जाऊंगा तो दुकानें बंद हो जाएंगी ।   "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## LOADING THE PROCESSED DATASET  \n",
    "\n",
    "df= pd.read_csv('DATA/etoori_train.csv')\n",
    "df[\"dec_output\"] = df.dec_input\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e6f8cc-401b-47f1-a951-b7aba2e752e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71e080e6-0bf4-4066-84c4-0b7a4ca95880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enc_input</th>\n",
       "      <th>dec_input</th>\n",
       "      <th>dec_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>परन्तु वे दोनों उन बातों को ज़्यादा समय तक अप ...</td>\n",
       "      <td>&lt;start&gt; परन्तु वे दोनों उन बातों को ज़्यादा सम...</td>\n",
       "      <td>परन्तु वे दोनों उन बातों को ज़्यादा समय तक अपन...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>देश में हिन्दी को विस्थापित कर का षड़यंत्र चल ...</td>\n",
       "      <td>&lt;start&gt; देश में हिन्दी को विस्थापित करने का षड...</td>\n",
       "      <td>देश में हिन्दी को विस्थापित करने का षड़यंत्र च...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>तीन साल पहले कातिलाना हमले के प्रकरण में एफआर ...</td>\n",
       "      <td>&lt;start&gt; तीन साल पहले कातिलाना हमले के प्रकरण म...</td>\n",
       "      <td>तीन साल पहले कातिलाना हमले के प्रकरण में एफआर ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>रामायण रिविजिटेड अ टेल ऑफ लव एंड एडवेंचर नाम स...</td>\n",
       "      <td>&lt;start&gt; रामायण रिविजिटेड अ टेल ऑफ लव एंड एडवें...</td>\n",
       "      <td>रामायण रिविजिटेड अ टेल ऑफ लव एंड एडवेंचर नाम स...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>तब तक के लिए हमें विराम ले की अनुमति दीजिए ।</td>\n",
       "      <td>&lt;start&gt; तब तक के लिए हमें विराम लेने की अनुमति...</td>\n",
       "      <td>तब तक के लिए हमें विराम लेने की अनुमति दीजिए ।...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139995</th>\n",
       "      <td>लेकिन फिर भी फिल्म को लोगों जित निगेटिव कमेंट्...</td>\n",
       "      <td>&lt;start&gt; लेकिन फिर भी फिल्म को लोगों ने जितने न...</td>\n",
       "      <td>लेकिन फिर भी फिल्म को लोगों ने जितने निगेटिव क...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139996</th>\n",
       "      <td>बेटी से छेड़छाड़ के साथ वह कई बार दुराचार की क...</td>\n",
       "      <td>&lt;start&gt; बेटी से छेड़छाड़ के साथ उसने कई बार दु...</td>\n",
       "      <td>बेटी से छेड़छाड़ के साथ उसने कई बार दुराचार की...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139997</th>\n",
       "      <td>आज यह कलाकार बालीवुड की चकाचौंध से दूर अपने गा...</td>\n",
       "      <td>&lt;start&gt; आज यह कलाकार बालीवुड की चकाचौंध से दूर...</td>\n",
       "      <td>आज यह कलाकार बालीवुड की चकाचौंध से दूर अपने गा...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139998</th>\n",
       "      <td>यदि ये इस वर्ष अपनी प्रतियोगी परीक्षाओं में सफ...</td>\n",
       "      <td>&lt;start&gt; यदि ये इस वर्ष अपनी प्रतियोगी परीक्षाओ...</td>\n",
       "      <td>यदि ये इस वर्ष अपनी प्रतियोगी परीक्षाओं में सफ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139999</th>\n",
       "      <td>होश हैं तो जोश हैं</td>\n",
       "      <td>&lt;start&gt; होश है तो जोश है</td>\n",
       "      <td>होश है तो जोश है &lt;end&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                enc_input  \\\n",
       "0       परन्तु वे दोनों उन बातों को ज़्यादा समय तक अप ...   \n",
       "1       देश में हिन्दी को विस्थापित कर का षड़यंत्र चल ...   \n",
       "2       तीन साल पहले कातिलाना हमले के प्रकरण में एफआर ...   \n",
       "3       रामायण रिविजिटेड अ टेल ऑफ लव एंड एडवेंचर नाम स...   \n",
       "4            तब तक के लिए हमें विराम ले की अनुमति दीजिए ।   \n",
       "...                                                   ...   \n",
       "139995  लेकिन फिर भी फिल्म को लोगों जित निगेटिव कमेंट्...   \n",
       "139996  बेटी से छेड़छाड़ के साथ वह कई बार दुराचार की क...   \n",
       "139997  आज यह कलाकार बालीवुड की चकाचौंध से दूर अपने गा...   \n",
       "139998  यदि ये इस वर्ष अपनी प्रतियोगी परीक्षाओं में सफ...   \n",
       "139999                                 होश हैं तो जोश हैं   \n",
       "\n",
       "                                                dec_input  \\\n",
       "0       <start> परन्तु वे दोनों उन बातों को ज़्यादा सम...   \n",
       "1       <start> देश में हिन्दी को विस्थापित करने का षड...   \n",
       "2       <start> तीन साल पहले कातिलाना हमले के प्रकरण म...   \n",
       "3       <start> रामायण रिविजिटेड अ टेल ऑफ लव एंड एडवें...   \n",
       "4       <start> तब तक के लिए हमें विराम लेने की अनुमति...   \n",
       "...                                                   ...   \n",
       "139995  <start> लेकिन फिर भी फिल्म को लोगों ने जितने न...   \n",
       "139996  <start> बेटी से छेड़छाड़ के साथ उसने कई बार दु...   \n",
       "139997  <start> आज यह कलाकार बालीवुड की चकाचौंध से दूर...   \n",
       "139998  <start> यदि ये इस वर्ष अपनी प्रतियोगी परीक्षाओ...   \n",
       "139999                           <start> होश है तो जोश है   \n",
       "\n",
       "                                               dec_output  \n",
       "0       परन्तु वे दोनों उन बातों को ज़्यादा समय तक अपन...  \n",
       "1       देश में हिन्दी को विस्थापित करने का षड़यंत्र च...  \n",
       "2       तीन साल पहले कातिलाना हमले के प्रकरण में एफआर ...  \n",
       "3       रामायण रिविजिटेड अ टेल ऑफ लव एंड एडवेंचर नाम स...  \n",
       "4       तब तक के लिए हमें विराम लेने की अनुमति दीजिए ।...  \n",
       "...                                                   ...  \n",
       "139995  लेकिन फिर भी फिल्म को लोगों ने जितने निगेटिव क...  \n",
       "139996  बेटी से छेड़छाड़ के साथ उसने कई बार दुराचार की...  \n",
       "139997  आज यह कलाकार बालीवुड की चकाचौंध से दूर अपने गा...  \n",
       "139998  यदि ये इस वर्ष अपनी प्रतियोगी परीक्षाओं में सफ...  \n",
       "139999                             होश है तो जोश है <end>  \n",
       "\n",
       "[140000 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding start and end token\n",
    "## THE INPUTS TO THE DECODER REQUIRES SPECIAL TOKENS FOR THE START AND THE END SO WE ARE GOING TO USE \n",
    "## <start> AS BEGINING TOKEN\n",
    "## <end>  AS END TOKEN\n",
    "\n",
    "df[\"dec_input\"]= \"<start> \" + df[\"dec_input\"]\n",
    "df[\"dec_output\"] =  df[\"dec_output\"] + \" <end>\" \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dbbdfd9-97fb-4f03-bc7e-daab9bdc53c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140000, 3)\n"
     ]
    }
   ],
   "source": [
    "# Splitting And Sampling around 100k datapoints\n",
    "#THE TOTAL DATASET HAS 500K DATAPOINTS WHICH WILL TAKE MUCH HIGHER TRAINING TIME. THEREFORE I AM SAMPLING ONE-FIFTH OF THE TOTAL DATASET\n",
    "\n",
    "#df_sampled = pd.concat((df[df.enc_input].sample(frac= 0.2,random_state=1)))\n",
    "#df_sampled = df.sample(frac = 0.1)\n",
    "print(df.shape)\n",
    "#print(df_sampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d8bc948-cc71-4302-b457-c15aaef88fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ONCE THE DATA IS SAMPLED WE ARE SPLITTIND THE DATA IN TO TRAIN AND TEST\n",
    "\n",
    "df_train ,df_val = train_test_split(df,test_size=0.2,random_state = 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a118dea5-c7bb-467b-9384-e18296642ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## IN THE COLUMN WHICH HAS DECODER INPUTS ADDING \"<end>\" TOKEN TO BE LEARNED BY THE TOKENIZER\n",
    "\n",
    "df_train[\"dec_input\"].iloc[0]  = df_train.iloc[0][\"dec_input\"] + \" <end>\"\n",
    "df_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a04ea613-5671-42ee-9ab8-805a563390b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enc_input</th>\n",
       "      <th>dec_input</th>\n",
       "      <th>dec_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90522</th>\n",
       "      <td>महुआ का तेल जलाने के काम में लाया जाता हैं ।</td>\n",
       "      <td>&lt;start&gt; महुआ का तेल जलाने के काम में लाया जाता...</td>\n",
       "      <td>महुआ का तेल जलाने के काम में लाया जाता है ।  &lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133504</th>\n",
       "      <td>आजकल ट्रेन में एक से ज़्यादा टीटी भी होते हैंं...</td>\n",
       "      <td>&lt;start&gt; आजकल ट्रेन में एक से ज़्यादा टीटी भी ह...</td>\n",
       "      <td>आजकल ट्रेन में एक से ज़्यादा टीटी भी होते हैं ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2373</th>\n",
       "      <td>शाम के वक्त बारी बारी से घर के सभी सदस्य रश्मि...</td>\n",
       "      <td>&lt;start&gt; शाम के वक्त बारी बारी से घर के सभी सदस...</td>\n",
       "      <td>शाम के वक्त बारी बारी से घर के सभी सदस्य रश्मि...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136466</th>\n",
       "      <td>उनमें शिवकुमार दीपक प्रमुख है ।</td>\n",
       "      <td>&lt;start&gt; उनमें शिवकुमार दीपक प्रमुख हैं ।</td>\n",
       "      <td>उनमें शिवकुमार दीपक प्रमुख हैं ।  &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5198</th>\n",
       "      <td>हमारे देश में संविधान द्वारा अब स्त्रियों को अ...</td>\n",
       "      <td>&lt;start&gt; हमारे देश में संविधान द्वारा अब स्त्रि...</td>\n",
       "      <td>हमारे देश में संविधान द्वारा अब स्त्रियों को अ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111735</th>\n",
       "      <td>सरकार किसी पुल या सड़क का लोकार्पण करती हैं तो...</td>\n",
       "      <td>&lt;start&gt; सरकार किसी पुल या सड़क का लोकार्पण करत...</td>\n",
       "      <td>सरकार किसी पुल या सड़क का लोकार्पण करती है तो ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19247</th>\n",
       "      <td>उन्होंने हमें सिखाया कि कैसे संघर्ष किया जाता ...</td>\n",
       "      <td>&lt;start&gt; उन्होंने हमें सिखाया कि कैसे संघर्ष कि...</td>\n",
       "      <td>उन्होंने हमें सिखाया कि कैसे संघर्ष किया जाता ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57036</th>\n",
       "      <td>लेकिन यह इतिहास का अन्त नहीं हैं ।</td>\n",
       "      <td>&lt;start&gt; लेकिन यह इतिहास का अन्त नहीं है ।</td>\n",
       "      <td>लेकिन यह इतिहास का अन्त नहीं है ।  &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73689</th>\n",
       "      <td>रतन टाटा मल्टीब्रांड रिटेल में एफडीआई का स्वाग...</td>\n",
       "      <td>&lt;start&gt; रतन टाटा ने मल्टीब्रांड रिटेल में एफडी...</td>\n",
       "      <td>रतन टाटा ने मल्टीब्रांड रिटेल में एफडीआई का स्...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134554</th>\n",
       "      <td>पाकिस्तान के शहर कराची में इससे पहले भी कई मंद...</td>\n",
       "      <td>&lt;start&gt; पाकिस्तान के शहर कराची में इससे पहले भ...</td>\n",
       "      <td>पाकिस्तान के शहर कराची में इससे पहले भी कई मंद...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                enc_input  \\\n",
       "90522        महुआ का तेल जलाने के काम में लाया जाता हैं ।   \n",
       "133504  आजकल ट्रेन में एक से ज़्यादा टीटी भी होते हैंं...   \n",
       "2373    शाम के वक्त बारी बारी से घर के सभी सदस्य रश्मि...   \n",
       "136466                    उनमें शिवकुमार दीपक प्रमुख है ।   \n",
       "5198    हमारे देश में संविधान द्वारा अब स्त्रियों को अ...   \n",
       "...                                                   ...   \n",
       "111735  सरकार किसी पुल या सड़क का लोकार्पण करती हैं तो...   \n",
       "19247   उन्होंने हमें सिखाया कि कैसे संघर्ष किया जाता ...   \n",
       "57036                  लेकिन यह इतिहास का अन्त नहीं हैं ।   \n",
       "73689   रतन टाटा मल्टीब्रांड रिटेल में एफडीआई का स्वाग...   \n",
       "134554  पाकिस्तान के शहर कराची में इससे पहले भी कई मंद...   \n",
       "\n",
       "                                                dec_input  \\\n",
       "90522   <start> महुआ का तेल जलाने के काम में लाया जाता...   \n",
       "133504  <start> आजकल ट्रेन में एक से ज़्यादा टीटी भी ह...   \n",
       "2373    <start> शाम के वक्त बारी बारी से घर के सभी सदस...   \n",
       "136466          <start> उनमें शिवकुमार दीपक प्रमुख हैं ।    \n",
       "5198    <start> हमारे देश में संविधान द्वारा अब स्त्रि...   \n",
       "...                                                   ...   \n",
       "111735  <start> सरकार किसी पुल या सड़क का लोकार्पण करत...   \n",
       "19247   <start> उन्होंने हमें सिखाया कि कैसे संघर्ष कि...   \n",
       "57036          <start> लेकिन यह इतिहास का अन्त नहीं है ।    \n",
       "73689   <start> रतन टाटा ने मल्टीब्रांड रिटेल में एफडी...   \n",
       "134554  <start> पाकिस्तान के शहर कराची में इससे पहले भ...   \n",
       "\n",
       "                                               dec_output  \n",
       "90522   महुआ का तेल जलाने के काम में लाया जाता है ।  <...  \n",
       "133504  आजकल ट्रेन में एक से ज़्यादा टीटी भी होते हैं ...  \n",
       "2373    शाम के वक्त बारी बारी से घर के सभी सदस्य रश्मि...  \n",
       "136466            उनमें शिवकुमार दीपक प्रमुख हैं ।  <end>  \n",
       "5198    हमारे देश में संविधान द्वारा अब स्त्रियों को अ...  \n",
       "...                                                   ...  \n",
       "111735  सरकार किसी पुल या सड़क का लोकार्पण करती है तो ...  \n",
       "19247   उन्होंने हमें सिखाया कि कैसे संघर्ष किया जाता ...  \n",
       "57036            लेकिन यह इतिहास का अन्त नहीं है ।  <end>  \n",
       "73689   रतन टाटा ने मल्टीब्रांड रिटेल में एफडीआई का स्...  \n",
       "134554  पाकिस्तान के शहर कराची में इससे पहले भी कई मंद...  \n",
       "\n",
       "[28000 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## VALIDATION DATA\n",
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12fb571f-2a53-45f9-9863-d5cca86bf074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enc_input</th>\n",
       "      <th>dec_input</th>\n",
       "      <th>dec_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80240</th>\n",
       "      <td>हमें आने वाले हफ्तों में रोवियो मोबाइल द्वारा ...</td>\n",
       "      <td>&lt;start&gt; हमें आने वाले हफ्तों में रोवियो मोबाइल...</td>\n",
       "      <td>हमें आने वाले हफ्तों में रोवियो मोबाइल द्वारा ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32433</th>\n",
       "      <td>आज कमेन्ट मोदेरेशन सक्षम हैंं ।</td>\n",
       "      <td>&lt;start&gt; आज कमेन्ट मोदेरेशन सक्षम हैं ।</td>\n",
       "      <td>आज कमेन्ट मोदेरेशन सक्षम हैं ।  &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135530</th>\n",
       "      <td>राजस् थेन स्कूल टीचर्स यूनियन के अध्यक्ष आर पी...</td>\n",
       "      <td>&lt;start&gt; राजस् थान स्कूल टीचर्स यूनियन के अध्यक...</td>\n",
       "      <td>राजस् थान स्कूल टीचर्स यूनियन के अध्यक्ष आर पी...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3354</th>\n",
       "      <td>सेक्स का कारक ग्रह भी शुक्र ही हैं तथा शुक्र ए...</td>\n",
       "      <td>&lt;start&gt; सेक्स का कारक ग्रह भी शुक्र ही है तथा ...</td>\n",
       "      <td>सेक्स का कारक ग्रह भी शुक्र ही है तथा शुक्र एक...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125119</th>\n",
       "      <td>वह एक गिलास शर्बत</td>\n",
       "      <td>&lt;start&gt; उसने एक गिलास शर्बत</td>\n",
       "      <td>उसने एक गिलास शर्बत &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123821</th>\n",
       "      <td>बीकॉम ऑनर्स और इको ऑनर्स कोर्स स्टूडेंट की पसं...</td>\n",
       "      <td>&lt;start&gt; बीकॉम ऑनर्स और इको ऑनर्स कोर्स स्टूडें...</td>\n",
       "      <td>बीकॉम ऑनर्स और इको ऑनर्स कोर्स स्टूडेंट की पसं...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40525</th>\n",
       "      <td>मरने वालों में बस में सवार यात्री थी ।</td>\n",
       "      <td>&lt;start&gt; मरने वालों में बस में सवार यात्री थे ।</td>\n",
       "      <td>मरने वालों में बस में सवार यात्री थे ।  &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72286</th>\n",
       "      <td>यान्त्रिक रूप से क्षमा मांगना सम्पर्क बढ़ा का ...</td>\n",
       "      <td>&lt;start&gt; यान्त्रिक रूप से क्षमा मांगना सम्पर्क ...</td>\n",
       "      <td>यान्त्रिक रूप से क्षमा मांगना सम्पर्क बढ़ाने क...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90240</th>\n",
       "      <td>मैंनेने इस शहर में खुद का स् वागत बांहें खोलकर...</td>\n",
       "      <td>&lt;start&gt; मैंने इस शहर में खुद का स् वागत बांहें...</td>\n",
       "      <td>मैंने इस शहर में खुद का स् वागत बांहें खोलकर न...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47760</th>\n",
       "      <td>मैं माउथ फ्रेशनर खाया और उसके घर पहुँचा ।</td>\n",
       "      <td>&lt;start&gt; मैंने माउथ फ्रेशनर खाया और उसके घर पहु...</td>\n",
       "      <td>मैंने माउथ फ्रेशनर खाया और उसके घर पहुँचा ।  &lt;...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                enc_input  \\\n",
       "80240   हमें आने वाले हफ्तों में रोवियो मोबाइल द्वारा ...   \n",
       "32433                     आज कमेन्ट मोदेरेशन सक्षम हैंं ।   \n",
       "135530  राजस् थेन स्कूल टीचर्स यूनियन के अध्यक्ष आर पी...   \n",
       "3354    सेक्स का कारक ग्रह भी शुक्र ही हैं तथा शुक्र ए...   \n",
       "125119                                  वह एक गिलास शर्बत   \n",
       "...                                                   ...   \n",
       "123821  बीकॉम ऑनर्स और इको ऑनर्स कोर्स स्टूडेंट की पसं...   \n",
       "40525              मरने वालों में बस में सवार यात्री थी ।   \n",
       "72286   यान्त्रिक रूप से क्षमा मांगना सम्पर्क बढ़ा का ...   \n",
       "90240   मैंनेने इस शहर में खुद का स् वागत बांहें खोलकर...   \n",
       "47760           मैं माउथ फ्रेशनर खाया और उसके घर पहुँचा ।   \n",
       "\n",
       "                                                dec_input  \\\n",
       "80240   <start> हमें आने वाले हफ्तों में रोवियो मोबाइल...   \n",
       "32433             <start> आज कमेन्ट मोदेरेशन सक्षम हैं ।    \n",
       "135530  <start> राजस् थान स्कूल टीचर्स यूनियन के अध्यक...   \n",
       "3354    <start> सेक्स का कारक ग्रह भी शुक्र ही है तथा ...   \n",
       "125119                        <start> उसने एक गिलास शर्बत   \n",
       "...                                                   ...   \n",
       "123821  <start> बीकॉम ऑनर्स और इको ऑनर्स कोर्स स्टूडें...   \n",
       "40525     <start> मरने वालों में बस में सवार यात्री थे ।    \n",
       "72286   <start> यान्त्रिक रूप से क्षमा मांगना सम्पर्क ...   \n",
       "90240   <start> मैंने इस शहर में खुद का स् वागत बांहें...   \n",
       "47760   <start> मैंने माउथ फ्रेशनर खाया और उसके घर पहु...   \n",
       "\n",
       "                                               dec_output  \n",
       "80240   हमें आने वाले हफ्तों में रोवियो मोबाइल द्वारा ...  \n",
       "32433               आज कमेन्ट मोदेरेशन सक्षम हैं ।  <end>  \n",
       "135530  राजस् थान स्कूल टीचर्स यूनियन के अध्यक्ष आर पी...  \n",
       "3354    सेक्स का कारक ग्रह भी शुक्र ही है तथा शुक्र एक...  \n",
       "125119                          उसने एक गिलास शर्बत <end>  \n",
       "...                                                   ...  \n",
       "123821  बीकॉम ऑनर्स और इको ऑनर्स कोर्स स्टूडेंट की पसं...  \n",
       "40525       मरने वालों में बस में सवार यात्री थे ।  <end>  \n",
       "72286   यान्त्रिक रूप से क्षमा मांगना सम्पर्क बढ़ाने क...  \n",
       "90240   मैंने इस शहर में खुद का स् वागत बांहें खोलकर न...  \n",
       "47760   मैंने माउथ फ्रेशनर खाया और उसके घर पहुँचा ।  <...  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## HERE I AM SAMPLING 1000 POINTS FROM THE DATAFRAME AS TEST DATA WHICH ARE NOT PRESEENT IN THE TRAIN AND VALIDAION DATA\n",
    "np.random.seed(5) \n",
    "df_test = df.loc[np.random.choice(np.array([x for x in df.index.values]),1000,replace= False,)]\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ea083bb-9189-4dde-891b-167fbc2cb76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4febba4d-091d-4309-a280-790f319efd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TOKENIZER FOR ENCODER INPUT\n",
    "tk_inp = Tokenizer()\n",
    "tk_inp.fit_on_texts(df_train.enc_input.apply(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "242b37cb-d354-4ffa-8ff7-8dfb6144e5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOKENIZER FOR DECODER INPUT\n",
    "tk_out = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n' )\n",
    "tk_out.fit_on_texts(df_train.dec_input.apply(str))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5d99c6e8-cf21-4597-86dc-abe6023320ac",
   "metadata": {},
   "source": [
    "Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b595141-a5c3-47b8-a84d-d7d64c708717",
   "metadata": {},
   "outputs": [],
   "source": [
    "## THIS CLASS CONVERTS TEXT DATA TO INTEGER SEQUENCES AND RETURNS THE PADDED SEQUENCES\n",
    "\n",
    "class Dataset :\n",
    "    def __init__(self, data , tk_inp ,tk_out, max_len):\n",
    "        ## SETTING THE REQUIRED ATTRIBUTES\n",
    "        self.encoder_inp = data[\"enc_input\"].apply(str).values\n",
    "        self.decoder_inp = data[\"dec_input\"].apply(str).values\n",
    "        self.decoder_out = data[\"dec_output\"].apply(str).values\n",
    "        self.tk_inp = tk_inp\n",
    "        self.tk_out = tk_out\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __getitem__(self,i):\n",
    "        # INPUT SEQUENCES\n",
    "        self.encoder_seq = self.tk_inp.texts_to_sequences([self.encoder_inp[i]])\n",
    "        # DECODER INPUT SEQUENCES \n",
    "        self.decoder_inp_seq = self.tk_out.texts_to_sequences([self.decoder_inp[i]])\n",
    "        # DECODER INPUT SEQUENCES\n",
    "        self.decoder_out_seq = self.tk_out.texts_to_sequences([self.decoder_out[i]])\n",
    "        \n",
    "        # PADDING THE ENCODER INPUT SEQUENCES\n",
    "        self.encoder_seq = pad_sequences(self.encoder_seq, padding=\"post\",maxlen = self.max_len)\n",
    "        # PADDING THE DECODER INPUT SEQUENCES\n",
    "        self.decoder_inp_seq = pad_sequences(self.decoder_inp_seq, padding=\"post\",maxlen = self.max_len)\n",
    "        # PADDING DECODER OUTPUT SEQUENCES\n",
    "        self.decoder_out_seq = pad_sequences(self.decoder_out_seq ,padding=\"post\", maxlen = self.max_len)\n",
    "\n",
    "        ##  RETURNING THE ENCODER INPUT , DECODER INPUT , AND DECODER OUTPUT\n",
    "        return self.encoder_seq ,  self.decoder_inp_seq,  self.decoder_out_seq\n",
    "    \n",
    "    def __len__(self):\n",
    "        # RETURN THE LEN OF INPUT ENDODER\n",
    "        return len(self.encoder_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2138832a-05b4-43aa-ac36-29b2fbde06c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## THIS CLASS CONVERTES THE DATASET INTO THE REQUIRED BATCH SIZE\n",
    "\n",
    "class Dataloader(tf.keras.utils.Sequence):\n",
    "    def __init__(self,batch_size,dataset):\n",
    "        # INTIALIZING THE REQUIRED VARIABLES \n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.totl_points = self.dataset.encoder_inp.shape[0]\n",
    "        \n",
    "    def __getitem__(self,i):\n",
    "        # STATING THE START AND STOP VATIABLE CONTAINGING INDEX VALUES FOR EACH BATCH\n",
    "        start = i * self.batch_size\n",
    "        stop = (i+1)*self.batch_size\n",
    "        \n",
    "        # PLACEHOLDERS FOR BATCHED DATA\n",
    "        batch_enc =[]\n",
    "        batch_dec_input = []\n",
    "        batch_dec_out =[]\n",
    "\n",
    "        for j in range(start,stop): \n",
    "            \n",
    "            a,b,c = self.dataset[j] \n",
    "            batch_enc.append(a[0]) \n",
    "            batch_dec_input.append(b[0])\n",
    "            batch_dec_out.append(c[0]) \n",
    "        \n",
    "        # Conveting list to array   \n",
    "        batch_enc = (np.array(batch_enc)) \n",
    "        batch_dec_input = np.array(batch_dec_input)\n",
    "        batch_dec_out = np.array(batch_dec_out)\n",
    "        \n",
    "        ## RETURNING BATCHED DATA IN REQUIRED FORM\n",
    "        return [batch_enc , batch_dec_input],batch_dec_out\n",
    "    \n",
    "    def __len__(self):\n",
    "        # Returning the number of batches\n",
    "        return int(self.totl_points/self.batch_size)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "56d57354-58ac-4de3-a47c-f33e0d351cb7",
   "metadata": {},
   "source": [
    "NOTE: WE ARE TAKING THE MAXIMUM LENGHT EQUAL TO 35 WHICH IS 99 PERCENTILE OF THE WORD LENGTH DISTRUBUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2f03182-7513-4279-b2fa-d41d845fdc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FORMING OBJECTS OF DATASET AND DATALOADER FOR TRAIN DATASET\n",
    "#train_dataset = Dataset(df_train,tk_inp,tk_out,35)\n",
    "train_dataset = Dataset(df_train,tk_inp,tk_out,50)\n",
    "train_dataloader = Dataloader( batch_size = 32, dataset=train_dataset)\n",
    "\n",
    "# FORMING OBJECTS OF DATASET AND DATALOADER FOR VALIDATION DATASET\n",
    "#val_dataset = Dataset(df_val , tk_inp,tk_out,35)\n",
    "val_dataset = Dataset(df_val , tk_inp,tk_out,50)\n",
    "val_dataloader = Dataloader(batch_size=32 , dataset=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04bc61d5-434d-4093-ae21-620e8cb8a210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENCODER DECODER MODEL\n",
    "## LOADING THE TENSORFLOW LIBRARIES\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87782bbc-0634-4b93-adc8-b62616563113",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DEFINING THE ENCODER LAYER AS A FUNCTION\n",
    "\n",
    "def encoder(input_shape,vocab, emb_output, lstm_units, enc_input):\n",
    "    '''THIS FUNCTION TAKES IN THE SEQUENCES AND RETURNS THE ENCODER OUTPUT'''\n",
    "    ## FIRST LAYER : EMBEDDING LAYER\n",
    "    enc_emb = layers.Embedding(vocab, emb_output,mask_zero = True,input_length=input_shape)(enc_input)\n",
    "    ## SECOND LAYER : LSTM LAYER\n",
    "    enc_lstm , enc_state_h,enc_state_c = layers.LSTM(units= lstm_units,return_sequences=True,return_state=True)(enc_emb)\n",
    "    ## RETURNING THE LSTM OUTPUTS AND STATES\n",
    "    return enc_lstm , enc_state_h,enc_state_c\n",
    "\n",
    "\n",
    "## DEFINING THE DECODER LAYER AS A FUNCTION \n",
    "def decoder(input_shape,vocab, emb_output, lstm_units,enc_states, dec_input):\n",
    "  ## FIRST LAYER : EMBEDDING LAYER\n",
    "  dec_emb = layers.Embedding(vocab, emb_output , mask_zero = True,input_length=input_shape)(dec_input)\n",
    "  ## SECONG LAYER : LSTM LAYER\n",
    "  dec_lstm, dec_state_h,dec_state_c = layers.LSTM(units=lstm_units,return_sequences=True,return_state=True)(dec_emb,initial_state= enc_states)\n",
    "  ## RETURNING THE LSTM OUTPUTS AND STATES\n",
    "  return dec_lstm, dec_state_h,dec_state_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bfbc8f9-f05b-49fe-b11e-3dccb9173ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-18 21:11:47.071671: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-18 21:11:50.502470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10413 MB memory:  -> device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:07:00.0, compute capability: 6.1\n",
      "2022-10-18 21:11:50.507042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 10413 MB memory:  -> device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:08:00.0, compute capability: 6.1\n",
      "2022-10-18 21:11:50.512798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 10413 MB memory:  -> device: 2, name: GeForce GTX 1080 Ti, pci bus id: 0000:0c:00.0, compute capability: 6.1\n",
      "2022-10-18 21:11:50.515586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 10413 MB memory:  -> device: 3, name: GeForce GTX 1080 Ti, pci bus id: 0000:0e:00.0, compute capability: 6.1\n",
      "2022-10-18 21:11:50.518092: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 2240 MB memory:  -> device: 4, name: GeForce GTX 1080 Ti, pci bus id: 0000:0f:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "## DEFINING THE MODEL ARCHITECTURE\n",
    "\n",
    "# INPUT LAYER\n",
    "#enc_input = layers.Input(shape=(35))\n",
    "enc_input = layers.Input(shape=(50))\n",
    "# ENCODER DEFINED FORM FUNCTON ABOVE\n",
    "#enc_lstm , enc_state_h,enc_state_c = encoder(35,len(tk_inp.word_index)+1 , 300 ,256, enc_input )\n",
    "enc_lstm , enc_state_h,enc_state_c = encoder(50,len(tk_inp.word_index)+1 , 300 ,256, enc_input )\n",
    "\n",
    "\n",
    "# DECODER INPUT LAYER\n",
    "#dec_input = layers.Input(shape = (35))\n",
    "dec_input = layers.Input(shape = (50))\n",
    "# DECODER DEFINEA FROM ABOVE FUNCTION\n",
    "#dec_lstm , dec_state_h,dec_state_c = decoder(35,len(tk_out.word_index)+1 , 300 , 256 , [enc_state_h,enc_state_c],dec_input)\n",
    "dec_lstm , dec_state_h,dec_state_c = decoder(50,len(tk_out.word_index)+1 , 300 , 256 , [enc_state_h,enc_state_c],dec_input)\n",
    "# DENCSE LAYER CONNECTOD TO DECODER OUTPUT\n",
    "dense = layers.Dense(len(tk_out.word_index)+1,activation=\"softmax\")(dec_lstm)\n",
    "\n",
    "# MODEL DEFINING\n",
    "model  = Model(inputs=[enc_input,dec_input],outputs=dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48b2f95a-a722-445f-88a1-08fdc71153e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 50)]         0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 50)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 50, 300)      22148700    ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 50, 300)      21891300    ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 50, 256),    570368      ['embedding[0][0]']              \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, 50, 256),    570368      ['embedding_1[0][0]',            \n",
      "                                 (None, 256),                     'lstm[0][1]',                   \n",
      "                                 (None, 256)]                     'lstm[0][2]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 50, 72971)    18753547    ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 63,934,283\n",
      "Trainable params: 63,934,283\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# MODEL SUMMARY\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d14fedf-7d65-4c41-8ae4-bfa38d2670b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DEFINING THE CALLBACKS\n",
    "callback =[ tf.keras.callbacks.ModelCheckpoint( \"models/hindi_trainable_word_emb.h5\",save_best_only=True,mode=\"min\" ,save_weights_only=True),\n",
    "           tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=5,verbose=1,min_delta=0.0001)\n",
    "]\n",
    "\n",
    "## STORING THE NUMBER OF STEPS IN ONE EPOCH FOR TRAIN AND VALIDATION DATASET\n",
    "train_steps = train_dataloader.__len__()\n",
    "val_steps  = val_dataloader.__len__()\n",
    "\n",
    "# COMPILING THE MODEL\n",
    "model.compile(optimizer=\"adam\",loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7773d81c-dfe0-4b4e-a8b4-e8eca3b1970d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-18 21:12:36.146427: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3500/3500 [==============================] - 417s 117ms/step - loss: 2.0455 - accuracy: 0.2638 - val_loss: 1.5739 - val_accuracy: 0.3971\n",
      "Epoch 2/60\n",
      "3500/3500 [==============================] - 406s 116ms/step - loss: 1.4220 - accuracy: 0.4519 - val_loss: 1.2459 - val_accuracy: 0.4976\n",
      "Epoch 3/60\n",
      "3500/3500 [==============================] - 405s 116ms/step - loss: 1.0934 - accuracy: 0.5389 - val_loss: 1.0683 - val_accuracy: 0.5512\n",
      "Epoch 4/60\n",
      "3500/3500 [==============================] - 405s 116ms/step - loss: 0.8556 - accuracy: 0.6096 - val_loss: 0.9604 - val_accuracy: 0.5884\n",
      "Epoch 5/60\n",
      "3500/3500 [==============================] - 405s 116ms/step - loss: 0.6728 - accuracy: 0.6731 - val_loss: 0.8967 - val_accuracy: 0.6138\n",
      "Epoch 6/60\n",
      "3500/3500 [==============================] - 405s 116ms/step - loss: 0.5307 - accuracy: 0.7313 - val_loss: 0.8507 - val_accuracy: 0.6354\n",
      "Epoch 7/60\n",
      "3500/3500 [==============================] - 404s 115ms/step - loss: 0.4235 - accuracy: 0.7798 - val_loss: 0.8260 - val_accuracy: 0.6509\n",
      "Epoch 8/60\n",
      "3500/3500 [==============================] - 408s 116ms/step - loss: 0.3447 - accuracy: 0.8165 - val_loss: 0.8097 - val_accuracy: 0.6632\n",
      "Epoch 9/60\n",
      "3500/3500 [==============================] - 406s 116ms/step - loss: 0.2814 - accuracy: 0.8471 - val_loss: 0.8066 - val_accuracy: 0.6703\n",
      "Epoch 10/60\n",
      "3500/3500 [==============================] - 405s 116ms/step - loss: 0.2349 - accuracy: 0.8695 - val_loss: 0.8075 - val_accuracy: 0.6770\n",
      "Epoch 11/60\n",
      "3500/3500 [==============================] - 405s 116ms/step - loss: 0.2012 - accuracy: 0.8859 - val_loss: 0.8063 - val_accuracy: 0.6831\n",
      "Epoch 12/60\n",
      "3500/3500 [==============================] - 404s 115ms/step - loss: 0.1705 - accuracy: 0.9016 - val_loss: 0.8155 - val_accuracy: 0.6879\n",
      "Epoch 13/60\n",
      "3500/3500 [==============================] - 407s 116ms/step - loss: 0.1462 - accuracy: 0.9147 - val_loss: 0.8289 - val_accuracy: 0.6894\n",
      "Epoch 14/60\n",
      "3500/3500 [==============================] - 405s 116ms/step - loss: 0.1281 - accuracy: 0.9242 - val_loss: 0.8398 - val_accuracy: 0.6914\n",
      "Epoch 15/60\n",
      "3500/3500 [==============================] - 404s 115ms/step - loss: 0.1126 - accuracy: 0.9323 - val_loss: 0.8500 - val_accuracy: 0.6950\n",
      "Epoch 16/60\n",
      "3500/3500 [==============================] - 404s 115ms/step - loss: 0.0997 - accuracy: 0.9394 - val_loss: 0.8639 - val_accuracy: 0.6955\n",
      "Epoch 00016: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fea9478f898>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## FITTING THE MODEL\n",
    "model.fit(train_dataloader,steps_per_epoch=train_steps,epochs=60,validation_data = val_dataloader,validation_steps =val_steps,callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bdfe52-e2f4-438c-b347-ec7b65736004",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbd23b2-1d9f-441c-8c50-92a1fa113ae8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e074cab9-d446-4baa-b09c-e5065dff99ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOADING THE WEIGHTS FOR BEST MODEL\n",
    "#model.load_weights(\"model_save/word_trainable_embedding/besh.h5\")\n",
    "model.built = True\n",
    "model.load_weights(\"models/hindi_trainable_word_emb.h5\")\n",
    "#model.load_weights(\"models/hindi_trainable_word_emb_small.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "25cda283-0a02-43cb-b887-02882afa5f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "## THIS FUNCTION IS USED IN THE INFERENCE TIME TO PREDICT THE RESULTS GIVEN THE INPUT TEXT\n",
    "\n",
    "def predict(inp , model):\n",
    "    ##  TAKES INPUT AS TEXT AND THE MODEL\n",
    "\n",
    "    # CONVERT TEXT INPUT TO SEQUENCES \n",
    "    seq = tk_inp.texts_to_sequences([inp])\n",
    "    # PADDING THE SEQUENCE\n",
    "    #seq = pad_sequences(seq,maxlen = 35,padding=\"post\")\n",
    "    seq = pad_sequences(seq,maxlen = 50,padding=\"post\")\n",
    "    ## INITIAL STATES FOR ENCODER\n",
    "    state = [tf.zeros(shape=(1,256)),tf.zeros(shape= (1,256))]\n",
    "\n",
    "    # SEQUENCE TO EMBEDDING\n",
    "    enc_emb  = model.layers[2](seq)\n",
    "    # PASSING EMBBEDDED SEQUENCES TO LSTM LAYER\n",
    "    enc_output,state_h,state_c= model.layers[4](enc_emb,state)\n",
    "\n",
    "    # PLACE HOLDER FOR PREDECTED WORDS\n",
    "    pred = []\n",
    "    # PLACE HOLDER FOR STATES \n",
    "    input_state = [state_h,state_c]\n",
    "    # CURRENT VECTOR TO BE PASSED TO DECODER \n",
    "    current_vec = tf.ones((1,1))\n",
    "    \n",
    "    for i in range(50): # FOR i UP TO 50 (MAX LENGTH)\n",
    "        ## CONVERT THE CURRENT VECTOR SEQUENCE WORD TO EMBEDDINGS\n",
    "        dec_emb  = model.layers[3](current_vec)\n",
    "        ## PASSING EMBEDDED VECTOR TO DECODER LSTM LAYER\n",
    "        dec_output,dec_state_h,dec_state_c = model.layers[5](dec_emb , input_state)\n",
    "        # PASSING DECODER OUTPUT TO DENSE LAYER\n",
    "        dense = model.layers[6](dec_output)\n",
    "\n",
    "        # SELECTING INDEX OF MAXIMUM DENSE OUTPUT AS CURRENT VECTOR\n",
    "        current_vec = np.argmax(dense ,axis = -1)\n",
    "        # UPDATING THE INPUT STATES\n",
    "        input_state = [dec_state_h,dec_state_c]\n",
    "\n",
    "        # APPENDING THE ACTUAL TEXT TO \"pred\" VARIABLE\n",
    "        pred.append(tk_out.index_word[current_vec[0][0]])\n",
    "        ## IF THE CURRENT VECTOR IS \"<end>\" BREAK THE LOOP\n",
    "        if tk_out.index_word[current_vec[0][0]]==\"<end>\":\n",
    "            break\n",
    "    ## RETURN THE JOINED STRING IN LIST \"pred\"\n",
    "    return \" \".join(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "619d8a7f-3c98-49c8-924b-f085dc4fab75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT SENTENCE ===>  इसी बीच अमरीकी विदेश मंत्री हिलेरीक्लिंटन ने कहा हैं कि विकीलीक्स को जानकारी देने वालों के विरुद्ध कड़ी कार्रवाई की जाएगी ।\n",
      "PREDICTED SENTENCE ===>  इसी बीच अमरीकी विदेश मंत्री हिलेरीक्लिंटन ने कहा है कि विकीलीक्स को जानकारी देकर सुरक्षा के बदले की जानकारी होनी चाहिए । <end>\n",
      "ACTUAL SENTENCE ===>  इसी बीच अमरीकी विदेश मंत्री हिलेरीक्लिंटन ने कहा है कि विकीलीक्स को जानकारी देने वालों के विरुद्ध कड़ी कार्रवाई की जाएगी ।  <end>\n"
     ]
    }
   ],
   "source": [
    "# Prediction on Test Set\n",
    "print(\"INPUT SENTENCE ===> \",df_test.enc_input.values[10])\n",
    "print(\"PREDICTED SENTENCE ===> \",predict(df_test.enc_input.values[10],model))\n",
    "print(\"ACTUAL SENTENCE ===> \",df_test.dec_output.values[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c37db6e-046c-46e9-9a88-80924c8fd3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT SENTENCE ===>  वह एक गिलास शर्बत\n",
      "PREDICTED SENTENCE ===>  उसने एक गिलास शर्बत <end>\n",
      "ACTUAL SENTENCE ===>  उसने एक गिलास शर्बत <end>\n"
     ]
    }
   ],
   "source": [
    "print(\"INPUT SENTENCE ===> \",df_test.enc_input.values[4])\n",
    "print(\"PREDICTED SENTENCE ===> \",predict(df_test.enc_input.values[4],model))\n",
    "print(\"ACTUAL SENTENCE ===> \",df_test.dec_output.values[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "da01c30e-cd86-4369-ad22-e6d5be2c96a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT SENTENCE ===>  गुजरात और यूपी भी में हुए ऐसे मामले\n",
      "PREDICTED SENTENCE ===>  गुजरात में किसे लेने की जल्द जानकारी मामले <end>\n",
      "ACTUAL SENTENCE ===>  गुजरात और यूपी में भी हुए ऐसे मामले <end>\n"
     ]
    }
   ],
   "source": [
    "print(\"INPUT SENTENCE ===> \",df_test.enc_input.values[20])\n",
    "print(\"PREDICTED SENTENCE ===> \",predict(df_test.enc_input.values[20],model))\n",
    "print(\"ACTUAL SENTENCE ===> \",df_test.dec_output.values[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c1ebf5ba-580c-4cbe-97e4-e847168e5848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT SENTENCE ===>  अमेरिका भी इससे अलग नहीं हैं ।\n",
      "PREDICTED SENTENCE ===>  अमेरिका भी इससे अलग नहीं है । <end>\n",
      "ACTUAL SENTENCE ===>  अमेरिका भी इससे अलग नहीं है ।  <end>\n"
     ]
    }
   ],
   "source": [
    "print(\"INPUT SENTENCE ===> \",df_test.enc_input.values[500])\n",
    "print(\"PREDICTED SENTENCE ===> \",predict(df_test.enc_input.values[500],model))\n",
    "print(\"ACTUAL SENTENCE ===> \",df_test.dec_output.values[500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c8b12cdb-dee2-4393-9748-e210e3af7f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT SENTENCE ===>  इसलिए वैज्ञानिकों ने लाइकोपीन आधारिक एक दवाई बनाई हैं ।\n",
      "PREDICTED SENTENCE ===>  इसलिए वैज्ञानिकों ने लाइकोपीन आधारिक एक दवाई बनाई है । <end>\n",
      "ACTUAL SENTENCE ===>  इसलिए वैज्ञानिकों ने लाइकोपीन आधारिक एक दवाई बनाई है ।  <end>\n"
     ]
    }
   ],
   "source": [
    "print(\"INPUT SENTENCE ===> \",df_test.enc_input.values[900])\n",
    "print(\"PREDICTED SENTENCE ===> \",predict(df_test.enc_input.values[900],model))\n",
    "print(\"ACTUAL SENTENCE ===> \",df_test.dec_output.values[900])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8e0cd4c8-bb40-49b9-86e9-3f4a6d248dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT SENTENCE ===>  जनपथ के एक दुकानदार नितिन कहते है कि अबतक उन्होंने किसी को भी पॉलिथीन चेकिंग करते नहीं देखा\n",
      "PREDICTED SENTENCE ===>  जनपथ के एक दुकानदार नितिन कहते हैं कि अबतक उन्होंने किसी को भी पॉलिथीन चेकिंग करते नहीं देखा <end>\n",
      "ACTUAL SENTENCE ===>  जनपथ के एक दुकानदार नितिन कहते हैं कि अबतक उन्होंने किसी को भी पॉलिथीन चेकिंग करते नहीं देखा <end>\n"
     ]
    }
   ],
   "source": [
    "print(\"INPUT SENTENCE ===> \",df_test.enc_input.values[700])\n",
    "print(\"PREDICTED SENTENCE ===> \",predict(df_test.enc_input.values[700],model))\n",
    "print(\"ACTUAL SENTENCE ===> \",df_test.dec_output.values[700])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d3aa1d08-5868-47bc-8527-ff41f37c6f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT SENTENCE ===>  पांचवें दिन फौज के लोगों को फकीरी दी जाती थे ।\n",
      "PREDICTED SENTENCE ===>  पांचवें दिन फौज के लोगों को फकीरी दी जाती थी । <end>\n",
      "ACTUAL SENTENCE ===>  पांचवें दिन फौज के लोगों को फकीरी दी जाती थी ।  <end>\n"
     ]
    }
   ],
   "source": [
    "print(\"INPUT SENTENCE ===> \",df_test.enc_input.values[550])\n",
    "print(\"PREDICTED SENTENCE ===> \",predict(df_test.enc_input.values[550],model))\n",
    "print(\"ACTUAL SENTENCE ===> \",df_test.dec_output.values[550])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9d89a9f1-bf4f-453f-8da0-f8ed72b2469a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 3)\n"
     ]
    }
   ],
   "source": [
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7888c001-2206-4e3b-9bd2-7607b48fbefa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 209 ms, sys: 4.57 ms, total: 214 ms\n",
      "Wall time: 180 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'नारों की आवाज मुखिया को ठीक उसी तरह खीच लाई जैसे बीन की धुन सांप को बाहर खीच लाती है । <end>'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#Inference Time\n",
    "predict(df_test.enc_input.values[50],model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "20160977-9bd7-4a81-80ea-d3208c703076",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BELU SCore\n",
    "import nltk.translate.bleu_score as bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "103cd94c-7575-49df-9007-48e26a31f795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT SENTENCE ===>  पांचवें दिन फौज के लोगों को फकीरी दी जाती थे ।\n",
      "PREDICTED SENTENCE ===>  पांचवें दिन फौज के लोगों को फकीरी दी जाती थी । <end>\n",
      "ACTUAL SENTENCE ===>  पांचवें दिन फौज के लोगों को फकीरी दी जाती थी ।  <end>\n"
     ]
    }
   ],
   "source": [
    "print(\"INPUT SENTENCE ===> \",df_test.enc_input.values[550])\n",
    "p = predict(df_test.enc_input.values[550],model)\n",
    "a = df_test.dec_output.values[550]\n",
    "print(\"PREDICTED SENTENCE ===> \",p)\n",
    "print(\"ACTUAL SENTENCE ===> \",a)\n",
    "# import nltk.translate.bleu_score as bleu\n",
    "# bleu.sentence_bleu(a,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8e850c5b-c966-4bef-aae9-36f48e7fef59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [02:08,  7.80it/s]\n"
     ]
    }
   ],
   "source": [
    "# VALIDATION BELU SCORE\n",
    "import nltk.translate.bleu_score as bleu\n",
    "BLEU_val_emb = []\n",
    "test_data = df_val.loc[np.random.choice(df_val.index,size = 1000)]\n",
    "for ind,i in tqdm(test_data.iterrows(),position=0):\n",
    "    try:\n",
    "        pred = predict(str(i.enc_input),model).split()\n",
    "        act = [str(i.dec_output).split()]\n",
    "        b =bleu.sentence_bleu(act,pred)\n",
    "        BLEU_val_emb.append(b)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "448bb5d0-6243-4efc-9b82-de4464a2e475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BELU Score =  0.31729669098268243\n"
     ]
    }
   ],
   "source": [
    "print(\"BELU Score = \",np.mean(BLEU_val_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4747a169-51cb-45af-94ee-b5c2a96c9730",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [02:08,  7.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BELU Score =  0.31729669098268243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "BLEU_val_emb = []\n",
    "test_data = df_val.loc[np.random.choice(df_val.index,size = 1000)]\n",
    "for ind,i in tqdm(test_data.iterrows(),position=0):\n",
    "    try:\n",
    "        pred = predict(str(i.enc_input),model).split()\n",
    "        act = [str(i.dec_output).split()]\n",
    "        b =bleu.sentence_bleu(act,pred)\n",
    "        BLEU_val_emb.append(b)\n",
    "    except:\n",
    "        continue\n",
    "print(\"BELU Score = \",np.mean(BLEU_val_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8976d568-26d3-482a-b8eb-3e19aa4f87ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 3)\n"
     ]
    }
   ],
   "source": [
    "#New test set (all together a different dataset)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e9371f84-33b6-416a-b8d0-d17c1f4e7b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enc_input</th>\n",
       "      <th>dec_input</th>\n",
       "      <th>dec_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>इसके अलावा माइकल शूमाकर द्वारा चलाई गई एक फरार...</td>\n",
       "      <td>इसके अलावा माइकल शूमाकर द्वारा चलाई गई एक फरार...</td>\n",
       "      <td>इसके अलावा माइकल शूमाकर द्वारा चलाई गई एक फरार...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>यह मन को काबू में करने वाली मुद्रा हैं इसीलिए ...</td>\n",
       "      <td>यह मन को काबू में करने वाली मुद्रा है इसीलिए इ...</td>\n",
       "      <td>यह मन को काबू में करने वाली मुद्रा है इसीलिए इ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>आप पुस्तक पढ़ने में तल्लीन हैं और बच्चा उसनेाँ...</td>\n",
       "      <td>आप पुस्तक पढ़ने में तल्लीन हैं और बच्चा वहाँ प...</td>\n",
       "      <td>आप पुस्तक पढ़ने में तल्लीन हैं और बच्चा वहाँ प...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>परिवार के मुताबिक धमाकों में हिस्सा लेने वाले ...</td>\n",
       "      <td>परिवार के मुताबिक धमाकों में हिस्सा लेने वाले ...</td>\n",
       "      <td>परिवार के मुताबिक धमाकों में हिस्सा लेने वाले ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>उनकी वो वाली बात भी अनिश्चित रहती हैं ।</td>\n",
       "      <td>उनकी वो वाली बात भी अनिश्चित रहती है ।</td>\n",
       "      <td>उनकी वो वाली बात भी अनिश्चित रहती है ।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>पालिश घर्षक मशीनें करती हैंं ।</td>\n",
       "      <td>पालिश घर्षक मशीनें करती हैं ।</td>\n",
       "      <td>पालिश घर्षक मशीनें करती हैं ।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>पहले पाकिस्तान ने हमले में भारत का हाथ बताया औ...</td>\n",
       "      <td>पहले पाकिस्तान ने हमले में भारत का हाथ बताया औ...</td>\n",
       "      <td>पहले पाकिस्तान ने हमले में भारत का हाथ बताया औ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>सारे का सारा दर्द उन्हों अप ह्रदय में ही समेट ...</td>\n",
       "      <td>सारे का सारा दर्द उन्होंने अपने ह्रदय में ही स...</td>\n",
       "      <td>सारे का सारा दर्द उन्होंने अपने ह्रदय में ही स...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>विल्सन ने लिखे पत्र में रिपब्लिकन सांसदों से भ...</td>\n",
       "      <td>विल्सन ने लिखे पत्र में रिपब्लिकन सांसदों से भ...</td>\n",
       "      <td>विल्सन ने लिखे पत्र में रिपब्लिकन सांसदों से भ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>और ये सिलसिला चलता रहता हैं ।</td>\n",
       "      <td>और ये सिलसिला चलता रहता है ।</td>\n",
       "      <td>और ये सिलसिला चलता रहता है ।</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               enc_input  \\\n",
       "0      इसके अलावा माइकल शूमाकर द्वारा चलाई गई एक फरार...   \n",
       "1      यह मन को काबू में करने वाली मुद्रा हैं इसीलिए ...   \n",
       "2      आप पुस्तक पढ़ने में तल्लीन हैं और बच्चा उसनेाँ...   \n",
       "3      परिवार के मुताबिक धमाकों में हिस्सा लेने वाले ...   \n",
       "4                उनकी वो वाली बात भी अनिश्चित रहती हैं ।   \n",
       "...                                                  ...   \n",
       "29995                     पालिश घर्षक मशीनें करती हैंं ।   \n",
       "29996  पहले पाकिस्तान ने हमले में भारत का हाथ बताया औ...   \n",
       "29997  सारे का सारा दर्द उन्हों अप ह्रदय में ही समेट ...   \n",
       "29998  विल्सन ने लिखे पत्र में रिपब्लिकन सांसदों से भ...   \n",
       "29999                      और ये सिलसिला चलता रहता हैं ।   \n",
       "\n",
       "                                               dec_input  \\\n",
       "0      इसके अलावा माइकल शूमाकर द्वारा चलाई गई एक फरार...   \n",
       "1      यह मन को काबू में करने वाली मुद्रा है इसीलिए इ...   \n",
       "2      आप पुस्तक पढ़ने में तल्लीन हैं और बच्चा वहाँ प...   \n",
       "3      परिवार के मुताबिक धमाकों में हिस्सा लेने वाले ...   \n",
       "4                उनकी वो वाली बात भी अनिश्चित रहती है ।    \n",
       "...                                                  ...   \n",
       "29995                     पालिश घर्षक मशीनें करती हैं ।    \n",
       "29996  पहले पाकिस्तान ने हमले में भारत का हाथ बताया औ...   \n",
       "29997  सारे का सारा दर्द उन्होंने अपने ह्रदय में ही स...   \n",
       "29998  विल्सन ने लिखे पत्र में रिपब्लिकन सांसदों से भ...   \n",
       "29999                      और ये सिलसिला चलता रहता है ।    \n",
       "\n",
       "                                              dec_output  \n",
       "0      इसके अलावा माइकल शूमाकर द्वारा चलाई गई एक फरार...  \n",
       "1      यह मन को काबू में करने वाली मुद्रा है इसीलिए इ...  \n",
       "2      आप पुस्तक पढ़ने में तल्लीन हैं और बच्चा वहाँ प...  \n",
       "3      परिवार के मुताबिक धमाकों में हिस्सा लेने वाले ...  \n",
       "4                उनकी वो वाली बात भी अनिश्चित रहती है ।   \n",
       "...                                                  ...  \n",
       "29995                     पालिश घर्षक मशीनें करती हैं ।   \n",
       "29996  पहले पाकिस्तान ने हमले में भारत का हाथ बताया औ...  \n",
       "29997  सारे का सारा दर्द उन्होंने अपने ह्रदय में ही स...  \n",
       "29998  विल्सन ने लिखे पत्र में रिपब्लिकन सांसदों से भ...  \n",
       "29999                      और ये सिलसिला चलता रहता है ।   \n",
       "\n",
       "[30000 rows x 3 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test1= pd.read_csv(\"DATA/etoori_test.csv\")\n",
    "df_test1.columns = [\"enc_input\",\"dec_input\"] \n",
    "df_test1[\"dec_output\"] = df_test1.dec_input\n",
    "print(df_test1.shape)\n",
    "df_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ed4191d7-47bc-4ff1-9a3e-2ece93c67e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT SENTENCE ===>  घर में घुस के बाद भी सुकून नहीं ।\n",
      "PREDICTED SENTENCE ===>  घर में घुसने के बाद भी आज्ञा दिया । <end>\n",
      "ACTUAL SENTENCE ===>  घर में घुसने के बाद भी सुकून नहीं । \n"
     ]
    }
   ],
   "source": [
    "print(\"INPUT SENTENCE ===> \",df_test1.enc_input.values[50])\n",
    "print(\"PREDICTED SENTENCE ===> \",predict(df_test1.enc_input.values[50],model))\n",
    "print(\"ACTUAL SENTENCE ===> \",df_test1.dec_output.values[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9bb2ef6d-e4fb-4386-b58f-7878e3056c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT SENTENCE ===>  जगजीत ने ग़ज़लों लोकप्रिय बनाने के लिए बहुत मेहनत की और हर विधा से उसकी प्रचार किया ।\n",
      "PREDICTED SENTENCE ===>  जगजीत वाजपेयी ने कार्यशाला होने के लिए अच्छी और आरक्षित से हर क्षण को अपने लिए किया । <end>\n",
      "ACTUAL SENTENCE ===>  जगजीत ने ग़ज़लों लोकप्रिय बनाने के लिए बहुत मेहनत की और हर विधा से उसका प्रचार किया । \n"
     ]
    }
   ],
   "source": [
    "print(\"INPUT SENTENCE ===> \",df_test1.enc_input.values[1000])\n",
    "print(\"PREDICTED SENTENCE ===> \",predict(df_test1.enc_input.values[1000],model))\n",
    "print(\"ACTUAL SENTENCE ===> \",df_test1.dec_output.values[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fb415668-299b-4467-bcee-4b11c3dc9b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test1 = df_test1.head(1000)\n",
    "df_test1[\"dec_input\"]= \"<start> \" + df_test1[\"dec_input\"]\n",
    "df_test1[\"dec_output\"] =  df_test1[\"dec_output\"] + \" <end>\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c0cb4591-07ae-4547-8522-72cfdba2b848",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [02:06,  7.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BELU Score =  0.3104000846208022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "BLEU_val_emb = []\n",
    "test_data = df_test1\n",
    "for ind,i in tqdm(test_data.iterrows(),position=0):\n",
    "    try:\n",
    "        pred = predict(str(i.enc_input),model).split()\n",
    "        act = [str(i.dec_output).split()]\n",
    "        b =bleu.sentence_bleu(act,pred)\n",
    "        BLEU_val_emb.append(b)\n",
    "    except:\n",
    "        continue\n",
    "print(\"BELU Score = \",np.mean(BLEU_val_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4c85e86f-89c6-4f37-980e-ac018fdc180f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT SENTENCE ===>  घर में घुस के बाद भी सुकून नहीं ।\n",
      "PREDICTED SENTENCE ===>  घर में घुसने के बाद भी आज्ञा दिया । <end>\n",
      "ACTUAL SENTENCE ===>  घर में घुसने के बाद भी सुकून नहीं ।  <end>\n"
     ]
    }
   ],
   "source": [
    "print(\"INPUT SENTENCE ===> \",df_test1.enc_input.values[50])\n",
    "print(\"PREDICTED SENTENCE ===> \",predict(df_test1.enc_input.values[50],model))\n",
    "print(\"ACTUAL SENTENCE ===> \",df_test1.dec_output.values[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a3db1034-7fd8-4063-9f67-c5b2dcfcbd5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 3)\n"
     ]
    }
   ],
   "source": [
    "df_test1= pd.read_csv(\"DATA/etoori_test.csv\")\n",
    "df_test1.columns = [\"enc_input\",\"dec_input\"] \n",
    "df_test1[\"dec_output\"] = df_test1.dec_input\n",
    "print(df_test1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "015726bf-403d-44cd-9e28-c782f2ca0ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test1 = df_test1.head(10000)\n",
    "df_test1[\"dec_input\"]= \"<start> \" + df_test1[\"dec_input\"]\n",
    "df_test1[\"dec_output\"] =  df_test1[\"dec_output\"] + \" <end>\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "30a88f89-8760-4c03-86da-257c9bd675af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [21:49,  7.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BELU Score =  0.3049701667824825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "BLEU_val_emb = []\n",
    "test_data = df_test1\n",
    "print(test_data.shape)\n",
    "for ind,i in tqdm(test_data.iterrows(),position=0):\n",
    "    try:\n",
    "        pred = predict(str(i.enc_input),model).split()\n",
    "        act = [str(i.dec_output).split()]\n",
    "        b =bleu.sentence_bleu(act,pred)\n",
    "        BLEU_val_emb.append(b)\n",
    "    except:\n",
    "        continue\n",
    "print(\"BELU Score = \",np.mean(BLEU_val_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f042853-9136-4434-99e2-ff63ab120e3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
