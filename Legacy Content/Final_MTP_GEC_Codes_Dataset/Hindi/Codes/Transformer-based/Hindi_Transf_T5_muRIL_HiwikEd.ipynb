{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a9c7780-28f4-4676-8620-cfeffba88c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Apr 15 19:33:59 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.84       Driver Version: 460.84       CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:04:00.0 Off |                  N/A |\n",
      "| 34%   67C    P2    91W / 250W |   8657MiB / 11178MiB |     93%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:06:00.0 Off |                  N/A |\n",
      "| 38%   70C    P2   128W / 250W |  11044MiB / 11178MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce GTX 108...  Off  | 00000000:07:00.0 Off |                  N/A |\n",
      "| 23%   57C    P2    75W / 250W |   9860MiB / 11178MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce GTX 108...  Off  | 00000000:08:00.0 Off |                  N/A |\n",
      "| 36%   68C    P2   132W / 250W |  11000MiB / 11178MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  GeForce GTX 108...  Off  | 00000000:0C:00.0 Off |                  N/A |\n",
      "| 42%   74C    P2    84W / 250W |   3957MiB / 11178MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  GeForce GTX 108...  Off  | 00000000:0D:00.0 Off |                  N/A |\n",
      "| 20%   23C    P8     8W / 250W |      2MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  GeForce GTX 108...  Off  | 00000000:0E:00.0 Off |                  N/A |\n",
      "| 23%   57C    P2    63W / 250W |   4913MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  GeForce GTX 108...  Off  | 00000000:0F:00.0 Off |                  N/A |\n",
      "| 36%   68C    P2   204W / 250W |   3535MiB / 11178MiB |     41%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     11690      C   /usr/bin/python3                 4133MiB |\n",
      "|    0   N/A  N/A     11691      C   /usr/bin/python3                  649MiB |\n",
      "|    0   N/A  N/A     11692      C   /usr/bin/python3                  649MiB |\n",
      "|    0   N/A  N/A     11693      C   /usr/bin/python3                  649MiB |\n",
      "|    0   N/A  N/A     38504      C   /opt/conda/bin/python             445MiB |\n",
      "|    0   N/A  N/A     41710      C   python3                           135MiB |\n",
      "|    1   N/A  N/A     11691      C   /usr/bin/python3                 3657MiB |\n",
      "|    2   N/A  N/A     14515      C   python3                          2919MiB |\n",
      "|    3   N/A  N/A     11692      C   /usr/bin/python3                 3875MiB |\n",
      "|    4   N/A  N/A     11693      C   /usr/bin/python3                 3955MiB |\n",
      "|    6   N/A  N/A     20739      C   python                           4911MiB |\n",
      "|    7   N/A  N/A     41710      C   python3                          3533MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1472674-e209-489e-93b9-3d3c8da03a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'GeForce GTX 1080 Ti'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# The GPU id to use, \"0\" to  \"7\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"5,6,7\"\n",
    "#torch.cuda.set_device(0)\n",
    "n_gpu = torch.cuda.device_count()\n",
    "print(n_gpu)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.get_device_name(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ba40e0c-5fcc-43a9-8d28-47ff9e9870f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "340acc79-3319-47aa-8140-07059948a04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /DATA/gupta92/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "import random\n",
    "import re\n",
    "from itertools import chain\n",
    "from string import punctuation\n",
    "#Set a seed\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import datasets\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    T5ForConditionalGeneration,\n",
    "    T5Tokenizer,\n",
    "    get_linear_schedule_with_warmup\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7712b672-2f06-47dd-906a-42ab51326a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fc22694-eff1-4618-ad9c-8b6110972cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4aaf87c-52e6-4e3d-870c-1955b9afd376",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e4420cd-d086-467d-8384-bc29bb4d91ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140000, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('DATA/etoori_train.csv')\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5761a856-2e35-4eb8-9ff6-8fff051468e0",
   "metadata": {},
   "source": [
    "# Training on Hindi_Artificial_train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44742dea-9094-4df9-809a-f4c662c755da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2592885, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('DATA/Hindi_Artificial_train.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0430727a-5f58-494a-a2af-70c742d2f066",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.head(500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "baf2f26e-0f56-4ae3-8028-99c3534594bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADP_INFL: (1101, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(13187, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df_adp_infl = pd.read_csv('DATA/Wikiedits_ADP_INFL.csv')\n",
    "print(\"ADP_INFL:\", df_adp_infl.shape)\n",
    "df1 = pd.read_csv('DATA/HiWikEd.csv')\n",
    "df1 = df1.drop(['Unnamed: 0'], axis=1)\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac38255d-4957-461b-b6e0-18a272a09a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enc_input</th>\n",
       "      <th>dec_input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>जल प्रदूषण पर नियंत्रण हेतु नालों का नियमित रूप से साफ सफाई करना चाहिए.</td>\n",
       "      <td>जल प्रदूषण पर नियंत्रण हेतु नालों की नियमित रूप से साफ सफाई करना चाहिए.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ये यूनिसन ग्रुप का सबसे बड़ी योजना थी.</td>\n",
       "      <td>ये यूनिसन ग्रुप की सबसे बड़ी योजना थी.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 enc_input  \\\n",
       "0  जल प्रदूषण पर नियंत्रण हेतु नालों का नियमित रूप से साफ सफाई करना चाहिए.   \n",
       "1                                   ये यूनिसन ग्रुप का सबसे बड़ी योजना थी.   \n",
       "\n",
       "                                                                 dec_input  \n",
       "0  जल प्रदूषण पर नियंत्रण हेतु नालों की नियमित रूप से साफ सफाई करना चाहिए.  \n",
       "1                                   ये यूनिसन ग्रुप की सबसे बड़ी योजना थी.  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_adp_infl.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23398c8b-598c-4095-97a2-a0919d0065e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enc_input</th>\n",
       "      <th>dec_input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>चाय की दुकान से लेकर वाहनों और दिवारों तक हर जगह विज्ञापन ही विज्ञापन दिखाई देते है.</td>\n",
       "      <td>चाय की दुकान से लेकर वाहनों और दिवारों तक हर जगह विज्ञापन ही विज्ञापन दिखाई देते हैं.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ये कहीं पे निगाहें, कही पे निशाना का सा अन्दाज है.</td>\n",
       "      <td>यह कहीं पे निगाहें, कही पे निशाना का सा अन्दाज है.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                              enc_input  \\\n",
       "0  चाय की दुकान से लेकर वाहनों और दिवारों तक हर जगह विज्ञापन ही विज्ञापन दिखाई देते है.   \n",
       "1                                    ये कहीं पे निगाहें, कही पे निशाना का सा अन्दाज है.   \n",
       "\n",
       "                                                                               dec_input  \n",
       "0  चाय की दुकान से लेकर वाहनों और दिवारों तक हर जगह विज्ञापन ही विज्ञापन दिखाई देते हैं.  \n",
       "1                                     यह कहीं पे निगाहें, कही पे निशाना का सा अन्दाज है.  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35e95d81-a4ce-4210-b921-c6998fc0d7b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14288, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = [df1, df_adp_infl]\n",
    "df = pd.concat(frames)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60dd0008-7592-44dd-a2af-0d748bd383d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enc_input</th>\n",
       "      <th>dec_input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>चाय की दुकान से लेकर वाहनों और दिवारों तक हर जगह विज्ञापन ही विज्ञापन दिखाई देते है.</td>\n",
       "      <td>चाय की दुकान से लेकर वाहनों और दिवारों तक हर जगह विज्ञापन ही विज्ञापन दिखाई देते हैं.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ये कहीं पे निगाहें, कही पे निशाना का सा अन्दाज है.</td>\n",
       "      <td>यह कहीं पे निगाहें, कही पे निशाना का सा अन्दाज है.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                              enc_input  \\\n",
       "0  चाय की दुकान से लेकर वाहनों और दिवारों तक हर जगह विज्ञापन ही विज्ञापन दिखाई देते है.   \n",
       "1                                    ये कहीं पे निगाहें, कही पे निशाना का सा अन्दाज है.   \n",
       "\n",
       "                                                                               dec_input  \n",
       "0  चाय की दुकान से लेकर वाहनों और दिवारों तक हर जगह विज्ञापन ही विज्ञापन दिखाई देते हैं.  \n",
       "1                                     यह कहीं पे निगाहें, कही पे निशाना का सा अन्दाज है.  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f23822f-77c3-4e13-9245-404f08e1743a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fc84c40-1152-4f97-b749-186365fff1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = {'enc_input':'input'}, inplace = True)\n",
    "df.rename(columns = {'dec_input':'output'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b51b0af9-4f5f-4e8f-92e5-10d8ed20e7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5dd252f1-a794-4cef-be0b-1b59e0d8185c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>चाय की दुकान से लेकर वाहनों और दिवारों तक हर जगह विज्ञापन ही विज्ञापन दिखाई देते है.</td>\n",
       "      <td>चाय की दुकान से लेकर वाहनों और दिवारों तक हर जगह विज्ञापन ही विज्ञापन दिखाई देते हैं.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ये कहीं पे निगाहें, कही पे निशाना का सा अन्दाज है.</td>\n",
       "      <td>यह कहीं पे निगाहें, कही पे निशाना का सा अन्दाज है.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                  input  \\\n",
       "0  चाय की दुकान से लेकर वाहनों और दिवारों तक हर जगह विज्ञापन ही विज्ञापन दिखाई देते है.   \n",
       "1                                    ये कहीं पे निगाहें, कही पे निशाना का सा अन्दाज है.   \n",
       "\n",
       "                                                                                  output  \n",
       "0  चाय की दुकान से लेकर वाहनों और दिवारों तक हर जगह विज्ञापन ही विज्ञापन दिखाई देते हैं.  \n",
       "1                                     यह कहीं पे निगाहें, कही पे निशाना का सा अन्दाज है.  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c81e7ec2-d0fa-45d6-be30-7c2e2877dc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    T5ForConditionalGeneration, T5Tokenizer, \n",
    "    Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq\n",
    "  )\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c509b356-7320-4dbb-9184-9750dd208a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/muril-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3fc016f6-2311-4978-a799-f40e96abaef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='google/muril-base-cased', vocab_size=197285, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cbc19d2f-5c42-46ea-8c21-decc47553c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98a081dd-fbb1-4b1d-a762-4d99ecc0ad9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = AutoModelForMaskedLM.from_pretrained(\"google/muril-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b199d7a2-2b5d-4904-b204-a379c34aefca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "#model_name = 't5-base'\n",
    "#tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "#model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "#model_name = 't5_gec_hindi_muRIL'\n",
    "#model_name = 't5_gec_hindi_muRIL_best'\n",
    "model_name ='t5_gec_hindi_muRIL_best_Full'\n",
    "torch_device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name).to(torch_device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ca44d0-39fd-48a8-a0a2-466fd4ce1d60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aca04df4-d7de-4f44-9800-94eb1c5296ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_token_len(example):\n",
    "    return len(tokenizer(example).input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9821b86-5a8b-4956-856c-d4c88d482f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12859, 2), (1429, 2))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train - Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df, test_size=0.10, shuffle=True)\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c514352d-1338-4a42-95a6-36151e6b0306",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['input_token_len'] = test_df['input'].apply(calc_token_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f9df2945-fb4d-4f63-b24b-2571dceba51b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>input_token_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4450</th>\n",
       "      <td>यह वेल्स राष्ट्रीय रग्बी यूनियन टीम का घर है और वेल्स की राष्ट्रीय फ़ुटबॉल टीम के खेल की मेजबानी भी करता है.</td>\n",
       "      <td>यह वेल्स राष्ट्रीय रग्बी यूनियन टीम का घर है और वेल्स की राष्ट्रीय फ़ुटबॉल टीम के मैच की मेजबानी भी करता है.</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7854</th>\n",
       "      <td>चक्षुषा हिंदू पौराणिक कथाओं के एक पात्र हैं, जो छठे मन्वंतर के मनु हैं, जो ऋषि वृहती के पुत्र हैं.</td>\n",
       "      <td>चक्षुषा हिंदू पौराणिक कथाओं के एक पात्र हैं, जो छठे मन्वंतर के मनु हैं, तथा ऋषि वृहती के पुत्र हैं.</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7050</th>\n",
       "      <td>इस गांव में छत्रिय ब्राह्मण दलित बघेल आज जातियां मुख्य रूप से पाई जाती हैं.</td>\n",
       "      <td>इस गांव में छत्रिय ब्राह्मण दलित बघेल आदि जातियां मुख्य रूप से पाई जाती हैं.</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12868</th>\n",
       "      <td>यदि इस गांव से ऊपर की ओर जाया जाए तो घोरल, एंटीलोप्स, काले और लाल भालुओं को देखा जा सकता है.</td>\n",
       "      <td>यदि इस ग्राम से ऊपर की ओर जाया जाए तो घोरल, एंटीलोप्स, काले और लाल भालुओं को देखा जा सकता है.</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7242</th>\n",
       "      <td>वह एक दशक से अधिक समय के लिए एक प्रमुख शौकिया चैंपियन था.</td>\n",
       "      <td>वह एक दशक से अधिक समय के लिए एक प्रधान शौकिया चैंपियन था.</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                              input  \\\n",
       "4450   यह वेल्स राष्ट्रीय रग्बी यूनियन टीम का घर है और वेल्स की राष्ट्रीय फ़ुटबॉल टीम के खेल की मेजबानी भी करता है.   \n",
       "7854             चक्षुषा हिंदू पौराणिक कथाओं के एक पात्र हैं, जो छठे मन्वंतर के मनु हैं, जो ऋषि वृहती के पुत्र हैं.   \n",
       "7050                                    इस गांव में छत्रिय ब्राह्मण दलित बघेल आज जातियां मुख्य रूप से पाई जाती हैं.   \n",
       "12868                  यदि इस गांव से ऊपर की ओर जाया जाए तो घोरल, एंटीलोप्स, काले और लाल भालुओं को देखा जा सकता है.   \n",
       "7242                                                      वह एक दशक से अधिक समय के लिए एक प्रमुख शौकिया चैंपियन था.   \n",
       "\n",
       "                                                                                                             output  \\\n",
       "4450   यह वेल्स राष्ट्रीय रग्बी यूनियन टीम का घर है और वेल्स की राष्ट्रीय फ़ुटबॉल टीम के मैच की मेजबानी भी करता है.   \n",
       "7854            चक्षुषा हिंदू पौराणिक कथाओं के एक पात्र हैं, जो छठे मन्वंतर के मनु हैं, तथा ऋषि वृहती के पुत्र हैं.   \n",
       "7050                                   इस गांव में छत्रिय ब्राह्मण दलित बघेल आदि जातियां मुख्य रूप से पाई जाती हैं.   \n",
       "12868                 यदि इस ग्राम से ऊपर की ओर जाया जाए तो घोरल, एंटीलोप्स, काले और लाल भालुओं को देखा जा सकता है.   \n",
       "7242                                                      वह एक दशक से अधिक समय के लिए एक प्रधान शौकिया चैंपियन था.   \n",
       "\n",
       "       input_token_len  \n",
       "4450                26  \n",
       "7854                30  \n",
       "7050                21  \n",
       "12868               30  \n",
       "7242                16  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd321d92-6f3a-40ee-ba4a-907be30ea244",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['input_token_len'].describe()\n",
    "\n",
    "train_df = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a5e933a2-ae5f-4c20-87b4-4dbb99b2c5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will use a token length of 64 since it will cover the vast majority of examples\n",
    "from datasets import Dataset\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8ca6fab2-ae06-441f-807e-da87e843249b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "183"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.input.str.len().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d75fca39-9ccb-4bce-8a14-ca5d573cb60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the Dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class GrammarDataset(Dataset):\n",
    "    def __init__(self, dataset, tokenizer,print_text=False):         \n",
    "        self.dataset = dataset\n",
    "        self.pad_to_max_length = False\n",
    "        self.tokenizer = tokenizer\n",
    "        self.print_text = print_text\n",
    "        #self.max_len = 128\n",
    "        self.max_len = 64\n",
    "  \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "\n",
    "    def tokenize_data(self, example):\n",
    "        input_, target_ = example['input'], example['output']\n",
    "\n",
    "        # tokenize inputs\n",
    "        tokenized_inputs = tokenizer(input_, pad_to_max_length=self.pad_to_max_length, \n",
    "                                            max_length=self.max_len,\n",
    "                                            return_attention_mask=True)\n",
    "    \n",
    "        tokenized_targets = tokenizer(target_, pad_to_max_length=self.pad_to_max_length, \n",
    "                                            max_length=self.max_len,\n",
    "                                            return_attention_mask=True)\n",
    "\n",
    "        inputs={\"input_ids\": tokenized_inputs['input_ids'],\n",
    "            \"attention_mask\": tokenized_inputs['attention_mask'],\n",
    "            \"labels\": tokenized_targets['input_ids']\n",
    "        }\n",
    "        \n",
    "        return inputs\n",
    "\n",
    "  \n",
    "    def __getitem__(self, index):\n",
    "        inputs = self.tokenize_data(self.dataset[index])\n",
    "        \n",
    "        if self.print_text:\n",
    "            for k in inputs.keys():\n",
    "                print(k, len(inputs[k]))\n",
    "\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b8aa2940-f691-4bc5-9c05-d70ff42e05ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids 13\n",
      "attention_mask 13\n",
      "labels 13\n",
      "{'input_ids': [104, 1503, 23421, 6407, 2768, 2254, 7593, 1124, 2768, 13913, 1115, 121, 105], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [104, 1503, 23421, 6407, 2768, 2254, 7593, 1124, 2768, 13913, 1145, 121, 105]}\n"
     ]
    }
   ],
   "source": [
    "dataset = GrammarDataset(test_dataset, tokenizer, True)\n",
    "print(dataset[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfc0564-2706-4d95-8dfb-e9970a0e2a02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e6bd3fc-b11e-47a1-b473-10705ebe1d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Evaluator\n",
    "#!pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f50438a6-1ed2-460a-8bb0-307fa7b23806",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "rouge_metric = load_metric(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bf186c82-6bea-4bb3-b9f3-1b00df72ee70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Model\n",
    "#data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, padding='longest', return_tensors='pt')\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, padding='longest', return_tensors='pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "46056d09-d0ba-46ac-823e-adf72d83ac55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = 't5_gec_hindi_muRIL_1'\n",
    "#torch_device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
    "#model = T5ForConditionalGeneration.from_pretrained(model_name).to(torch_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7b108ae3-2088-44fa-af0f-8b3583bd157d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining training related arguments\n",
    "batch_size = 8\n",
    "'''\n",
    "args = Seq2SeqTrainingArguments(output_dir=\"models/hindi/T5_muRIL_3\",\n",
    "                        evaluation_strategy=\"epoch\",\n",
    "                        per_device_train_batch_size=batch_size,\n",
    "                        per_device_eval_batch_size=batch_size,\n",
    "                        learning_rate=2e-5,\n",
    "                        num_train_epochs=1,\n",
    "                        weight_decay=0.1,\n",
    "                        save_total_limit=2,\n",
    "                        predict_with_generate=True,\n",
    "                        fp16 = True,\n",
    "                        gradient_accumulation_steps = 6,\n",
    "                        #eval_steps = 500,\n",
    "                        #save_steps = 2000,\n",
    "                        #dataloader_num_workers= 4,\n",
    "                        load_best_model_at_end=True,\n",
    "                        logging_dir=\"logs/hindi/T5_muRIL_3\")\n",
    "'''\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"models/hindi/T5_muRIL_Full\",\n",
    "    #output_dir =None,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-3,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.3,\n",
    "    save_steps=300000,\n",
    "    num_train_epochs=10,\n",
    "    dataloader_num_workers= 2,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    #logging_dir=\"logs/hindi/T5_muRIL_3\"\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e2a430e6-c635-43bb-a305-357ac0773191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "#os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"false\"\n",
    "os.environ['TRANSFORMERS_NO_ADVISORY_WARNINGS'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bfbcd6b1-bdcb-4f9d-a7ca-cd6924d7e6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9d9743c7-8b58-4bee-9ab1-2fcd8032b17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuda_amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "# defining trainer using 🤗\n",
    "trainer = Seq2SeqTrainer(model=model, \n",
    "                args=args, \n",
    "                train_dataset= GrammarDataset(train_dataset, tokenizer),\n",
    "                eval_dataset=GrammarDataset(test_dataset, tokenizer),\n",
    "                tokenizer=tokenizer,\n",
    "                data_collator=data_collator)\n",
    "                #compute_metrics=compute_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "50e692da-5dee-4325-b082-b660f82d1e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch\n",
    "#torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "daad0d94-9d45-428a-b04a-712301e66c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 14288\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 24\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5960\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5960' max='5960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5960/5960 1:17:29, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.464700</td>\n",
       "      <td>1.607950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.404500</td>\n",
       "      <td>1.396081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.327900</td>\n",
       "      <td>1.434922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.210000</td>\n",
       "      <td>1.267827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.144800</td>\n",
       "      <td>1.079509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.744200</td>\n",
       "      <td>0.838862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.432800</td>\n",
       "      <td>0.879704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.320200</td>\n",
       "      <td>0.538478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.999400</td>\n",
       "      <td>0.454238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.851300</td>\n",
       "      <td>0.404103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1429\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1429\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1429\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1429\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1429\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1429\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1429\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1429\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1429\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1429\n",
      "  Batch size = 24\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5960, training_loss=1.7238809111934381, metrics={'train_runtime': 4660.5741, 'train_samples_per_second': 30.657, 'train_steps_per_second': 1.279, 'total_flos': 5281501299793920.0, 'train_loss': 1.7238809111934381, 'epoch': 10.0})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"     #Disabling Wandb\n",
    "#model.resize_token_embeddings(len(tokenizer))\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8bfc48c8-a51f-4f22-94fb-59aec03306f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to t5_gec_hindi_muRIL_best_Full\n",
      "Configuration saved in t5_gec_hindi_muRIL_best_Full/config.json\n",
      "Model weights saved in t5_gec_hindi_muRIL_best_Full/pytorch_model.bin\n",
      "tokenizer config file saved in t5_gec_hindi_muRIL_best_Full/tokenizer_config.json\n",
      "Special tokens file saved in t5_gec_hindi_muRIL_best_Full/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "#Save the trained Model\n",
    "trainer.save_model('t5_gec_hindi_muRIL_best_Full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5878bd-b180-46db-b3e9-21b6f54f411d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65993d5a-b5f8-4578-b285-e63e6bdcc36e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2136d560-e522-4f3a-9828-e67211d9fc77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 12859\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 24\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1608\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1608' max='1608' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1608/1608 21:06, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.390700</td>\n",
       "      <td>0.628927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.384600</td>\n",
       "      <td>0.628927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.388100</td>\n",
       "      <td>0.628927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1429\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1429\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1429\n",
      "  Batch size = 24\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1608, training_loss=0.3878441734693537, metrics={'train_runtime': 1267.4907, 'train_samples_per_second': 30.436, 'train_steps_per_second': 1.269, 'total_flos': 1427035726725120.0, 'train_loss': 0.3878441734693537, 'epoch': 3.0})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"     #Disabling Wandb\n",
    "#model.resize_token_embeddings(len(tokenizer))\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "20205c3b-6918-4777-ad9f-e5a62d091c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to t5_gec_hindi_muRIL_best_Full\n",
      "Configuration saved in t5_gec_hindi_muRIL_best_Full/config.json\n",
      "Model weights saved in t5_gec_hindi_muRIL_best_Full/pytorch_model.bin\n",
      "tokenizer config file saved in t5_gec_hindi_muRIL_best_Full/tokenizer_config.json\n",
      "Special tokens file saved in t5_gec_hindi_muRIL_best_Full/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "#Save the trained Model\n",
    "trainer.save_model('t5_gec_hindi_muRIL_best_Full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba66188d-fed4-4bb9-9c41-23f8fc3d63c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5229eac7-5a16-4eb4-be00-c3f7ee5a9c1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cea8f05e-4128-4723-90ee-ae9e2ff96afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 2333596\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 24\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 97234\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='97234' max='97234' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [97234/97234 21:34:31, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.113900</td>\n",
       "      <td>0.088758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to models/hindi/T5_muRIL_Full/checkpoint-30000\n",
      "Configuration saved in models/hindi/T5_muRIL_Full/checkpoint-30000/config.json\n",
      "Model weights saved in models/hindi/T5_muRIL_Full/checkpoint-30000/pytorch_model.bin\n",
      "tokenizer config file saved in models/hindi/T5_muRIL_Full/checkpoint-30000/tokenizer_config.json\n",
      "Special tokens file saved in models/hindi/T5_muRIL_Full/checkpoint-30000/special_tokens_map.json\n",
      "Saving model checkpoint to models/hindi/T5_muRIL_Full/checkpoint-60000\n",
      "Configuration saved in models/hindi/T5_muRIL_Full/checkpoint-60000/config.json\n",
      "Model weights saved in models/hindi/T5_muRIL_Full/checkpoint-60000/pytorch_model.bin\n",
      "tokenizer config file saved in models/hindi/T5_muRIL_Full/checkpoint-60000/tokenizer_config.json\n",
      "Special tokens file saved in models/hindi/T5_muRIL_Full/checkpoint-60000/special_tokens_map.json\n",
      "Saving model checkpoint to models/hindi/T5_muRIL_Full/checkpoint-90000\n",
      "Configuration saved in models/hindi/T5_muRIL_Full/checkpoint-90000/config.json\n",
      "Model weights saved in models/hindi/T5_muRIL_Full/checkpoint-90000/pytorch_model.bin\n",
      "tokenizer config file saved in models/hindi/T5_muRIL_Full/checkpoint-90000/tokenizer_config.json\n",
      "Special tokens file saved in models/hindi/T5_muRIL_Full/checkpoint-90000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 259289\n",
      "  Batch size = 24\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=97234, training_loss=2.108593665541063, metrics={'train_runtime': 77686.3981, 'train_samples_per_second': 30.039, 'train_steps_per_second': 1.252, 'total_flos': 9.332473302411264e+16, 'train_loss': 2.108593665541063, 'epoch': 1.0})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"     #Disabling Wandb\n",
    "#model.resize_token_embeddings(len(tokenizer))\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0e7a11-1f66-4cfd-9a41-8cdefe7ea3aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ccc43f08-6d80-442d-83c5-543aac70e9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 2333596\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 24\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 97234\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='97234' max='97234' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [97234/97234 21:29:41, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.070400</td>\n",
       "      <td>0.059936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 259289\n",
      "  Batch size = 24\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=97234, training_loss=0.7156300433809912, metrics={'train_runtime': 77398.8282, 'train_samples_per_second': 30.15, 'train_steps_per_second': 1.256, 'total_flos': 9.332804423264256e+16, 'train_loss': 0.7156300433809912, 'epoch': 1.0})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"     #Disabling Wandb\n",
    "#model.resize_token_embeddings(len(tokenizer))\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aaaea036-afff-4988-b9c3-605dace1b50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 450000\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 24\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18750\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18750' max='18750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18750/18750 4:06:38, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.132100</td>\n",
       "      <td>0.107768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 24\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=18750, training_loss=0.6001573170979818, metrics={'train_runtime': 14814.4253, 'train_samples_per_second': 30.376, 'train_steps_per_second': 1.266, 'total_flos': 1.799350678020096e+16, 'train_loss': 0.6001573170979818, 'epoch': 1.0})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Wandb API Key: bcdbdd5ee9d76a20c90b5f2a246eb45f14b341a9\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"     #Disabling Wandb\n",
    "#model.resize_token_embeddings(len(tokenizer))\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f4ed8776-52ca-4d06-9e15-158994267915",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch_device = 'cuda' if torch.cuda.is_available() else 'cpu' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b68254c3-619e-464f-bfa6-01c21279c6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to t5_gec_hindi_muRIL_best\n",
      "Configuration saved in t5_gec_hindi_muRIL_best/config.json\n",
      "Model weights saved in t5_gec_hindi_muRIL_best/pytorch_model.bin\n",
      "tokenizer config file saved in t5_gec_hindi_muRIL_best/tokenizer_config.json\n",
      "Special tokens file saved in t5_gec_hindi_muRIL_best/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "#Save the trained Model\n",
    "trainer.save_model('t5_gec_hindi_muRIL_best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "627b9bd5-acdd-4728-8bb5-8ac6bb809b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to t5_gec_hindi_muRIL_best\n",
      "Configuration saved in t5_gec_hindi_muRIL_best/config.json\n",
      "Model weights saved in t5_gec_hindi_muRIL_best/pytorch_model.bin\n",
      "tokenizer config file saved in t5_gec_hindi_muRIL_best/tokenizer_config.json\n",
      "Special tokens file saved in t5_gec_hindi_muRIL_best/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "#Save the trained Model\n",
    "trainer.save_model('t5_gec_hindi_muRIL_best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa6e472-f983-4018-97ea-fd020ae3ea39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!zip -r 't5_gec_hindi_muRIL_2.zip' 't5_gec_hindi_muRIL_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3895631b-8f35-4ea2-930f-ef9c56e17072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained\n"
     ]
    }
   ],
   "source": [
    "print(\"Trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da45d37b-cd1f-43e7-a4e2-bc18ef984b14",
   "metadata": {},
   "source": [
    "# Testing Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6ea2de44-6fbe-40a6-ba4f-f074a82b6767",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /DATA/gupta92/.cache/huggingface/hub/models--google--muril-base-cased/snapshots/afd9f36c7923d54e97903922ff1b260d091d202f/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"google/muril-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.22.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 197285\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at /DATA/gupta92/.cache/huggingface/hub/models--google--muril-base-cased/snapshots/afd9f36c7923d54e97903922ff1b260d091d202f/vocab.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /DATA/gupta92/.cache/huggingface/hub/models--google--muril-base-cased/snapshots/afd9f36c7923d54e97903922ff1b260d091d202f/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /DATA/gupta92/.cache/huggingface/hub/models--google--muril-base-cased/snapshots/afd9f36c7923d54e97903922ff1b260d091d202f/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /DATA/gupta92/.cache/huggingface/hub/models--google--muril-base-cased/snapshots/afd9f36c7923d54e97903922ff1b260d091d202f/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"google/muril-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.22.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 197285\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /DATA/gupta92/.cache/huggingface/hub/models--google--muril-base-cased/snapshots/afd9f36c7923d54e97903922ff1b260d091d202f/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"google/muril-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.22.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 197285\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Testing\n",
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration,AutoTokenizer\n",
    "#model_name = 't5_gec_hindi_muRIL'\n",
    "#model_name = 't5_gec_hindi_muRIL_best'\n",
    "model_name = 't5_gec_hindi_muRIL_best_Full'\n",
    "torch_device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/muril-base-cased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "98143e4e-6280-4ab1-96a5-2be73cad8d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file t5_gec_hindi_muRIL_best_Full/config.json\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"t5_gec_hindi_muRIL_best_Full\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 3072,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.22.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 197285\n",
      "}\n",
      "\n",
      "loading weights file t5_gec_hindi_muRIL_best_Full/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
      "\n",
      "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at t5_gec_hindi_muRIL_best_Full.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "#tokenizer = AutoTokenizer.from_pretrained(\"surajp/RoBERTa-hindi-guj-san\")\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"google/muril-base-cased\")\n",
    "trained_model = T5ForConditionalGeneration.from_pretrained(model_name).to(torch_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7dee6d65-83bc-4bb6-bdbc-8511c6becea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cde5ea1c-2854-458b-bd0e-288c372d6768",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: continue\n",
    "        param = parameter.numel()\n",
    "        table.add_row([name, param])\n",
    "        total_params+=param\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params\n",
    "\n",
    "#count_parameters(trained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b6e20830-2f49-4050-b1cd-67ebdb5a4534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size: 1334.168MB\n"
     ]
    }
   ],
   "source": [
    "param_size = 0\n",
    "for param in trained_model.parameters():\n",
    "    param_size += param.nelement() * param.element_size()\n",
    "buffer_size = 0\n",
    "for buffer in trained_model.buffers():\n",
    "    buffer_size += buffer.nelement() * buffer.element_size()\n",
    "\n",
    "size_all_mb = (param_size + buffer_size) / 1024**2\n",
    "print('model size: {:.3f}MB'.format(size_all_mb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9669013c-f34f-44b1-a35c-f265f106a427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_grammar(input_text,num_return_sequences):\n",
    "    #batch = tokenizer([input_text],truncation=True,padding='max_length',max_length=64, return_tensors=\"pt\").to(torch_device)\n",
    "    batch = tokenizer([input_text],truncation=True,padding='max_length',max_length=64, return_tensors=\"pt\",return_token_type_ids=False).to(device)\n",
    "    #print(batch)\n",
    "    #translated = model1.generate(**batch,max_length=64,num_beams=4, num_return_sequences=num_return_sequences, temperature=1.5)\n",
    "    max_len =  train_df.input.str.len().max()\n",
    "    #translated= trained_model.generate(**batch,max_length=64,num_beams=4, num_return_sequences=num_return_sequences, temperature=1.5)\n",
    "    translated= trained_model.generate(**batch,max_length=max_len,num_beams=4, num_return_sequences=num_return_sequences, temperature=1.5)\n",
    "    \n",
    "    \n",
    "    #print(\"here\")\n",
    "    tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "    return tgt_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b786ccc2-8dea-4c4d-b60c-c242ef187a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(T5ForConditionalGeneration.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b28c83a6-7420-49d1-a2c1-369c78b33644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Sentence: नागरमोथा की जड़ में कसेरू की भांति एक कन्द निकलता है जिसे नागरमोथा कहते हैं.\n",
      "Correct Seentence: नागरमोथा की जड़ में कसेरू की भांति एक कन्द निकलता हैं जिसे नागरमोथा कहते हैं.\n",
      "Predicted Sentence: नागरमोथा के जड़ में कसेरू की भांति एक कन्द निकलता है जिसे नागरमोथा कहते हैं. \n"
     ]
    }
   ],
   "source": [
    "text = test_df['input'].iat[200]\n",
    "correct = test_df['output'].iat[200]\n",
    "print(\"Incorrect Sentence:\", text)\n",
    "print(\"Correct Seentence:\",correct)\n",
    "l = len(correct)\n",
    "predicted_s = correct_grammar(text, num_return_sequences=4)[0]\n",
    "p = len(predicted_s)\n",
    "\n",
    "if(p>l):\n",
    "    predicted_s = predicted_s[:l]\n",
    "elif (p<l-4):\n",
    "    predicted_s = text\n",
    "print(\"Predicted Sentence:\",predicted_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d83c4e-4a3f-4cfd-bbb6-0d2d457e825a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2dc10f7d-909a-4d2b-917a-475e43619610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Sentence: यह शहर मलक्का जलसन्धि पर बसा हुआ हैं.\n",
      "Correct Seentence: यह शहर मलक्का जलसन्धि पर बसा हुआ है.\n",
      "Predicted Sentence: यह शहर मलक्का जलसन्धि पर बसा हुआ है.\n"
     ]
    }
   ],
   "source": [
    "text = test_df['input'].iat[0]\n",
    "correct = test_df['output'].iat[0]\n",
    "print(\"Incorrect Sentence:\", text)\n",
    "print(\"Correct Seentence:\",correct)\n",
    "l = len(correct)\n",
    "predicted_s = correct_grammar(text, num_return_sequences=4)[0]\n",
    "p = len(predicted_s)\n",
    "\n",
    "if(p>l):\n",
    "    predicted_s = predicted_s[:l]\n",
    "elif (p<l-4):\n",
    "    predicted_s = text\n",
    "print(\"Predicted Sentence:\",predicted_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "33497c92-ccc5-4eba-89d9-004161a5e100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Sentence: दरभंगा, बिहार के एक प्रखण्ड.\n",
      "Correct Seentence: दरभंगा, बिहार का एक प्रखण्ड.\n",
      "Predicted Sentence: दरभंगा, बिहार का एक प्रखण्ड.\n"
     ]
    }
   ],
   "source": [
    "text = test_df['input'].iat[0]\n",
    "correct = test_df['output'].iat[0]\n",
    "print(\"Incorrect Sentence:\", text)\n",
    "print(\"Correct Seentence:\",correct)\n",
    "l = len(correct)\n",
    "predicted_s = correct_grammar(text, num_return_sequences=2)[0]\n",
    "p = len(predicted_s)\n",
    "\n",
    "if(p>l):\n",
    "    predicted_s = predicted_s[:l]\n",
    "elif (p<l-4):\n",
    "    predicted_s = text\n",
    "\n",
    "\n",
    "print(\"Predicted Sentence:\",predicted_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e27fa025-97be-48b8-8e96-c59cbbd23fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Sentence: अन् ‍ त पुर को लै गईं, जहां न दूजो जाय.\n",
      "Correct Seentence: अन् ‍ त पुर को लै गए, जहां न दूजो जाय.\n",
      "Predicted Sentence: अन् त पुर को लै गया, जहां न दूजो जाय. \n"
     ]
    }
   ],
   "source": [
    "text = test_df['input'].iat[100]\n",
    "correct = test_df['output'].iat[100]\n",
    "print(\"Incorrect Sentence:\", text)\n",
    "print(\"Correct Seentence:\",correct)\n",
    "l = len(correct)\n",
    "predicted_s = correct_grammar(text, num_return_sequences=2)[0]\n",
    "p = len(predicted_s)\n",
    "\n",
    "if(p>l):\n",
    "    predicted_s = predicted_s[:l]\n",
    "elif (p<l-4):\n",
    "    predicted_s = text\n",
    "\n",
    "\n",
    "print(\"Predicted Sentence:\",predicted_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f827ca3-b021-48c6-9d2f-caa01399511b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2021e0-7fe0-4db1-a0b5-db088775cbdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3f8b0823-1f45-41f2-a239-c4b724f58309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Sentence: अंतर केवल इतना ही है कि थोड़े स्थान में सभी सुविधाएं प्रदान करने का प्रयास कीं जाता है.\n",
      "Correct Seentence: अंतर केवल इतना ही है कि थोड़े स्थान में सभी सुविधाएं प्रदान करने का प्रयास किया जाता है.\n",
      "Predicted Sentence: अंतर केवल इतना ही है कि थोड़े स्थान में सभी सुविधाएं प्रदान करने का प्रयास किया जाता है.\n"
     ]
    }
   ],
   "source": [
    "text = test_df['input'].iat[43]\n",
    "correct = test_df['output'].iat[43]\n",
    "print(\"Incorrect Sentence:\", text)\n",
    "print(\"Correct Seentence:\",correct)\n",
    "p = len(predicted_s)\n",
    "l = len(correct)\n",
    "predicted_s = correct_grammar(text, num_return_sequences=2)[0]\n",
    "p = len(predicted_s)\n",
    "if(p>l):\n",
    "    predicted_s = predicted_s[:l]\n",
    "\n",
    "print(\"Predicted Sentence:\",predicted_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "79771c80-b79f-4ac2-8086-4eb0a0d82051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Sentence: दिल्ली का गुर्जरों ने मालगुजारी बहादुरशाह जफर मुगल बादशाह को देनी शुरू कर दी थी.\n",
      "Correct Seentence: दिल्ली के गुर्जरों ने मालगुजारी बहादुरशाह जफर मुगल बादशाह को देनी शुरू कर दी थी.\n",
      "Predicted Sentence: दिल्ली के गुर्जरों ने मालगुजारी बहादुरशाह जफर मुगल बादशाह को देना शुरू कर दी थी.\n"
     ]
    }
   ],
   "source": [
    "text = test_df['input'].iat[1]\n",
    "correct = test_df['output'].iat[1]\n",
    "print(\"Incorrect Sentence:\", text)\n",
    "print(\"Correct Seentence:\",correct)\n",
    "p = len(predicted_s)\n",
    "l = len(correct)\n",
    "predicted_s = correct_grammar(text, num_return_sequences=4)[0][:l]\n",
    "print(\"Predicted Sentence:\",predicted_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a3c96d0d-6d65-42bc-8faa-30a3b931c57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Sentence: वे ऐसी पहली राष्ट्रदेवी हैं, जिनकी मातृभाषा अंग्रेज़ी नहीं है.\n",
      "Correct Seentence: वे ऐसी पहली राष्ट्रदेवी है, जिनकी मातृभाषा अंग्रेज़ी नहीं है.\n",
      "Predicted Sentence: वे ऐसी पहली राष्ट्रदेवी हैं, जिनकी मातृभाषा अंग्रेज़ी नहीं है\n"
     ]
    }
   ],
   "source": [
    "text = test_df['input'].iat[50]\n",
    "correct = test_df['output'].iat[50]\n",
    "print(\"Incorrect Sentence:\", text)\n",
    "print(\"Correct Seentence:\",correct)\n",
    "predicted_s = correct_grammar(text, num_return_sequences=1)[0]\n",
    "l = len(correct)\n",
    "p = len(predicted_s)\n",
    "if(p>l):\n",
    "    predicted_s = predicted_s[:l]\n",
    "\n",
    "print(\"Predicted Sentence:\",predicted_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9f05b016-c983-4167-a2f7-c5f1736de779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Sentence: मराक गुरसुता  10 दिसंबर 1945 09 अक्टूबर 2006  पोलैंडी गायक, संगीतकार, कवि और चित्रकार था.\n",
      "Correct Seentence: मराक गुरसुता  10 दिसंबर 1945 09 अक्टूबर 2006  पोलैंडी गायक, संगीतकार, कवि और चित्रकार हैं.\n",
      "Predicted Sentence: मराक गुरसुता 10 दिसंबर 1945 09 अक्टूबर 2006 पोलैंडी गायक, संगीतकार, कवि और चित्रकार थे.\n"
     ]
    }
   ],
   "source": [
    "text = test_df['input'].iat[60]\n",
    "correct = test_df['output'].iat[60]\n",
    "print(\"Incorrect Sentence:\", text)\n",
    "print(\"Correct Seentence:\",correct)\n",
    "predicted_s = correct_grammar(text, num_return_sequences=1)[0]\n",
    "l = len(correct)\n",
    "p = len(predicted_s)\n",
    "if(p>l):\n",
    "    predicted_s = predicted_s[:l]\n",
    "print(\"Predicted Sentence:\",predicted_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7cf190-899c-4fc6-9954-59ba79ef6614",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d488748e-8345-4b94-baf3-84925a29ba2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Sentence: आज हम आपको हार्दिक पांड्या की ऐसी 5 बाते बताने जा रहे है जिन्हें आप शायद ही जानते होंगे.\n",
      "Correct Seentence: आज हम आपको हार्दिक पांड्या की ऐसी 5 बाते बताने जा रहे हैं जिन्हें आप शायद ही जानते होंगे.\n",
      "Predicted Sentence: आज हम आपको हार्दिक पांड्या की ऐसी 5 बाते बताने जा रहे हैं जिन्हें आप शायद ही जानते होंगे.\n"
     ]
    }
   ],
   "source": [
    "text = test_df['input'].iat[51]\n",
    "correct = test_df['output'].iat[51]\n",
    "print(\"Incorrect Sentence:\", text)\n",
    "print(\"Correct Seentence:\",correct)\n",
    "predicted_s = correct_grammar(text, num_return_sequences=1)[0]\n",
    "print(\"Predicted Sentence:\",predicted_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a2adc94a-4fc3-4eb6-b336-574d99c230eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Sentence: प्रारंभिक जीवन और परिवार के इतिहास.\n",
      "Correct Seentence: प्रारंभिक जीवन और परिवार का इतिहास.\n",
      "Predicted Sentence: प्रारंभिक जीवन और परिवार की इतिहास.\n"
     ]
    }
   ],
   "source": [
    "text = test_df['input'].iat[20]\n",
    "correct = test_df['output'].iat[20]\n",
    "print(\"Incorrect Sentence:\", text)\n",
    "print(\"Correct Seentence:\",correct)\n",
    "predicted_s = correct_grammar(text, num_return_sequences=1)[0]\n",
    "p=len(predicted_s)\n",
    "l = len(text)\n",
    "if(p>l):\n",
    "    predicted_s = predicted_s[:l]\n",
    "print(\"Predicted Sentence:\",predicted_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b37d9f-25df-483f-a3c3-29603e854408",
   "metadata": {},
   "source": [
    "# Performance Analysis\n",
    "1. BLEU Score\n",
    "2. GLEU Score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "18317b87-03d3-4d73-ae22-9cf8cb8e1db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(259289, 3)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "da058ef4-524c-4808-a1ba-bbd143f534d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>input_token_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>677358</th>\n",
       "      <td>अब किशन अपने भाई का बदला लेने की सोचता है, पर कई ओर से घिरी भी होता है.</td>\n",
       "      <td>अब किशन अपने भाई का बदला लेने की सोचता है, पर कई ओर से घिरा भी होता है.</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2028550</th>\n",
       "      <td>इसे इल्देजिज़ के दोनों पुत्रों मुहम्मद और किज़िल अरसतन को समर्पित कीं गया था.</td>\n",
       "      <td>इसे इल्देजिज़ के दोनों पुत्रों मुहम्मद और किज़िल अरसतन को समर्पित किया गया था.</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328281</th>\n",
       "      <td>शव को डेढ़ लाख लोगों ने जुलूस निकाल कर पूरे शहर में घुमाते हुए राप्ती नदी के किनारे राजघाट पर उसका अन्तिम संस्कार कर दी.</td>\n",
       "      <td>शव को डेढ़ लाख लोगों ने जुलूस निकाल कर पूरे शहर में घुमाते हुए राप्ती नदी के किनारे राजघाट पर उसका अन्तिम संस्कार कर दिया.</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188804</th>\n",
       "      <td>सूखी महीनों या वर्षों तक रह सकता है, और इसे 15 दिनों के बाद घोषित किया जा सकता है.</td>\n",
       "      <td>सूखा महीनों या वर्षों तक रह सकता है, और इसे 15 दिनों के बाद घोषित किया जा सकता है.</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2513989</th>\n",
       "      <td>भांडुप मुंबई की एक उपनगर है.</td>\n",
       "      <td>भांडुप मुंबई का एक उपनगर है.</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                            input  \\\n",
       "677358                                                    अब किशन अपने भाई का बदला लेने की सोचता है, पर कई ओर से घिरी भी होता है.   \n",
       "2028550                                             इसे इल्देजिज़ के दोनों पुत्रों मुहम्मद और किज़िल अरसतन को समर्पित कीं गया था.   \n",
       "328281   शव को डेढ़ लाख लोगों ने जुलूस निकाल कर पूरे शहर में घुमाते हुए राप्ती नदी के किनारे राजघाट पर उसका अन्तिम संस्कार कर दी.   \n",
       "188804                                         सूखी महीनों या वर्षों तक रह सकता है, और इसे 15 दिनों के बाद घोषित किया जा सकता है.   \n",
       "2513989                                                                                              भांडुप मुंबई की एक उपनगर है.   \n",
       "\n",
       "                                                                                                                             output  \\\n",
       "677358                                                      अब किशन अपने भाई का बदला लेने की सोचता है, पर कई ओर से घिरा भी होता है.   \n",
       "2028550                                              इसे इल्देजिज़ के दोनों पुत्रों मुहम्मद और किज़िल अरसतन को समर्पित किया गया था.   \n",
       "328281   शव को डेढ़ लाख लोगों ने जुलूस निकाल कर पूरे शहर में घुमाते हुए राप्ती नदी के किनारे राजघाट पर उसका अन्तिम संस्कार कर दिया.   \n",
       "188804                                           सूखा महीनों या वर्षों तक रह सकता है, और इसे 15 दिनों के बाद घोषित किया जा सकता है.   \n",
       "2513989                                                                                                भांडुप मुंबई का एक उपनगर है.   \n",
       "\n",
       "         input_token_len  \n",
       "677358                23  \n",
       "2028550               24  \n",
       "328281                31  \n",
       "188804                23  \n",
       "2513989               11  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a70f87cd-f789-4070-898d-25f6937deb4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>input_token_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>677358</th>\n",
       "      <td>अब किशन अपने भाई का बदला लेने की सोचता है, पर कई ओर से घिरी भी होता है.</td>\n",
       "      <td>अब किशन अपने भाई का बदला लेने की सोचता है, पर कई ओर से घिरा भी होता है.</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2028550</th>\n",
       "      <td>इसे इल्देजिज़ के दोनों पुत्रों मुहम्मद और किज़िल अरसतन को समर्पित कीं गया था.</td>\n",
       "      <td>इसे इल्देजिज़ के दोनों पुत्रों मुहम्मद और किज़िल अरसतन को समर्पित किया गया था.</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328281</th>\n",
       "      <td>शव को डेढ़ लाख लोगों ने जुलूस निकाल कर पूरे शहर में घुमाते हुए राप्ती नदी के किनारे राजघाट पर उसका अन्तिम संस्कार कर दी.</td>\n",
       "      <td>शव को डेढ़ लाख लोगों ने जुलूस निकाल कर पूरे शहर में घुमाते हुए राप्ती नदी के किनारे राजघाट पर उसका अन्तिम संस्कार कर दिया.</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188804</th>\n",
       "      <td>सूखी महीनों या वर्षों तक रह सकता है, और इसे 15 दिनों के बाद घोषित किया जा सकता है.</td>\n",
       "      <td>सूखा महीनों या वर्षों तक रह सकता है, और इसे 15 दिनों के बाद घोषित किया जा सकता है.</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2513989</th>\n",
       "      <td>भांडुप मुंबई की एक उपनगर है.</td>\n",
       "      <td>भांडुप मुंबई का एक उपनगर है.</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2405409</th>\n",
       "      <td>आचार्य धर्मपाल नालंदा महाविहार के कुलपति थे जिनका शिष्य शीलभद्र ह्वेन्त्सांग को महायान के प्रमुख ग्रंथों का अध्यापन कराया था.</td>\n",
       "      <td>आचार्य धर्मपाल नालंदा महाविहार के कुलपति थे जिनके शिष्य शीलभद्र ह्वेन्त्सांग को महायान के प्रमुख ग्रंथों का अध्यापन कराया था.</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985351</th>\n",
       "      <td>औरतें तीज और करवी चौथ की जगह स्वतंत्रता दिवस और गणतंत्रता दिवस का आनंद लेगी.</td>\n",
       "      <td>औरतें तीज और करवा चौथ की जगह स्वतंत्रता दिवस और गणतंत्रता दिवस का आनंद लेगी.</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911740</th>\n",
       "      <td>एकदरबेला नेपाल के जनकपुर अंचल का महोत्तरी जिला के एक गांव विकास समिति है.</td>\n",
       "      <td>एकदरबेला नेपाल के जनकपुर अंचल का महोत्तरी जिला का एक गांव विकास समिति है.</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621202</th>\n",
       "      <td>यहां रहने वाले कई जीवों में जीवदीप्ति भी देखी जाती हैं.</td>\n",
       "      <td>यहां रहने वाले कई जीवों में जीवदीप्ति भी देखी जाती है.</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068003</th>\n",
       "      <td>लोअर गंगा अब भी बहुत महत्वपूर्ण हैं, और सभी वर्ष दौर में यातायात है.</td>\n",
       "      <td>लोअर गंगा अब भी बहुत महत्वपूर्ण है, और सभी वर्ष दौर में यातायात है.</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>259289 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                 input  \\\n",
       "677358                                                         अब किशन अपने भाई का बदला लेने की सोचता है, पर कई ओर से घिरी भी होता है.   \n",
       "2028550                                                  इसे इल्देजिज़ के दोनों पुत्रों मुहम्मद और किज़िल अरसतन को समर्पित कीं गया था.   \n",
       "328281        शव को डेढ़ लाख लोगों ने जुलूस निकाल कर पूरे शहर में घुमाते हुए राप्ती नदी के किनारे राजघाट पर उसका अन्तिम संस्कार कर दी.   \n",
       "188804                                              सूखी महीनों या वर्षों तक रह सकता है, और इसे 15 दिनों के बाद घोषित किया जा सकता है.   \n",
       "2513989                                                                                                   भांडुप मुंबई की एक उपनगर है.   \n",
       "...                                                                                                                                ...   \n",
       "2405409  आचार्य धर्मपाल नालंदा महाविहार के कुलपति थे जिनका शिष्य शीलभद्र ह्वेन्त्सांग को महायान के प्रमुख ग्रंथों का अध्यापन कराया था.   \n",
       "985351                                                    औरतें तीज और करवी चौथ की जगह स्वतंत्रता दिवस और गणतंत्रता दिवस का आनंद लेगी.   \n",
       "1911740                                                      एकदरबेला नेपाल के जनकपुर अंचल का महोत्तरी जिला के एक गांव विकास समिति है.   \n",
       "621202                                                                         यहां रहने वाले कई जीवों में जीवदीप्ति भी देखी जाती हैं.   \n",
       "2068003                                                           लोअर गंगा अब भी बहुत महत्वपूर्ण हैं, और सभी वर्ष दौर में यातायात है.   \n",
       "\n",
       "                                                                                                                                output  \\\n",
       "677358                                                         अब किशन अपने भाई का बदला लेने की सोचता है, पर कई ओर से घिरा भी होता है.   \n",
       "2028550                                                 इसे इल्देजिज़ के दोनों पुत्रों मुहम्मद और किज़िल अरसतन को समर्पित किया गया था.   \n",
       "328281      शव को डेढ़ लाख लोगों ने जुलूस निकाल कर पूरे शहर में घुमाते हुए राप्ती नदी के किनारे राजघाट पर उसका अन्तिम संस्कार कर दिया.   \n",
       "188804                                              सूखा महीनों या वर्षों तक रह सकता है, और इसे 15 दिनों के बाद घोषित किया जा सकता है.   \n",
       "2513989                                                                                                   भांडुप मुंबई का एक उपनगर है.   \n",
       "...                                                                                                                                ...   \n",
       "2405409  आचार्य धर्मपाल नालंदा महाविहार के कुलपति थे जिनके शिष्य शीलभद्र ह्वेन्त्सांग को महायान के प्रमुख ग्रंथों का अध्यापन कराया था.   \n",
       "985351                                                    औरतें तीज और करवा चौथ की जगह स्वतंत्रता दिवस और गणतंत्रता दिवस का आनंद लेगी.   \n",
       "1911740                                                      एकदरबेला नेपाल के जनकपुर अंचल का महोत्तरी जिला का एक गांव विकास समिति है.   \n",
       "621202                                                                          यहां रहने वाले कई जीवों में जीवदीप्ति भी देखी जाती है.   \n",
       "2068003                                                            लोअर गंगा अब भी बहुत महत्वपूर्ण है, और सभी वर्ष दौर में यातायात है.   \n",
       "\n",
       "         input_token_len  \n",
       "677358                23  \n",
       "2028550               24  \n",
       "328281                31  \n",
       "188804                23  \n",
       "2513989               11  \n",
       "...                  ...  \n",
       "2405409               30  \n",
       "985351                20  \n",
       "1911740               19  \n",
       "621202                16  \n",
       "2068003               18  \n",
       "\n",
       "[259289 rows x 3 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676fdee8-3408-49be-a09a-f466f9599502",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "acc0b282-2efa-4674-9c26-7c282fc86759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:04,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [04:22,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  100  data point 0.9157751050731273\n",
      "GELU Score =  0.9157751050731273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.gleu_score import sentence_gleu\n",
    "GLEU_val_emb = []\n",
    "test_data = test_df.head(100)\n",
    "print(test_data.shape)\n",
    "#print(\"here\")\n",
    "itr = 0\n",
    "for ind,i in tqdm(test_data.iterrows(),position=0):\n",
    "    try:\n",
    "        #print(ind,i)\n",
    "        itr+=1\n",
    "        text = str(i.input)\n",
    "        #print(text)\n",
    "        #pred = predict(str(i.enc_input),model)[0].split()\n",
    "        pred = correct_grammar(text, num_return_sequences=1)[0]\n",
    "        l = len(text)\n",
    "        p = len(pred)\n",
    "        if(p>l):\n",
    "            pred = pred[:l]\n",
    "            \n",
    "        act = [str(i.output).split()]\n",
    "        pred_s = str(pred).split()\n",
    "        b = sentence_gleu(act,pred_s)\n",
    "        GLEU_val_emb.append(b)\n",
    "        if(itr%100 ==0):\n",
    "            print(\"GELU Score for \",itr,\" data point\",np.mean(GLEU_val_emb))\n",
    "    except:\n",
    "        print(\"Error\") \n",
    "        continue\n",
    "print(\"GELU Score = \",np.mean(GLEU_val_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2130e4-b422-40d3-be84-730ada29c6a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a435a7a2-f401-4454-bbb9-eef3ea7dace1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "47644d73-5446-4f03-a811-e22af050f85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [02:39,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  100  data point 0.9369473923868874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [05:21,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  200  data point 0.9203796555842938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "300it [08:04,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  300  data point 0.9054771818357039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400it [10:47,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  400  data point 0.9113628405396466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [13:28,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  500  data point 0.908630569472634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "600it [16:08,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  600  data point 0.9102320813490103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "700it [18:49,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  700  data point 0.9118186679206834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "800it [21:30,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  800  data point 0.9100877590947873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "900it [24:12,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  900  data point 0.9116741504812822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [26:55,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  1000  data point 0.9137746486265554\n",
      "GELU Score =  0.9137746486265554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.gleu_score import sentence_gleu\n",
    "GLEU_val_emb = []\n",
    "test_data = test_df.head(100)\n",
    "print(test_data.shape)\n",
    "#print(\"here\")\n",
    "itr = 0\n",
    "for ind,i in tqdm(test_data.iterrows(),position=0):\n",
    "    try:\n",
    "        #print(ind,i)\n",
    "        itr+=1\n",
    "        text = str(i.input)\n",
    "        #print(text)\n",
    "        #pred = predict(str(i.enc_input),model)[0].split()\n",
    "        pred = correct_grammar(text, num_return_sequences=1)[0]\n",
    "        l = len(text)\n",
    "        p = len(pred)\n",
    "        if(p>l):\n",
    "            pred = pred[:l]\n",
    "            \n",
    "        act = [str(i.output).split()]\n",
    "        pred_s = str(pred).split()\n",
    "        b = sentence_gleu(act,pred_s)\n",
    "        GLEU_val_emb.append(b)\n",
    "        if(itr%100 ==0):\n",
    "            print(\"GELU Score for \",itr,\" data point\",np.mean(GLEU_val_emb))\n",
    "    except:\n",
    "        print(\"Error\") \n",
    "        continue\n",
    "print(\"GELU Score = \",np.mean(GLEU_val_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4147c9-ef27-49bd-ace2-618bbfffe21a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d88fd148-1e9a-462c-87d1-ca731d01098c",
   "metadata": {},
   "source": [
    "# Evaluation on Etoori's Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c922895e-82d6-43db-a2c8-113bacd42372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_test = pd.read_csv('DATA/etoori_test.csv')\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab40e4eb-00a5-429e-a837-ed75ea61cc2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enc_input</th>\n",
       "      <th>dec_input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>इसके अलावा माइकल शूमाकर द्वारा चलाई गई एक फरार...</td>\n",
       "      <td>इसके अलावा माइकल शूमाकर द्वारा चलाई गई एक फरार...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>यह मन को काबू में करने वाली मुद्रा हैं इसीलिए ...</td>\n",
       "      <td>यह मन को काबू में करने वाली मुद्रा है इसीलिए इ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>आप पुस्तक पढ़ने में तल्लीन हैं और बच्चा उसनेाँ...</td>\n",
       "      <td>आप पुस्तक पढ़ने में तल्लीन हैं और बच्चा वहाँ प...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>परिवार के मुताबिक धमाकों में हिस्सा लेने वाले ...</td>\n",
       "      <td>परिवार के मुताबिक धमाकों में हिस्सा लेने वाले ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>उनकी वो वाली बात भी अनिश्चित रहती हैं ।</td>\n",
       "      <td>उनकी वो वाली बात भी अनिश्चित रहती है ।</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           enc_input  \\\n",
       "0  इसके अलावा माइकल शूमाकर द्वारा चलाई गई एक फरार...   \n",
       "1  यह मन को काबू में करने वाली मुद्रा हैं इसीलिए ...   \n",
       "2  आप पुस्तक पढ़ने में तल्लीन हैं और बच्चा उसनेाँ...   \n",
       "3  परिवार के मुताबिक धमाकों में हिस्सा लेने वाले ...   \n",
       "4            उनकी वो वाली बात भी अनिश्चित रहती हैं ।   \n",
       "\n",
       "                                           dec_input  \n",
       "0  इसके अलावा माइकल शूमाकर द्वारा चलाई गई एक फरार...  \n",
       "1  यह मन को काबू में करने वाली मुद्रा है इसीलिए इ...  \n",
       "2  आप पुस्तक पढ़ने में तल्लीन हैं और बच्चा वहाँ प...  \n",
       "3  परिवार के मुताबिक धमाकों में हिस्सा लेने वाले ...  \n",
       "4            उनकी वो वाली बात भी अनिश्चित रहती है ।   "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9216427e-77e4-4d58-a4c1-0fd582745e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Sentence: इसके अलावा माइकल शूमाकर द्वारा चलाई गई एक फरारी कार भी को मिलियन डॉलर क्लब में माना जा रहा है ।\n",
      "Correct Seentence: इसके अलावा माइकल शूमाकर द्वारा चलाई गई एक फरारी कार को भी मिलियन डॉलर क्लब में माना जा रहा है । \n",
      "Predicted Sentence: इसके अलावा माइकल शूमाकर द्वारा चलाई गई एक फरारी कार को भी मिलियन डॉलर क्लब में माना जा रहा है ।\n"
     ]
    }
   ],
   "source": [
    "text = df_test['enc_input'].iat[0]\n",
    "correct = df_test['dec_input'].iat[0]\n",
    "print(\"Incorrect Sentence:\", text)\n",
    "print(\"Correct Seentence:\",correct)\n",
    "predicted_s = correct_grammar(text, num_return_sequences=1)[0]\n",
    "l = len(correct)\n",
    "p = len(predicted_s)\n",
    "if(p>l):\n",
    "    predicted_s = predicted_s[:l]\n",
    "\n",
    "print(\"Predicted Sentence:\",predicted_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9eef891-a11f-47ae-9f15-17cf039ec8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Sentence: घर में घुस के बाद भी सुकून नहीं ।\n",
      "Correct Seentence: घर में घुसने के बाद भी सुकून नहीं । \n",
      "Predicted Sentence: घर में घुसने के बाद भी सुकून नहीं ।\n"
     ]
    }
   ],
   "source": [
    "text = df_test['enc_input'].iat[50]\n",
    "correct = df_test['dec_input'].iat[50]\n",
    "print(\"Incorrect Sentence:\", text)\n",
    "print(\"Correct Seentence:\",correct)\n",
    "predicted_s = correct_grammar(text, num_return_sequences=1)[0]\n",
    "l = len(correct)\n",
    "p = len(predicted_s)\n",
    "if(p>l):\n",
    "    predicted_s = predicted_s[:l]\n",
    "\n",
    "print(\"Predicted Sentence:\",predicted_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7fa5d601-9ba5-4961-8b1c-cb658cbcfdd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.26 s, sys: 84.4 ms, total: 1.34 s\n",
      "Wall time: 1.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predicted_s = correct_grammar(text, num_return_sequences=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d972ce-dab2-46ac-9de8-f0ffcfb53f85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ba007951-7c5e-4d99-8ca6-e9a4aa81d026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Sentence: यह मन को काबू में करने वाली मुद्रा हैं इसीलिए इसे चित्त हस्त मुद्रा योग कहते हैंं ।\n",
      "Correct Seentence: यह मन को काबू में करने वाली मुद्रा है इसीलिए इसे चित्त हस्त मुद्रा योग कहते हैं । \n",
      "Predicted Sentence: यह मन को काबू में करने वाली मुद्रा है इसीलिए इसे चित्त हस्त मुद्रा योग कहते हैं ।\n"
     ]
    }
   ],
   "source": [
    "text = df_test['enc_input'].iat[1]\n",
    "correct = df_test['dec_input'].iat[1]\n",
    "print(\"Incorrect Sentence:\", text)\n",
    "print(\"Correct Seentence:\",correct)\n",
    "predicted_s = correct_grammar(text, num_return_sequences=1)[0]\n",
    "l = len(correct)\n",
    "p = len(predicted_s)\n",
    "if(p>l):\n",
    "    predicted_s = predicted_s[:l]\n",
    "print(\"Predicted Sentence:\",predicted_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0b3169-ccf8-4ce1-adf8-4dd112c41f20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9c0c0e87-c89e-4143-bacf-d6fe15b9cca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Sentence: आप पुस्तक पढ़ने में तल्लीन हैं और बच्चा उसनेाँ पर शोर मचा रहा है ।\n",
      "Correct Seentence: आप पुस्तक पढ़ने में तल्लीन हैं और बच्चा वहाँ पर शोर मचा रहा है । \n",
      "Predicted Sentence: आप पुस्तक पढ़ने में तल्लीन हैं और बच्चा वहाँ पर शोर मचा रहा है ।\n"
     ]
    }
   ],
   "source": [
    "text = df_test['enc_input'].iat[2]\n",
    "correct = df_test['dec_input'].iat[2]\n",
    "print(\"Incorrect Sentence:\", text)\n",
    "print(\"Correct Seentence:\",correct)\n",
    "predicted_s = correct_grammar(text, num_return_sequences=1)[0]\n",
    "l = len(correct)\n",
    "p = len(predicted_s)\n",
    "if(p>l):\n",
    "    predicted_s = predicted_s[:l]\n",
    "print(\"Predicted Sentence:\",predicted_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6f233a47-440e-49b7-ba4f-b952be54da5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Sentence: परिवार के मुताबिक धमाकों में हिस्सा लेने वाले कोई दूसरे लोग थे और ये गलत पहचान का मामला हैं ।\n",
      "Correct Seentence: परिवार के मुताबिक धमाकों में हिस्सा लेने वाले कोई दूसरे लोग थे और ये गलत पहचान का मामला है । \n",
      "Predicted Sentence: परिवार के मुताबिक धमाकों में हिस्सा लेने वाले कोई दूसरे लोग थे और ये गलत पहचान का मामला है ।\n"
     ]
    }
   ],
   "source": [
    "text = df_test['enc_input'].iat[3]\n",
    "correct = df_test['dec_input'].iat[3]\n",
    "print(\"Incorrect Sentence:\", text)\n",
    "print(\"Correct Seentence:\",correct)\n",
    "predicted_s = correct_grammar(text, num_return_sequences=1)[0]\n",
    "l = len(correct)\n",
    "p = len(predicted_s)\n",
    "if(p>l):\n",
    "    predicted_s = predicted_s[:l]\n",
    "print(\"Predicted Sentence:\",predicted_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7ff4d00c-6d49-4e6e-b4f9-a765967fa1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Sentence: उनकी वो वाली बात भी अनिश्चित रहती हैं ।\n",
      "Correct Seentence: उनकी वो वाली बात भी अनिश्चित रहती है । \n",
      "Predicted Sentence: उनकी वो वाली बात भी अनिश्चित रहती है ।\n"
     ]
    }
   ],
   "source": [
    "text = df_test['enc_input'].iat[4]\n",
    "correct = df_test['dec_input'].iat[4]\n",
    "print(\"Incorrect Sentence:\", text)\n",
    "print(\"Correct Seentence:\",correct)\n",
    "predicted_s = correct_grammar(text, num_return_sequences=1)[0]\n",
    "l = len(correct)\n",
    "p = len(predicted_s)\n",
    "if(p>l):\n",
    "    predicted_s = predicted_s[:l]\n",
    "print(\"Predicted Sentence:\",predicted_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0ad90991-9465-4991-9562-bd6e88cfe5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Sentence: मैंने ललित हूँ ।\n",
      "Correct Seentence: मैं ललित हूँ । \n",
      "Predicted Sentence: मैं ललित हूँ । \n"
     ]
    }
   ],
   "source": [
    "text = df_test['enc_input'].iat[9]\n",
    "correct = df_test['dec_input'].iat[9]\n",
    "print(\"Incorrect Sentence:\", text)\n",
    "print(\"Correct Seentence:\",correct)\n",
    "predicted_s = correct_grammar(text, num_return_sequences=1)[0]\n",
    "l = len(correct)\n",
    "p = len(predicted_s)\n",
    "if(p>l):\n",
    "    predicted_s = predicted_s[:l]\n",
    "print(\"Predicted Sentence:\",predicted_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f63ceef-8b22-4af4-85b7-3b8ea69b275b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ffee1d-4065-4509-98cf-069cb233593b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf1c130-a68b-4bf1-86d9-d677f8ed9e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.translate.bleu_score as bleu\n",
    "BLEU = []\n",
    "index = []\n",
    "test_data = df_test.head(10000)\n",
    "np.random.seed(1)\n",
    "for ind,i in tqdm(test_data.iterrows(),position=0):\n",
    "    try:\n",
    "        text = str(i.enc_input)\n",
    "        #pred = predict(str(i.enc_input),model)[0].split()\n",
    "        pred = correct_grammar(text, num_return_sequences=1)[0]\n",
    "        act = [str(i.dec_input).split()]\n",
    "        pred_s = str(pred).split()\n",
    "        #print(act)\n",
    "        #print(pred_s)\n",
    "        b = bleu.sentence_bleu(act,pred_s)\n",
    "        BLEU.append(b)\n",
    "    except:\n",
    "        index.append(ind)\n",
    "        continue\n",
    "print(\"BELU = \", np.mean(BLEU))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cb825de7-9bcd-4d6e-8ba4-433f7ac00ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  1  data point 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [21:58,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  1001  data point 0.9150283140478553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2001it [42:44,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  2001  data point 0.9204379715628371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3001it [1:01:56,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  3001  data point 0.9182989341695741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4001it [1:20:27,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  4001  data point 0.9186494493296361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5001it [1:38:55,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  5001  data point 0.91909503414758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6001it [1:57:23,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  6001  data point 0.918329036146066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7001it [2:16:38,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  7001  data point 0.9192907337567936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8001it [2:35:05,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  8001  data point 0.9201028812376454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9001it [2:53:42,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  9001  data point 0.9205000001846352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [3:12:33,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score =  0.9208625332430048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.gleu_score import sentence_gleu\n",
    "GLEU_val_emb = []\n",
    "test_data = df_test.head(10000)\n",
    "print(test_data.shape)\n",
    "for ind,i in tqdm(test_data.iterrows(),position=0):\n",
    "    try:\n",
    "        text = str(i.enc_input)\n",
    "        #pred = predict(str(i.enc_input),model)[0].split()\n",
    "        pred = correct_grammar(text, num_return_sequences=1)[0]\n",
    "        l = len(text)\n",
    "        p = len(pred)\n",
    "        if(p>l):\n",
    "            pred = pred[:l]\n",
    "            \n",
    "        act = [str(i.dec_input).split()]\n",
    "        pred_s = str(pred).split()\n",
    "        b = sentence_gleu(act,pred_s)\n",
    "        GLEU_val_emb.append(b)\n",
    "        if(ind%1000 ==0):\n",
    "            print(\"GELU Score for \",ind+1,\" data point\",np.mean(GLEU_val_emb))\n",
    "    except:\n",
    "        continue\n",
    "print(\"GELU Score = \",np.mean(GLEU_val_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8f776a52-2f84-4b17-a268-62f049e9cc11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score =  0.9208625332430048\n"
     ]
    }
   ],
   "source": [
    "print(\"GELU Score = \",np.mean(GLEU_val_emb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b12e786-b7d7-4c70-8bce-592d1b146bcc",
   "metadata": {},
   "source": [
    "# Testing HiWikEd test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b3252f34-628a-4e12-9569-b81228062c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_test1 = pd.read_csv('DATA/HiWikEd.csv')\n",
    "df_test1.shape\n",
    "df_test1 = df_test1.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "875fa5f4-1261-42a1-a57e-021fe3debaf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enc_input</th>\n",
       "      <th>dec_input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>चाय की दुकान से लेकर वाहनों और दिवारों तक हर जगह विज्ञापन ही विज्ञापन दिखाई देते है.</td>\n",
       "      <td>चाय की दुकान से लेकर वाहनों और दिवारों तक हर जगह विज्ञापन ही विज्ञापन दिखाई देते हैं.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ये कहीं पे निगाहें, कही पे निशाना का सा अन्दाज है.</td>\n",
       "      <td>यह कहीं पे निगाहें, कही पे निशाना का सा अन्दाज है.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>आज हम विज्ञापन युग के सीमान्त पर आ खड़े हुए है.</td>\n",
       "      <td>आज हम विज्ञापन युग के सीमान्त पर आ खड़े हुए हैं.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>घर के बाहर पैर रखते ही हम विज्ञापन की दुनिया में घिर जाते है.</td>\n",
       "      <td>घर के बाहर पैर रखते ही हम विज्ञापन की दुनिया से घिर जाते है.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>वर्तमान समय में विज्ञापन के कोई रूप हमारे सामने आते है.</td>\n",
       "      <td>वर्तमान समय में विज्ञापन के कई रूप हमारे सामने आते है.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                              enc_input  \\\n",
       "0  चाय की दुकान से लेकर वाहनों और दिवारों तक हर जगह विज्ञापन ही विज्ञापन दिखाई देते है.   \n",
       "1                                    ये कहीं पे निगाहें, कही पे निशाना का सा अन्दाज है.   \n",
       "2                                       आज हम विज्ञापन युग के सीमान्त पर आ खड़े हुए है.   \n",
       "3                         घर के बाहर पैर रखते ही हम विज्ञापन की दुनिया में घिर जाते है.   \n",
       "4                               वर्तमान समय में विज्ञापन के कोई रूप हमारे सामने आते है.   \n",
       "\n",
       "                                                                               dec_input  \n",
       "0  चाय की दुकान से लेकर वाहनों और दिवारों तक हर जगह विज्ञापन ही विज्ञापन दिखाई देते हैं.  \n",
       "1                                     यह कहीं पे निगाहें, कही पे निशाना का सा अन्दाज है.  \n",
       "2                                       आज हम विज्ञापन युग के सीमान्त पर आ खड़े हुए हैं.  \n",
       "3                           घर के बाहर पैर रखते ही हम विज्ञापन की दुनिया से घिर जाते है.  \n",
       "4                                 वर्तमान समय में विज्ञापन के कई रूप हमारे सामने आते है.  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2982ca8d-6fdb-4c1c-b153-1006de98725c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Sentence: बादशाह के समक्ष एक लड़ाई में सिर काटे जाने पर भी उसका धड़ बहुत समय तक लड़ता रहा था.\n",
      "Correct Seentence: बादशाह के समक्ष एक लड़ाई में सिर काटे जाने पर भी उनका धड़ बहुत समय तक लड़ता रहा था.\n",
      "Predicted Sentence: बादशाह के समक्ष एक लड़ाई में सिर काटे जाने पर भी उसका धड़ बहुत समय तक लड़ता रहा था.\n"
     ]
    }
   ],
   "source": [
    "text = df_test1['enc_input'].iat[45]\n",
    "correct = df_test1['dec_input'].iat[45]\n",
    "print(\"Incorrect Sentence:\", text)\n",
    "print(\"Correct Seentence:\",correct)\n",
    "predicted_s = correct_grammar(text, num_return_sequences=1)[0]\n",
    "l = len(correct)\n",
    "p = len(predicted_s)\n",
    "if(p>l):\n",
    "    predicted_s = predicted_s[:l]\n",
    "\n",
    "print(\"Predicted Sentence:\",predicted_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06b1632b-6e87-4f62-a306-097d41556f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Sentence: इसे गौरी शंकर मंदिर भी कहते है.\n",
      "Correct Seentence: इसे गौरी शंकर मंदिर भी कहते हैं.\n",
      "Predicted Sentence: इसे गौरी शंकर मंदिर भी कहते हैं.\n"
     ]
    }
   ],
   "source": [
    "text = df_test1['enc_input'].iat[40]\n",
    "correct = df_test1['dec_input'].iat[40]\n",
    "print(\"Incorrect Sentence:\", text)\n",
    "print(\"Correct Seentence:\",correct)\n",
    "predicted_s = correct_grammar(text, num_return_sequences=1)[0]\n",
    "l = len(correct)\n",
    "p = len(predicted_s)\n",
    "if(p>l):\n",
    "    predicted_s = predicted_s[:l]\n",
    "\n",
    "print(\"Predicted Sentence:\",predicted_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ff017077-1056-4b4b-a24e-966a05fbc2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:02,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  1  data point 0.9354838709677419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [04:20,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score =  0.8107857635662435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from nltk.translate.gleu_score import sentence_gleu\n",
    "\n",
    "\n",
    "GLEU_val_emb = []\n",
    "test_data = df_test1.head(100)\n",
    "print(test_data.shape)\n",
    "\n",
    "for ind,i in tqdm(test_data.iterrows(),position=0):\n",
    "    try:\n",
    "        text = str(i.enc_input)\n",
    "        #pred = predict(str(i.enc_input),model)[0].split()\n",
    "        pred = correct_grammar(text, num_return_sequences=1)[0]\n",
    "        l = len(text)\n",
    "        p = len(pred)\n",
    "        if(p>l):\n",
    "            pred = pred[:l]\n",
    "            \n",
    "        act = [str(i.dec_input).split()]\n",
    "        pred_s = str(pred).split()\n",
    "        b = sentence_gleu(act,pred_s)\n",
    "        GLEU_val_emb.append(b)\n",
    "        if(ind%100 ==0):\n",
    "            print(\"GELU Score for \",ind+1,\" data point\",np.mean(GLEU_val_emb))\n",
    "    except:\n",
    "        continue\n",
    "print(\"GELU Score = \",np.mean(GLEU_val_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece44c76-ddbd-4136-8ab0-c2f84f33caea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8131416a-f3d2-484b-8a46-af8d0b6f7056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRON_INFL: (496, 2)\n",
      "ADJ_INFL: (150, 2)\n",
      "ADP_INFL: (1101, 2)\n",
      "VERB_INFL: (5241, 2)\n",
      "NOUN_INFL: (182, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_test_pron_infl = pd.read_csv('DATA/Wikiedits_PRON_INFL.csv')\n",
    "print(\"PRON_INFL:\", df_test_pron_infl.shape)\n",
    "\n",
    "df_test_adj_infl = pd.read_csv('DATA/Wikiedits_ADJ_INFL.csv')\n",
    "print(\"ADJ_INFL:\", df_test_adj_infl.shape)\n",
    "\n",
    "df_test_adp_infl = pd.read_csv('DATA/Wikiedits_ADP_INFL.csv')\n",
    "print(\"ADP_INFL:\", df_test_adp_infl.shape)\n",
    "\n",
    "df_test_verb_infl = pd.read_csv('DATA/Wikiedits_VERB_INFL.csv')\n",
    "print(\"VERB_INFL:\", df_test_verb_infl.shape)\n",
    "\n",
    "df_test_noun_infl = pd.read_csv('DATA/Wikiedits_NOUN_INFL.csv')\n",
    "print(\"NOUN_INFL:\", df_test_noun_infl.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa07c8d1-c006-4718-a6eb-9fb4004319ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enc_input</th>\n",
       "      <th>dec_input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>नैबरिजा ने अपनी भाषा पठन अध्ययन को चार पुस्तको...</td>\n",
       "      <td>नैबरिजा ने अपने भाषा पठन अध्ययन को चार पुस्तको...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>अपने मूल प्राकृतिक स्थिति में ये उत्तर अमेरिका...</td>\n",
       "      <td>अपनी मूल प्राकृतिक स्थिति में ये उत्तर अमेरिका...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           enc_input  \\\n",
       "0  नैबरिजा ने अपनी भाषा पठन अध्ययन को चार पुस्तको...   \n",
       "1  अपने मूल प्राकृतिक स्थिति में ये उत्तर अमेरिका...   \n",
       "\n",
       "                                           dec_input  \n",
       "0  नैबरिजा ने अपने भाषा पठन अध्ययन को चार पुस्तको...  \n",
       "1  अपनी मूल प्राकृतिक स्थिति में ये उत्तर अमेरिका...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_pron_infl.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebff85c3-855f-4c3b-97d7-1dda8a7f6c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enc_input</th>\n",
       "      <th>dec_input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>पहली समान विद्यालय व्यवस्था और दूसरी देश की शि...</td>\n",
       "      <td>पहली समान विद्यालय व्यवस्था और दूसरे देश की शि...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>नोएडा एशिया की सबसे बड़ी औद्योगिक उपनगरों में ...</td>\n",
       "      <td>नोएडा एशिया के सबसे बड़े औद्योगिक उपनगरों में ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           enc_input  \\\n",
       "0  पहली समान विद्यालय व्यवस्था और दूसरी देश की शि...   \n",
       "1  नोएडा एशिया की सबसे बड़ी औद्योगिक उपनगरों में ...   \n",
       "\n",
       "                                           dec_input  \n",
       "0  पहली समान विद्यालय व्यवस्था और दूसरे देश की शि...  \n",
       "1  नोएडा एशिया के सबसे बड़े औद्योगिक उपनगरों में ...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_adj_infl.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5a82a24-47bb-427a-a3d9-13d8bf9062b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  1  data point 0.8484848484848485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "51it [01:13,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  51  data point 0.7370891501571076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [02:19,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  101  data point 0.7305455277794598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150it [03:24,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score =  0.7434265640344555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from nltk.translate.gleu_score import sentence_gleu\n",
    "\n",
    "\n",
    "GLEU_val_emb = []\n",
    "test_data = df_test_adj_infl\n",
    "print(test_data.shape)\n",
    "\n",
    "for ind,i in tqdm(test_data.iterrows(),position=0):\n",
    "    try:\n",
    "        text = str(i.enc_input)\n",
    "        #pred = predict(str(i.enc_input),model)[0].split()\n",
    "        pred = correct_grammar(text, num_return_sequences=1)[0]\n",
    "        l = len(text)\n",
    "        p = len(pred)\n",
    "        if(p>l):\n",
    "            pred = pred[:l]\n",
    "            \n",
    "        act = [str(i.dec_input).split()]\n",
    "        pred_s = str(pred).split()\n",
    "        b = sentence_gleu(act,pred_s)\n",
    "        GLEU_val_emb.append(b)\n",
    "        if(ind%50 ==0):\n",
    "            print(\"GELU Score for \",ind+1,\" data point\",np.mean(GLEU_val_emb))\n",
    "    except:\n",
    "        continue\n",
    "print(\"GELU Score = \",np.mean(GLEU_val_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fad9cba8-9fc0-425b-a12a-9cf6d051116d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for ADJ_INFL Error=  0.7434265640344555\n"
     ]
    }
   ],
   "source": [
    "print(\"GELU Score for ADJ_INFL Error= \",np.mean(GLEU_val_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050f72db-9bb9-40d3-97af-ee0d85a3678a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48d3387c-c24c-4275-bc5e-efa3f9755f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(496, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  1  data point 0.6578947368421053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [02:15,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  101  data point 0.8025024854959928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [04:25,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  201  data point 0.805107032082467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [06:38,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  301  data point 0.8094019378566462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "401it [08:51,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  401  data point 0.8143655029809677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "496it [10:57,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score =  0.8095978571769412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from nltk.translate.gleu_score import sentence_gleu\n",
    "\n",
    "\n",
    "GLEU_val_emb = []\n",
    "test_data = df_test_pron_infl\n",
    "print(test_data.shape)\n",
    "\n",
    "for ind,i in tqdm(test_data.iterrows(),position=0):\n",
    "    try:\n",
    "        text = str(i.enc_input)\n",
    "        #pred = predict(str(i.enc_input),model)[0].split()\n",
    "        pred = correct_grammar(text, num_return_sequences=1)[0]\n",
    "        l = len(text)\n",
    "        p = len(pred)\n",
    "        if(p>l):\n",
    "            pred = pred[:l]\n",
    "            \n",
    "        act = [str(i.dec_input).split()]\n",
    "        pred_s = str(pred).split()\n",
    "        b = sentence_gleu(act,pred_s)\n",
    "        GLEU_val_emb.append(b)\n",
    "        if(ind%100 ==0):\n",
    "            print(\"GELU Score for \",ind+1,\" data point\",np.mean(GLEU_val_emb))\n",
    "    except:\n",
    "        continue\n",
    "print(\"GELU Score = \",np.mean(GLEU_val_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07da7565-b8c4-48c2-9d03-10e333bdd0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for PRON_INFL Error=  0.8095978571769412\n"
     ]
    }
   ],
   "source": [
    "print(\"GELU Score for PRON_INFL Error= \",np.mean(GLEU_val_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a058e9-f76a-4fc2-ae80-c4228f9bc61c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6df3b060-3da3-4c7d-a469-dcd1c3e4b6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:04,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  1  data point 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [07:03,  4.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score =  0.7324791038189717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from nltk.translate.gleu_score import sentence_gleu\n",
    "\n",
    "\n",
    "GLEU_val_emb = []\n",
    "test_data = df_test_adp_infl.head(100)\n",
    "print(test_data.shape)\n",
    "\n",
    "for ind,i in tqdm(test_data.iterrows(),position=0):\n",
    "    try:\n",
    "        text = str(i.enc_input)\n",
    "        #pred = predict(str(i.enc_input),model)[0].split()\n",
    "        pred = correct_grammar(text, num_return_sequences=1)[0]\n",
    "        l = len(text)\n",
    "        p = len(pred)\n",
    "        if(p>l):\n",
    "            pred = pred[:l]\n",
    "            \n",
    "        act = [str(i.dec_input).split()]\n",
    "        pred_s = str(pred).split()\n",
    "        b = sentence_gleu(act,pred_s)\n",
    "        GLEU_val_emb.append(b)\n",
    "        if(ind%200 ==0):\n",
    "            print(\"GELU Score for \",ind+1,\" data point\",np.mean(GLEU_val_emb))\n",
    "    except:\n",
    "        continue\n",
    "print(\"GELU Score = \",np.mean(GLEU_val_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4152590f-11cb-44b5-8ccd-44e032bcea58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for ADP_INFL Error=  0.7324791038189717\n"
     ]
    }
   ],
   "source": [
    "print(\"GELU Score for ADP_INFL Error= \",np.mean(GLEU_val_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4637706-5c90-4f2c-b7b8-25936a08af65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32093bfa-50f9-4d5c-8df0-ac9fecfca16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1101, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  1  data point 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [04:24,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  201  data point 0.827990913010508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "401it [08:48,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  401  data point 0.8107513856181036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "601it [13:11,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  601  data point 0.8063863263104685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "801it [17:33,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  801  data point 0.8080139789093645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [21:57,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  1001  data point 0.8102707580849008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1101it [24:11,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score =  0.8082467684365293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from nltk.translate.gleu_score import sentence_gleu\n",
    "\n",
    "\n",
    "GLEU_val_emb = []\n",
    "test_data = df_test_adp_infl\n",
    "print(test_data.shape)\n",
    "\n",
    "for ind,i in tqdm(test_data.iterrows(),position=0):\n",
    "    try:\n",
    "        text = str(i.enc_input)\n",
    "        #pred = predict(str(i.enc_input),model)[0].split()\n",
    "        pred = correct_grammar(text, num_return_sequences=1)[0]\n",
    "        l = len(text)\n",
    "        p = len(pred)\n",
    "        if(p>l):\n",
    "            pred = pred[:l]\n",
    "            \n",
    "        act = [str(i.dec_input).split()]\n",
    "        pred_s = str(pred).split()\n",
    "        b = sentence_gleu(act,pred_s)\n",
    "        GLEU_val_emb.append(b)\n",
    "        if(ind%200 ==0):\n",
    "            print(\"GELU Score for \",ind+1,\" data point\",np.mean(GLEU_val_emb))\n",
    "    except:\n",
    "        continue\n",
    "print(\"GELU Score = \",np.mean(GLEU_val_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1921f5d8-7445-4d60-8374-7908ef93654c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for ADP_INFL Error=  0.8082467684365293\n"
     ]
    }
   ],
   "source": [
    "print(\"GELU Score for ADP_INFL Error= \",np.mean(GLEU_val_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73af636-f27a-480b-a6a5-4339d2c7c23f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d211e56c-9bd1-4d2b-8723-da6e715e50db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5241, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  1  data point 0.9354838709677419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [21:59,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  1001  data point 0.8282614573022717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2001it [43:57,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  2001  data point 0.8175798609854311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3001it [1:05:55,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  3001  data point 0.8289549014661719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4001it [1:27:49,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  4001  data point 0.8287928854774717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5001it [1:49:50,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  5001  data point 0.8294709694830051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5241it [1:55:08,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score =  0.8298811959742303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from nltk.translate.gleu_score import sentence_gleu\n",
    "\n",
    "\n",
    "GLEU_val_emb = []\n",
    "test_data = df_test_verb_infl\n",
    "print(test_data.shape)\n",
    "\n",
    "for ind,i in tqdm(test_data.iterrows(),position=0):\n",
    "    try:\n",
    "        text = str(i.enc_input)\n",
    "        #pred = predict(str(i.enc_input),model)[0].split()\n",
    "        pred = correct_grammar(text, num_return_sequences=1)[0]\n",
    "        l = len(text)\n",
    "        p = len(pred)\n",
    "        if(p>l):\n",
    "            pred = pred[:l]\n",
    "            \n",
    "        act = [str(i.dec_input).split()]\n",
    "        pred_s = str(pred).split()\n",
    "        b = sentence_gleu(act,pred_s)\n",
    "        GLEU_val_emb.append(b)\n",
    "        if(ind%1000 ==0):\n",
    "            print(\"GELU Score for \",ind+1,\" data point\",np.mean(GLEU_val_emb))\n",
    "    except:\n",
    "        continue\n",
    "print(\"GELU Score = \",np.mean(GLEU_val_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ab474a7-400b-4eac-a752-1d7c3de32b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for VERB_INFL Error=  0.8298811959742303\n"
     ]
    }
   ],
   "source": [
    "print(\"GELU Score for VERB_INFL Error= \",np.mean(GLEU_val_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9a2cd3d7-1af4-4f5d-8993-33876292444d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(182, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:06,  6.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  1  data point 0.8780487804878049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "51it [05:44,  6.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  51  data point 0.693378284921975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [11:18,  6.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  101  data point 0.7262667914196586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "151it [16:52,  6.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  151  data point 0.7131101355914514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "182it [20:14,  6.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score =  0.7170992122074078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from nltk.translate.gleu_score import sentence_gleu\n",
    "\n",
    "\n",
    "GLEU_val_emb = []\n",
    "test_data = df_test_noun_infl\n",
    "print(test_data.shape)\n",
    "\n",
    "for ind,i in tqdm(test_data.iterrows(),position=0):\n",
    "    try:\n",
    "        text = str(i.enc_input)\n",
    "        #pred = predict(str(i.enc_input),model)[0].split()\n",
    "        pred = correct_grammar(text, num_return_sequences=1)[0]\n",
    "        l = len(text)\n",
    "        p = len(pred)\n",
    "        if(p>l):\n",
    "            pred = pred[:l]\n",
    "            \n",
    "        act = [str(i.dec_input).split()]\n",
    "        pred_s = str(pred).split()\n",
    "        b = sentence_gleu(act,pred_s)\n",
    "        GLEU_val_emb.append(b)\n",
    "        if(ind%50 ==0):\n",
    "            print(\"GELU Score for \",ind+1,\" data point\",np.mean(GLEU_val_emb))\n",
    "    except:\n",
    "        continue\n",
    "print(\"GELU Score = \",np.mean(GLEU_val_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "febf2bac-ff9d-4673-81da-1af6588e898e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for NOUN_INFL Error=  0.7170992122074078\n"
     ]
    }
   ],
   "source": [
    "print(\"GELU Score for NOUN_INFL Error= \",np.mean(GLEU_val_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc57a01-df6a-4982-b7b3-1c2be5ed2e68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "105e14f5-5def-40b4-89a3-be9dc31126c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13187, 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bc825034-6750-4534-bf2a-710b7471f5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13187, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:06,  6.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  1  data point 0.9354838709677419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [02:13,  6.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  21  data point 0.8085319589371981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "41it [04:16,  6.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  41  data point 0.8105983845524973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "61it [06:21,  6.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  61  data point 0.8078555837400341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [08:29,  6.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  81  data point 0.808525934806311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [10:30,  6.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score =  0.8067715348990488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from nltk.translate.gleu_score import sentence_gleu\n",
    "\n",
    "\n",
    "GLEU_val_emb = []\n",
    "test_data = df_test1.head(100)\n",
    "print(df_test1.shape)\n",
    "\n",
    "for ind,i in tqdm(test_data.iterrows(),position=0):\n",
    "    try:\n",
    "        text = str(i.enc_input)\n",
    "        #pred = predict(str(i.enc_input),model)[0].split()\n",
    "        pred = correct_grammar(text, num_return_sequences=1)[0]\n",
    "        l = len(text)\n",
    "        p = len(pred)\n",
    "        if(p>l):\n",
    "            pred = pred[:l]\n",
    "            \n",
    "        act = [str(i.dec_input).split()]\n",
    "        pred_s = str(pred).split()\n",
    "        b = sentence_gleu(act,pred_s)\n",
    "        GLEU_val_emb.append(b)\n",
    "        if(ind%20 ==0):\n",
    "            print(\"GELU Score for \",ind+1,\" data point\",np.mean(GLEU_val_emb))\n",
    "    except:\n",
    "        continue\n",
    "print(\"GELU Score = \",np.mean(GLEU_val_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febc574f-b357-4e0c-a9d5-68f7c1284733",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad474e87-62ca-401e-96e6-dad1e0179408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13187, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  1  data point 0.9354838709677419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [22:02,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  1001  data point 0.8039029214744148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2001it [43:37,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  2001  data point 0.8022953277285528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3001it [1:05:26,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  3001  data point 0.8045893234170699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4001it [1:26:50,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  4001  data point 0.8055452305729768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5001it [1:48:24,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  5001  data point 0.8044970005640886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6001it [2:09:51,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  6001  data point 0.812802730339381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7001it [2:31:06,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  7001  data point 0.8140137103670035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8001it [2:52:25,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  8001  data point 0.8129554474102898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9001it [3:13:58,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  9001  data point 0.8119726115275038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10001it [3:35:23,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  10001  data point 0.8115315126822349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11001it [3:56:50,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  11001  data point 0.8104934399514466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12001it [4:18:13,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  12001  data point 0.810914551153518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13001it [4:39:33,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  13001  data point 0.8095086869544634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13187it [4:43:27,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score =  0.8095147417782044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from nltk.translate.gleu_score import sentence_gleu\n",
    "\n",
    "\n",
    "GLEU_val_emb = []\n",
    "test_data = df_test1\n",
    "print(df_test1.shape)\n",
    "\n",
    "for ind,i in tqdm(test_data.iterrows(),position=0):\n",
    "    try:\n",
    "        text = str(i.enc_input)\n",
    "        #pred = predict(str(i.enc_input),model)[0].split()\n",
    "        pred = correct_grammar(text, num_return_sequences=1)[0]\n",
    "        l = len(text)\n",
    "        p = len(pred)\n",
    "        if(p>l):\n",
    "            pred = pred[:l]\n",
    "            \n",
    "        act = [str(i.dec_input).split()]\n",
    "        pred_s = str(pred).split()\n",
    "        b = sentence_gleu(act,pred_s)\n",
    "        GLEU_val_emb.append(b)\n",
    "        if(ind%1000 ==0):\n",
    "            print(\"GELU Score for \",ind+1,\" data point\",np.mean(GLEU_val_emb))\n",
    "    except:\n",
    "        continue\n",
    "print(\"GELU Score = \",np.mean(GLEU_val_emb))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
