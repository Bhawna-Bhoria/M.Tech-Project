{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a9c7780-28f4-4676-8620-cfeffba88c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Apr 15 19:33:59 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.84       Driver Version: 460.84       CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:04:00.0 Off |                  N/A |\n",
      "| 34%   67C    P2    91W / 250W |   8657MiB / 11178MiB |     93%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:06:00.0 Off |                  N/A |\n",
      "| 38%   70C    P2   128W / 250W |  11044MiB / 11178MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce GTX 108...  Off  | 00000000:07:00.0 Off |                  N/A |\n",
      "| 23%   57C    P2    75W / 250W |   9860MiB / 11178MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce GTX 108...  Off  | 00000000:08:00.0 Off |                  N/A |\n",
      "| 36%   68C    P2   132W / 250W |  11000MiB / 11178MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  GeForce GTX 108...  Off  | 00000000:0C:00.0 Off |                  N/A |\n",
      "| 42%   74C    P2    84W / 250W |   3957MiB / 11178MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  GeForce GTX 108...  Off  | 00000000:0D:00.0 Off |                  N/A |\n",
      "| 20%   23C    P8     8W / 250W |      2MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  GeForce GTX 108...  Off  | 00000000:0E:00.0 Off |                  N/A |\n",
      "| 23%   57C    P2    63W / 250W |   4913MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  GeForce GTX 108...  Off  | 00000000:0F:00.0 Off |                  N/A |\n",
      "| 36%   68C    P2   204W / 250W |   3535MiB / 11178MiB |     41%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     11690      C   /usr/bin/python3                 4133MiB |\n",
      "|    0   N/A  N/A     11691      C   /usr/bin/python3                  649MiB |\n",
      "|    0   N/A  N/A     11692      C   /usr/bin/python3                  649MiB |\n",
      "|    0   N/A  N/A     11693      C   /usr/bin/python3                  649MiB |\n",
      "|    0   N/A  N/A     38504      C   /opt/conda/bin/python             445MiB |\n",
      "|    0   N/A  N/A     41710      C   python3                           135MiB |\n",
      "|    1   N/A  N/A     11691      C   /usr/bin/python3                 3657MiB |\n",
      "|    2   N/A  N/A     14515      C   python3                          2919MiB |\n",
      "|    3   N/A  N/A     11692      C   /usr/bin/python3                 3875MiB |\n",
      "|    4   N/A  N/A     11693      C   /usr/bin/python3                 3955MiB |\n",
      "|    6   N/A  N/A     20739      C   python                           4911MiB |\n",
      "|    7   N/A  N/A     41710      C   python3                          3533MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1472674-e209-489e-93b9-3d3c8da03a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'GeForce GTX 1080 Ti'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# The GPU id to use, \"0\" to  \"7\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"5,6,7\"\n",
    "#torch.cuda.set_device(0)\n",
    "n_gpu = torch.cuda.device_count()\n",
    "print(n_gpu)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.get_device_name(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ba40e0c-5fcc-43a9-8d28-47ff9e9870f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "340acc79-3319-47aa-8140-07059948a04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /DATA/gupta92/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "import random\n",
    "import re\n",
    "from itertools import chain\n",
    "from string import punctuation\n",
    "#Set a seed\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import datasets\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    T5ForConditionalGeneration,\n",
    "    T5Tokenizer,\n",
    "    get_linear_schedule_with_warmup\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7712b672-2f06-47dd-906a-42ab51326a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fc22694-eff1-4618-ad9c-8b6110972cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4aaf87c-52e6-4e3d-870c-1955b9afd376",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e4420cd-d086-467d-8384-bc29bb4d91ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140000, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('DATA/etoori_train.csv')\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5761a856-2e35-4eb8-9ff6-8fff051468e0",
   "metadata": {},
   "source": [
    "# Training on Hindi_Artificial_train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44742dea-9094-4df9-809a-f4c662c755da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2592885, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('DATA/Hindi_Artificial_train.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0430727a-5f58-494a-a2af-70c742d2f066",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.head(500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "baf2f26e-0f56-4ae3-8028-99c3534594bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADP_INFL: (1101, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(13187, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df_adp_infl = pd.read_csv('DATA/Wikiedits_ADP_INFL.csv')\n",
    "print(\"ADP_INFL:\", df_adp_infl.shape)\n",
    "df1 = pd.read_csv('DATA/HiWikEd.csv')\n",
    "df1 = df1.drop(['Unnamed: 0'], axis=1)\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac38255d-4957-461b-b6e0-18a272a09a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enc_input</th>\n",
       "      <th>dec_input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‡§ú‡§≤ ‡§™‡•ç‡§∞‡§¶‡•Ç‡§∑‡§£ ‡§™‡§∞ ‡§®‡§ø‡§Ø‡§Ç‡§§‡•ç‡§∞‡§£ ‡§π‡•á‡§§‡•Å ‡§®‡§æ‡§≤‡•ã‡§Ç ‡§ï‡§æ ‡§®‡§ø‡§Ø‡§Æ‡§ø‡§§ ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§∏‡§æ‡§´ ‡§∏‡§´‡§æ‡§à ‡§ï‡§∞‡§®‡§æ ‡§ö‡§æ‡§π‡§ø‡§è.</td>\n",
       "      <td>‡§ú‡§≤ ‡§™‡•ç‡§∞‡§¶‡•Ç‡§∑‡§£ ‡§™‡§∞ ‡§®‡§ø‡§Ø‡§Ç‡§§‡•ç‡§∞‡§£ ‡§π‡•á‡§§‡•Å ‡§®‡§æ‡§≤‡•ã‡§Ç ‡§ï‡•Ä ‡§®‡§ø‡§Ø‡§Æ‡§ø‡§§ ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§∏‡§æ‡§´ ‡§∏‡§´‡§æ‡§à ‡§ï‡§∞‡§®‡§æ ‡§ö‡§æ‡§π‡§ø‡§è.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>‡§Ø‡•á ‡§Ø‡•Ç‡§®‡§ø‡§∏‡§® ‡§ó‡•ç‡§∞‡•Å‡§™ ‡§ï‡§æ ‡§∏‡§¨‡§∏‡•á ‡§¨‡§°‡§º‡•Ä ‡§Ø‡•ã‡§ú‡§®‡§æ ‡§•‡•Ä.</td>\n",
       "      <td>‡§Ø‡•á ‡§Ø‡•Ç‡§®‡§ø‡§∏‡§® ‡§ó‡•ç‡§∞‡•Å‡§™ ‡§ï‡•Ä ‡§∏‡§¨‡§∏‡•á ‡§¨‡§°‡§º‡•Ä ‡§Ø‡•ã‡§ú‡§®‡§æ ‡§•‡•Ä.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 enc_input  \\\n",
       "0  ‡§ú‡§≤ ‡§™‡•ç‡§∞‡§¶‡•Ç‡§∑‡§£ ‡§™‡§∞ ‡§®‡§ø‡§Ø‡§Ç‡§§‡•ç‡§∞‡§£ ‡§π‡•á‡§§‡•Å ‡§®‡§æ‡§≤‡•ã‡§Ç ‡§ï‡§æ ‡§®‡§ø‡§Ø‡§Æ‡§ø‡§§ ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§∏‡§æ‡§´ ‡§∏‡§´‡§æ‡§à ‡§ï‡§∞‡§®‡§æ ‡§ö‡§æ‡§π‡§ø‡§è.   \n",
       "1                                   ‡§Ø‡•á ‡§Ø‡•Ç‡§®‡§ø‡§∏‡§® ‡§ó‡•ç‡§∞‡•Å‡§™ ‡§ï‡§æ ‡§∏‡§¨‡§∏‡•á ‡§¨‡§°‡§º‡•Ä ‡§Ø‡•ã‡§ú‡§®‡§æ ‡§•‡•Ä.   \n",
       "\n",
       "                                                                 dec_input  \n",
       "0  ‡§ú‡§≤ ‡§™‡•ç‡§∞‡§¶‡•Ç‡§∑‡§£ ‡§™‡§∞ ‡§®‡§ø‡§Ø‡§Ç‡§§‡•ç‡§∞‡§£ ‡§π‡•á‡§§‡•Å ‡§®‡§æ‡§≤‡•ã‡§Ç ‡§ï‡•Ä ‡§®‡§ø‡§Ø‡§Æ‡§ø‡§§ ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§∏‡§æ‡§´ ‡§∏‡§´‡§æ‡§à ‡§ï‡§∞‡§®‡§æ ‡§ö‡§æ‡§π‡§ø‡§è.  \n",
       "1                                   ‡§Ø‡•á ‡§Ø‡•Ç‡§®‡§ø‡§∏‡§® ‡§ó‡•ç‡§∞‡•Å‡§™ ‡§ï‡•Ä ‡§∏‡§¨‡§∏‡•á ‡§¨‡§°‡§º‡•Ä ‡§Ø‡•ã‡§ú‡§®‡§æ ‡§•‡•Ä.  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_adp_infl.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23398c8b-598c-4095-97a2-a0919d0065e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enc_input</th>\n",
       "      <th>dec_input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‡§ö‡§æ‡§Ø ‡§ï‡•Ä ‡§¶‡•Å‡§ï‡§æ‡§® ‡§∏‡•á ‡§≤‡•á‡§ï‡§∞ ‡§µ‡§æ‡§π‡§®‡•ã‡§Ç ‡§î‡§∞ ‡§¶‡§ø‡§µ‡§æ‡§∞‡•ã‡§Ç ‡§§‡§ï ‡§π‡§∞ ‡§ú‡§ó‡§π ‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§™‡§® ‡§π‡•Ä ‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§™‡§® ‡§¶‡§ø‡§ñ‡§æ‡§à ‡§¶‡•á‡§§‡•á ‡§π‡•à.</td>\n",
       "      <td>‡§ö‡§æ‡§Ø ‡§ï‡•Ä ‡§¶‡•Å‡§ï‡§æ‡§® ‡§∏‡•á ‡§≤‡•á‡§ï‡§∞ ‡§µ‡§æ‡§π‡§®‡•ã‡§Ç ‡§î‡§∞ ‡§¶‡§ø‡§µ‡§æ‡§∞‡•ã‡§Ç ‡§§‡§ï ‡§π‡§∞ ‡§ú‡§ó‡§π ‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§™‡§® ‡§π‡•Ä ‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§™‡§® ‡§¶‡§ø‡§ñ‡§æ‡§à ‡§¶‡•á‡§§‡•á ‡§π‡•à‡§Ç.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>‡§Ø‡•á ‡§ï‡§π‡•Ä‡§Ç ‡§™‡•á ‡§®‡§ø‡§ó‡§æ‡§π‡•á‡§Ç, ‡§ï‡§π‡•Ä ‡§™‡•á ‡§®‡§ø‡§∂‡§æ‡§®‡§æ ‡§ï‡§æ ‡§∏‡§æ ‡§Ö‡§®‡•ç‡§¶‡§æ‡§ú ‡§π‡•à.</td>\n",
       "      <td>‡§Ø‡§π ‡§ï‡§π‡•Ä‡§Ç ‡§™‡•á ‡§®‡§ø‡§ó‡§æ‡§π‡•á‡§Ç, ‡§ï‡§π‡•Ä ‡§™‡•á ‡§®‡§ø‡§∂‡§æ‡§®‡§æ ‡§ï‡§æ ‡§∏‡§æ ‡§Ö‡§®‡•ç‡§¶‡§æ‡§ú ‡§π‡•à.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                              enc_input  \\\n",
       "0  ‡§ö‡§æ‡§Ø ‡§ï‡•Ä ‡§¶‡•Å‡§ï‡§æ‡§® ‡§∏‡•á ‡§≤‡•á‡§ï‡§∞ ‡§µ‡§æ‡§π‡§®‡•ã‡§Ç ‡§î‡§∞ ‡§¶‡§ø‡§µ‡§æ‡§∞‡•ã‡§Ç ‡§§‡§ï ‡§π‡§∞ ‡§ú‡§ó‡§π ‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§™‡§® ‡§π‡•Ä ‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§™‡§® ‡§¶‡§ø‡§ñ‡§æ‡§à ‡§¶‡•á‡§§‡•á ‡§π‡•à.   \n",
       "1                                    ‡§Ø‡•á ‡§ï‡§π‡•Ä‡§Ç ‡§™‡•á ‡§®‡§ø‡§ó‡§æ‡§π‡•á‡§Ç, ‡§ï‡§π‡•Ä ‡§™‡•á ‡§®‡§ø‡§∂‡§æ‡§®‡§æ ‡§ï‡§æ ‡§∏‡§æ ‡§Ö‡§®‡•ç‡§¶‡§æ‡§ú ‡§π‡•à.   \n",
       "\n",
       "                                                                               dec_input  \n",
       "0  ‡§ö‡§æ‡§Ø ‡§ï‡•Ä ‡§¶‡•Å‡§ï‡§æ‡§® ‡§∏‡•á ‡§≤‡•á‡§ï‡§∞ ‡§µ‡§æ‡§π‡§®‡•ã‡§Ç ‡§î‡§∞ ‡§¶‡§ø‡§µ‡§æ‡§∞‡•ã‡§Ç ‡§§‡§ï ‡§π‡§∞ ‡§ú‡§ó‡§π ‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§™‡§® ‡§π‡•Ä ‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§™‡§® ‡§¶‡§ø‡§ñ‡§æ‡§à ‡§¶‡•á‡§§‡•á ‡§π‡•à‡§Ç.  \n",
       "1                                     ‡§Ø‡§π ‡§ï‡§π‡•Ä‡§Ç ‡§™‡•á ‡§®‡§ø‡§ó‡§æ‡§π‡•á‡§Ç, ‡§ï‡§π‡•Ä ‡§™‡•á ‡§®‡§ø‡§∂‡§æ‡§®‡§æ ‡§ï‡§æ ‡§∏‡§æ ‡§Ö‡§®‡•ç‡§¶‡§æ‡§ú ‡§π‡•à.  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35e95d81-a4ce-4210-b921-c6998fc0d7b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14288, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = [df1, df_adp_infl]\n",
    "df = pd.concat(frames)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60dd0008-7592-44dd-a2af-0d748bd383d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enc_input</th>\n",
       "      <th>dec_input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‡§ö‡§æ‡§Ø ‡§ï‡•Ä ‡§¶‡•Å‡§ï‡§æ‡§® ‡§∏‡•á ‡§≤‡•á‡§ï‡§∞ ‡§µ‡§æ‡§π‡§®‡•ã‡§Ç ‡§î‡§∞ ‡§¶‡§ø‡§µ‡§æ‡§∞‡•ã‡§Ç ‡§§‡§ï ‡§π‡§∞ ‡§ú‡§ó‡§π ‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§™‡§® ‡§π‡•Ä ‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§™‡§® ‡§¶‡§ø‡§ñ‡§æ‡§à ‡§¶‡•á‡§§‡•á ‡§π‡•à.</td>\n",
       "      <td>‡§ö‡§æ‡§Ø ‡§ï‡•Ä ‡§¶‡•Å‡§ï‡§æ‡§® ‡§∏‡•á ‡§≤‡•á‡§ï‡§∞ ‡§µ‡§æ‡§π‡§®‡•ã‡§Ç ‡§î‡§∞ ‡§¶‡§ø‡§µ‡§æ‡§∞‡•ã‡§Ç ‡§§‡§ï ‡§π‡§∞ ‡§ú‡§ó‡§π ‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§™‡§® ‡§π‡•Ä ‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§™‡§® ‡§¶‡§ø‡§ñ‡§æ‡§à ‡§¶‡•á‡§§‡•á ‡§π‡•à‡§Ç.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>‡§Ø‡•á ‡§ï‡§π‡•Ä‡§Ç ‡§™‡•á ‡§®‡§ø‡§ó‡§æ‡§π‡•á‡§Ç, ‡§ï‡§π‡•Ä ‡§™‡•á ‡§®‡§ø‡§∂‡§æ‡§®‡§æ ‡§ï‡§æ ‡§∏‡§æ ‡§Ö‡§®‡•ç‡§¶‡§æ‡§ú ‡§π‡•à.</td>\n",
       "      <td>‡§Ø‡§π ‡§ï‡§π‡•Ä‡§Ç ‡§™‡•á ‡§®‡§ø‡§ó‡§æ‡§π‡•á‡§Ç, ‡§ï‡§π‡•Ä ‡§™‡•á ‡§®‡§ø‡§∂‡§æ‡§®‡§æ ‡§ï‡§æ ‡§∏‡§æ ‡§Ö‡§®‡•ç‡§¶‡§æ‡§ú ‡§π‡•à.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                              enc_input  \\\n",
       "0  ‡§ö‡§æ‡§Ø ‡§ï‡•Ä ‡§¶‡•Å‡§ï‡§æ‡§® ‡§∏‡•á ‡§≤‡•á‡§ï‡§∞ ‡§µ‡§æ‡§π‡§®‡•ã‡§Ç ‡§î‡§∞ ‡§¶‡§ø‡§µ‡§æ‡§∞‡•ã‡§Ç ‡§§‡§ï ‡§π‡§∞ ‡§ú‡§ó‡§π ‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§™‡§® ‡§π‡•Ä ‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§™‡§® ‡§¶‡§ø‡§ñ‡§æ‡§à ‡§¶‡•á‡§§‡•á ‡§π‡•à.   \n",
       "1                                    ‡§Ø‡•á ‡§ï‡§π‡•Ä‡§Ç ‡§™‡•á ‡§®‡§ø‡§ó‡§æ‡§π‡•á‡§Ç, ‡§ï‡§π‡•Ä ‡§™‡•á ‡§®‡§ø‡§∂‡§æ‡§®‡§æ ‡§ï‡§æ ‡§∏‡§æ ‡§Ö‡§®‡•ç‡§¶‡§æ‡§ú ‡§π‡•à.   \n",
       "\n",
       "                                                                               dec_input  \n",
       "0  ‡§ö‡§æ‡§Ø ‡§ï‡•Ä ‡§¶‡•Å‡§ï‡§æ‡§® ‡§∏‡•á ‡§≤‡•á‡§ï‡§∞ ‡§µ‡§æ‡§π‡§®‡•ã‡§Ç ‡§î‡§∞ ‡§¶‡§ø‡§µ‡§æ‡§∞‡•ã‡§Ç ‡§§‡§ï ‡§π‡§∞ ‡§ú‡§ó‡§π ‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§™‡§® ‡§π‡•Ä ‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§™‡§® ‡§¶‡§ø‡§ñ‡§æ‡§à ‡§¶‡•á‡§§‡•á ‡§π‡•à‡§Ç.  \n",
       "1                                     ‡§Ø‡§π ‡§ï‡§π‡•Ä‡§Ç ‡§™‡•á ‡§®‡§ø‡§ó‡§æ‡§π‡•á‡§Ç, ‡§ï‡§π‡•Ä ‡§™‡•á ‡§®‡§ø‡§∂‡§æ‡§®‡§æ ‡§ï‡§æ ‡§∏‡§æ ‡§Ö‡§®‡•ç‡§¶‡§æ‡§ú ‡§π‡•à.  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f23822f-77c3-4e13-9245-404f08e1743a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fc84c40-1152-4f97-b749-186365fff1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = {'enc_input':'input'}, inplace = True)\n",
    "df.rename(columns = {'dec_input':'output'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b51b0af9-4f5f-4e8f-92e5-10d8ed20e7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5dd252f1-a794-4cef-be0b-1b59e0d8185c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‡§ö‡§æ‡§Ø ‡§ï‡•Ä ‡§¶‡•Å‡§ï‡§æ‡§® ‡§∏‡•á ‡§≤‡•á‡§ï‡§∞ ‡§µ‡§æ‡§π‡§®‡•ã‡§Ç ‡§î‡§∞ ‡§¶‡§ø‡§µ‡§æ‡§∞‡•ã‡§Ç ‡§§‡§ï ‡§π‡§∞ ‡§ú‡§ó‡§π ‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§™‡§® ‡§π‡•Ä ‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§™‡§® ‡§¶‡§ø‡§ñ‡§æ‡§à ‡§¶‡•á‡§§‡•á ‡§π‡•à.</td>\n",
       "      <td>‡§ö‡§æ‡§Ø ‡§ï‡•Ä ‡§¶‡•Å‡§ï‡§æ‡§® ‡§∏‡•á ‡§≤‡•á‡§ï‡§∞ ‡§µ‡§æ‡§π‡§®‡•ã‡§Ç ‡§î‡§∞ ‡§¶‡§ø‡§µ‡§æ‡§∞‡•ã‡§Ç ‡§§‡§ï ‡§π‡§∞ ‡§ú‡§ó‡§π ‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§™‡§® ‡§π‡•Ä ‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§™‡§® ‡§¶‡§ø‡§ñ‡§æ‡§à ‡§¶‡•á‡§§‡•á ‡§π‡•à‡§Ç.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>‡§Ø‡•á ‡§ï‡§π‡•Ä‡§Ç ‡§™‡•á ‡§®‡§ø‡§ó‡§æ‡§π‡•á‡§Ç, ‡§ï‡§π‡•Ä ‡§™‡•á ‡§®‡§ø‡§∂‡§æ‡§®‡§æ ‡§ï‡§æ ‡§∏‡§æ ‡§Ö‡§®‡•ç‡§¶‡§æ‡§ú ‡§π‡•à.</td>\n",
       "      <td>‡§Ø‡§π ‡§ï‡§π‡•Ä‡§Ç ‡§™‡•á ‡§®‡§ø‡§ó‡§æ‡§π‡•á‡§Ç, ‡§ï‡§π‡•Ä ‡§™‡•á ‡§®‡§ø‡§∂‡§æ‡§®‡§æ ‡§ï‡§æ ‡§∏‡§æ ‡§Ö‡§®‡•ç‡§¶‡§æ‡§ú ‡§π‡•à.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                  input  \\\n",
       "0  ‡§ö‡§æ‡§Ø ‡§ï‡•Ä ‡§¶‡•Å‡§ï‡§æ‡§® ‡§∏‡•á ‡§≤‡•á‡§ï‡§∞ ‡§µ‡§æ‡§π‡§®‡•ã‡§Ç ‡§î‡§∞ ‡§¶‡§ø‡§µ‡§æ‡§∞‡•ã‡§Ç ‡§§‡§ï ‡§π‡§∞ ‡§ú‡§ó‡§π ‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§™‡§® ‡§π‡•Ä ‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§™‡§® ‡§¶‡§ø‡§ñ‡§æ‡§à ‡§¶‡•á‡§§‡•á ‡§π‡•à.   \n",
       "1                                    ‡§Ø‡•á ‡§ï‡§π‡•Ä‡§Ç ‡§™‡•á ‡§®‡§ø‡§ó‡§æ‡§π‡•á‡§Ç, ‡§ï‡§π‡•Ä ‡§™‡•á ‡§®‡§ø‡§∂‡§æ‡§®‡§æ ‡§ï‡§æ ‡§∏‡§æ ‡§Ö‡§®‡•ç‡§¶‡§æ‡§ú ‡§π‡•à.   \n",
       "\n",
       "                                                                                  output  \n",
       "0  ‡§ö‡§æ‡§Ø ‡§ï‡•Ä ‡§¶‡•Å‡§ï‡§æ‡§® ‡§∏‡•á ‡§≤‡•á‡§ï‡§∞ ‡§µ‡§æ‡§π‡§®‡•ã‡§Ç ‡§î‡§∞ ‡§¶‡§ø‡§µ‡§æ‡§∞‡•ã‡§Ç ‡§§‡§ï ‡§π‡§∞ ‡§ú‡§ó‡§π ‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§™‡§® ‡§π‡•Ä ‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§™‡§® ‡§¶‡§ø‡§ñ‡§æ‡§à ‡§¶‡•á‡§§‡•á ‡§π‡•à‡§Ç.  \n",
       "1                                     ‡§Ø‡§π ‡§ï‡§π‡•Ä‡§Ç ‡§™‡•á ‡§®‡§ø‡§ó‡§æ‡§π‡•á‡§Ç, ‡§ï‡§π‡•Ä ‡§™‡•á ‡§®‡§ø‡§∂‡§æ‡§®‡§æ ‡§ï‡§æ ‡§∏‡§æ ‡§Ö‡§®‡•ç‡§¶‡§æ‡§ú ‡§π‡•à.  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c81e7ec2-d0fa-45d6-be30-7c2e2877dc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    T5ForConditionalGeneration, T5Tokenizer, \n",
    "    Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq\n",
    "  )\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c509b356-7320-4dbb-9184-9750dd208a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/muril-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3fc016f6-2311-4978-a799-f40e96abaef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='google/muril-base-cased', vocab_size=197285, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cbc19d2f-5c42-46ea-8c21-decc47553c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98a081dd-fbb1-4b1d-a762-4d99ecc0ad9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = AutoModelForMaskedLM.from_pretrained(\"google/muril-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b199d7a2-2b5d-4904-b204-a379c34aefca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "#model_name = 't5-base'\n",
    "#tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "#model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "#model_name = 't5_gec_hindi_muRIL'\n",
    "#model_name = 't5_gec_hindi_muRIL_best'\n",
    "model_name ='t5_gec_hindi_muRIL_best_Full'\n",
    "torch_device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name).to(torch_device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ca44d0-39fd-48a8-a0a2-466fd4ce1d60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aca04df4-d7de-4f44-9800-94eb1c5296ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_token_len(example):\n",
    "    return len(tokenizer(example).input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9821b86-5a8b-4956-856c-d4c88d482f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12859, 2), (1429, 2))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train - Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df, test_size=0.10, shuffle=True)\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c514352d-1338-4a42-95a6-36151e6b0306",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['input_token_len'] = test_df['input'].apply(calc_token_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f9df2945-fb4d-4f63-b24b-2571dceba51b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>input_token_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4450</th>\n",
       "      <td>‡§Ø‡§π ‡§µ‡•á‡§≤‡•ç‡§∏ ‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Ø ‡§∞‡§ó‡•ç‡§¨‡•Ä ‡§Ø‡•Ç‡§®‡§ø‡§Ø‡§® ‡§ü‡•Ä‡§Æ ‡§ï‡§æ ‡§ò‡§∞ ‡§π‡•à ‡§î‡§∞ ‡§µ‡•á‡§≤‡•ç‡§∏ ‡§ï‡•Ä ‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Ø ‡§´‡§º‡•Å‡§ü‡§¨‡•â‡§≤ ‡§ü‡•Ä‡§Æ ‡§ï‡•á ‡§ñ‡•á‡§≤ ‡§ï‡•Ä ‡§Æ‡•á‡§ú‡§¨‡§æ‡§®‡•Ä ‡§≠‡•Ä ‡§ï‡§∞‡§§‡§æ ‡§π‡•à.</td>\n",
       "      <td>‡§Ø‡§π ‡§µ‡•á‡§≤‡•ç‡§∏ ‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Ø ‡§∞‡§ó‡•ç‡§¨‡•Ä ‡§Ø‡•Ç‡§®‡§ø‡§Ø‡§® ‡§ü‡•Ä‡§Æ ‡§ï‡§æ ‡§ò‡§∞ ‡§π‡•à ‡§î‡§∞ ‡§µ‡•á‡§≤‡•ç‡§∏ ‡§ï‡•Ä ‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Ø ‡§´‡§º‡•Å‡§ü‡§¨‡•â‡§≤ ‡§ü‡•Ä‡§Æ ‡§ï‡•á ‡§Æ‡•à‡§ö ‡§ï‡•Ä ‡§Æ‡•á‡§ú‡§¨‡§æ‡§®‡•Ä ‡§≠‡•Ä ‡§ï‡§∞‡§§‡§æ ‡§π‡•à.</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7854</th>\n",
       "      <td>‡§ö‡§ï‡•ç‡§∑‡•Å‡§∑‡§æ ‡§π‡§ø‡§Ç‡§¶‡•Ç ‡§™‡•å‡§∞‡§æ‡§£‡§ø‡§ï ‡§ï‡§•‡§æ‡§ì‡§Ç ‡§ï‡•á ‡§è‡§ï ‡§™‡§æ‡§§‡•ç‡§∞ ‡§π‡•à‡§Ç, ‡§ú‡•ã ‡§õ‡§†‡•á ‡§Æ‡§®‡•ç‡§µ‡§Ç‡§§‡§∞ ‡§ï‡•á ‡§Æ‡§®‡•Å ‡§π‡•à‡§Ç, ‡§ú‡•ã ‡§ã‡§∑‡§ø ‡§µ‡•É‡§π‡§§‡•Ä ‡§ï‡•á ‡§™‡•Å‡§§‡•ç‡§∞ ‡§π‡•à‡§Ç.</td>\n",
       "      <td>‡§ö‡§ï‡•ç‡§∑‡•Å‡§∑‡§æ ‡§π‡§ø‡§Ç‡§¶‡•Ç ‡§™‡•å‡§∞‡§æ‡§£‡§ø‡§ï ‡§ï‡§•‡§æ‡§ì‡§Ç ‡§ï‡•á ‡§è‡§ï ‡§™‡§æ‡§§‡•ç‡§∞ ‡§π‡•à‡§Ç, ‡§ú‡•ã ‡§õ‡§†‡•á ‡§Æ‡§®‡•ç‡§µ‡§Ç‡§§‡§∞ ‡§ï‡•á ‡§Æ‡§®‡•Å ‡§π‡•à‡§Ç, ‡§§‡§•‡§æ ‡§ã‡§∑‡§ø ‡§µ‡•É‡§π‡§§‡•Ä ‡§ï‡•á ‡§™‡•Å‡§§‡•ç‡§∞ ‡§π‡•à‡§Ç.</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7050</th>\n",
       "      <td>‡§á‡§∏ ‡§ó‡§æ‡§Ç‡§µ ‡§Æ‡•á‡§Ç ‡§õ‡§§‡•ç‡§∞‡§ø‡§Ø ‡§¨‡•ç‡§∞‡§æ‡§π‡•ç‡§Æ‡§£ ‡§¶‡§≤‡§ø‡§§ ‡§¨‡§ò‡•á‡§≤ ‡§Ü‡§ú ‡§ú‡§æ‡§§‡§ø‡§Ø‡§æ‡§Ç ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§™‡§æ‡§à ‡§ú‡§æ‡§§‡•Ä ‡§π‡•à‡§Ç.</td>\n",
       "      <td>‡§á‡§∏ ‡§ó‡§æ‡§Ç‡§µ ‡§Æ‡•á‡§Ç ‡§õ‡§§‡•ç‡§∞‡§ø‡§Ø ‡§¨‡•ç‡§∞‡§æ‡§π‡•ç‡§Æ‡§£ ‡§¶‡§≤‡§ø‡§§ ‡§¨‡§ò‡•á‡§≤ ‡§Ü‡§¶‡§ø ‡§ú‡§æ‡§§‡§ø‡§Ø‡§æ‡§Ç ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§™‡§æ‡§à ‡§ú‡§æ‡§§‡•Ä ‡§π‡•à‡§Ç.</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12868</th>\n",
       "      <td>‡§Ø‡§¶‡§ø ‡§á‡§∏ ‡§ó‡§æ‡§Ç‡§µ ‡§∏‡•á ‡§ä‡§™‡§∞ ‡§ï‡•Ä ‡§ì‡§∞ ‡§ú‡§æ‡§Ø‡§æ ‡§ú‡§æ‡§è ‡§§‡•ã ‡§ò‡•ã‡§∞‡§≤, ‡§è‡§Ç‡§ü‡•Ä‡§≤‡•ã‡§™‡•ç‡§∏, ‡§ï‡§æ‡§≤‡•á ‡§î‡§∞ ‡§≤‡§æ‡§≤ ‡§≠‡§æ‡§≤‡•Å‡§ì‡§Ç ‡§ï‡•ã ‡§¶‡•á‡§ñ‡§æ ‡§ú‡§æ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à.</td>\n",
       "      <td>‡§Ø‡§¶‡§ø ‡§á‡§∏ ‡§ó‡•ç‡§∞‡§æ‡§Æ ‡§∏‡•á ‡§ä‡§™‡§∞ ‡§ï‡•Ä ‡§ì‡§∞ ‡§ú‡§æ‡§Ø‡§æ ‡§ú‡§æ‡§è ‡§§‡•ã ‡§ò‡•ã‡§∞‡§≤, ‡§è‡§Ç‡§ü‡•Ä‡§≤‡•ã‡§™‡•ç‡§∏, ‡§ï‡§æ‡§≤‡•á ‡§î‡§∞ ‡§≤‡§æ‡§≤ ‡§≠‡§æ‡§≤‡•Å‡§ì‡§Ç ‡§ï‡•ã ‡§¶‡•á‡§ñ‡§æ ‡§ú‡§æ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à.</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7242</th>\n",
       "      <td>‡§µ‡§π ‡§è‡§ï ‡§¶‡§∂‡§ï ‡§∏‡•á ‡§Ö‡§ß‡§ø‡§ï ‡§∏‡§Æ‡§Ø ‡§ï‡•á ‡§≤‡§ø‡§è ‡§è‡§ï ‡§™‡•ç‡§∞‡§Æ‡•Å‡§ñ ‡§∂‡•å‡§ï‡§ø‡§Ø‡§æ ‡§ö‡•à‡§Ç‡§™‡§ø‡§Ø‡§® ‡§•‡§æ.</td>\n",
       "      <td>‡§µ‡§π ‡§è‡§ï ‡§¶‡§∂‡§ï ‡§∏‡•á ‡§Ö‡§ß‡§ø‡§ï ‡§∏‡§Æ‡§Ø ‡§ï‡•á ‡§≤‡§ø‡§è ‡§è‡§ï ‡§™‡•ç‡§∞‡§ß‡§æ‡§® ‡§∂‡•å‡§ï‡§ø‡§Ø‡§æ ‡§ö‡•à‡§Ç‡§™‡§ø‡§Ø‡§® ‡§•‡§æ.</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                              input  \\\n",
       "4450   ‡§Ø‡§π ‡§µ‡•á‡§≤‡•ç‡§∏ ‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Ø ‡§∞‡§ó‡•ç‡§¨‡•Ä ‡§Ø‡•Ç‡§®‡§ø‡§Ø‡§® ‡§ü‡•Ä‡§Æ ‡§ï‡§æ ‡§ò‡§∞ ‡§π‡•à ‡§î‡§∞ ‡§µ‡•á‡§≤‡•ç‡§∏ ‡§ï‡•Ä ‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Ø ‡§´‡§º‡•Å‡§ü‡§¨‡•â‡§≤ ‡§ü‡•Ä‡§Æ ‡§ï‡•á ‡§ñ‡•á‡§≤ ‡§ï‡•Ä ‡§Æ‡•á‡§ú‡§¨‡§æ‡§®‡•Ä ‡§≠‡•Ä ‡§ï‡§∞‡§§‡§æ ‡§π‡•à.   \n",
       "7854             ‡§ö‡§ï‡•ç‡§∑‡•Å‡§∑‡§æ ‡§π‡§ø‡§Ç‡§¶‡•Ç ‡§™‡•å‡§∞‡§æ‡§£‡§ø‡§ï ‡§ï‡§•‡§æ‡§ì‡§Ç ‡§ï‡•á ‡§è‡§ï ‡§™‡§æ‡§§‡•ç‡§∞ ‡§π‡•à‡§Ç, ‡§ú‡•ã ‡§õ‡§†‡•á ‡§Æ‡§®‡•ç‡§µ‡§Ç‡§§‡§∞ ‡§ï‡•á ‡§Æ‡§®‡•Å ‡§π‡•à‡§Ç, ‡§ú‡•ã ‡§ã‡§∑‡§ø ‡§µ‡•É‡§π‡§§‡•Ä ‡§ï‡•á ‡§™‡•Å‡§§‡•ç‡§∞ ‡§π‡•à‡§Ç.   \n",
       "7050                                    ‡§á‡§∏ ‡§ó‡§æ‡§Ç‡§µ ‡§Æ‡•á‡§Ç ‡§õ‡§§‡•ç‡§∞‡§ø‡§Ø ‡§¨‡•ç‡§∞‡§æ‡§π‡•ç‡§Æ‡§£ ‡§¶‡§≤‡§ø‡§§ ‡§¨‡§ò‡•á‡§≤ ‡§Ü‡§ú ‡§ú‡§æ‡§§‡§ø‡§Ø‡§æ‡§Ç ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§™‡§æ‡§à ‡§ú‡§æ‡§§‡•Ä ‡§π‡•à‡§Ç.   \n",
       "12868                  ‡§Ø‡§¶‡§ø ‡§á‡§∏ ‡§ó‡§æ‡§Ç‡§µ ‡§∏‡•á ‡§ä‡§™‡§∞ ‡§ï‡•Ä ‡§ì‡§∞ ‡§ú‡§æ‡§Ø‡§æ ‡§ú‡§æ‡§è ‡§§‡•ã ‡§ò‡•ã‡§∞‡§≤, ‡§è‡§Ç‡§ü‡•Ä‡§≤‡•ã‡§™‡•ç‡§∏, ‡§ï‡§æ‡§≤‡•á ‡§î‡§∞ ‡§≤‡§æ‡§≤ ‡§≠‡§æ‡§≤‡•Å‡§ì‡§Ç ‡§ï‡•ã ‡§¶‡•á‡§ñ‡§æ ‡§ú‡§æ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à.   \n",
       "7242                                                      ‡§µ‡§π ‡§è‡§ï ‡§¶‡§∂‡§ï ‡§∏‡•á ‡§Ö‡§ß‡§ø‡§ï ‡§∏‡§Æ‡§Ø ‡§ï‡•á ‡§≤‡§ø‡§è ‡§è‡§ï ‡§™‡•ç‡§∞‡§Æ‡•Å‡§ñ ‡§∂‡•å‡§ï‡§ø‡§Ø‡§æ ‡§ö‡•à‡§Ç‡§™‡§ø‡§Ø‡§® ‡§•‡§æ.   \n",
       "\n",
       "                                                                                                             output  \\\n",
       "4450   ‡§Ø‡§π ‡§µ‡•á‡§≤‡•ç‡§∏ ‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Ø ‡§∞‡§ó‡•ç‡§¨‡•Ä ‡§Ø‡•Ç‡§®‡§ø‡§Ø‡§® ‡§ü‡•Ä‡§Æ ‡§ï‡§æ ‡§ò‡§∞ ‡§π‡•à ‡§î‡§∞ ‡§µ‡•á‡§≤‡•ç‡§∏ ‡§ï‡•Ä ‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Ø ‡§´‡§º‡•Å‡§ü‡§¨‡•â‡§≤ ‡§ü‡•Ä‡§Æ ‡§ï‡•á ‡§Æ‡•à‡§ö ‡§ï‡•Ä ‡§Æ‡•á‡§ú‡§¨‡§æ‡§®‡•Ä ‡§≠‡•Ä ‡§ï‡§∞‡§§‡§æ ‡§π‡•à.   \n",
       "7854            ‡§ö‡§ï‡•ç‡§∑‡•Å‡§∑‡§æ ‡§π‡§ø‡§Ç‡§¶‡•Ç ‡§™‡•å‡§∞‡§æ‡§£‡§ø‡§ï ‡§ï‡§•‡§æ‡§ì‡§Ç ‡§ï‡•á ‡§è‡§ï ‡§™‡§æ‡§§‡•ç‡§∞ ‡§π‡•à‡§Ç, ‡§ú‡•ã ‡§õ‡§†‡•á ‡§Æ‡§®‡•ç‡§µ‡§Ç‡§§‡§∞ ‡§ï‡•á ‡§Æ‡§®‡•Å ‡§π‡•à‡§Ç, ‡§§‡§•‡§æ ‡§ã‡§∑‡§ø ‡§µ‡•É‡§π‡§§‡•Ä ‡§ï‡•á ‡§™‡•Å‡§§‡•ç‡§∞ ‡§π‡•à‡§Ç.   \n",
       "7050                                   ‡§á‡§∏ ‡§ó‡§æ‡§Ç‡§µ ‡§Æ‡•á‡§Ç ‡§õ‡§§‡•ç‡§∞‡§ø‡§Ø ‡§¨‡•ç‡§∞‡§æ‡§π‡•ç‡§Æ‡§£ ‡§¶‡§≤‡§ø‡§§ ‡§¨‡§ò‡•á‡§≤ ‡§Ü‡§¶‡§ø ‡§ú‡§æ‡§§‡§ø‡§Ø‡§æ‡§Ç ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§™‡§æ‡§à ‡§ú‡§æ‡§§‡•Ä ‡§π‡•à‡§Ç.   \n",
       "12868                 ‡§Ø‡§¶‡§ø ‡§á‡§∏ ‡§ó‡•ç‡§∞‡§æ‡§Æ ‡§∏‡•á ‡§ä‡§™‡§∞ ‡§ï‡•Ä ‡§ì‡§∞ ‡§ú‡§æ‡§Ø‡§æ ‡§ú‡§æ‡§è ‡§§‡•ã ‡§ò‡•ã‡§∞‡§≤, ‡§è‡§Ç‡§ü‡•Ä‡§≤‡•ã‡§™‡•ç‡§∏, ‡§ï‡§æ‡§≤‡•á ‡§î‡§∞ ‡§≤‡§æ‡§≤ ‡§≠‡§æ‡§≤‡•Å‡§ì‡§Ç ‡§ï‡•ã ‡§¶‡•á‡§ñ‡§æ ‡§ú‡§æ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à.   \n",
       "7242                                                      ‡§µ‡§π ‡§è‡§ï ‡§¶‡§∂‡§ï ‡§∏‡•á ‡§Ö‡§ß‡§ø‡§ï ‡§∏‡§Æ‡§Ø ‡§ï‡•á ‡§≤‡§ø‡§è ‡§è‡§ï ‡§™‡•ç‡§∞‡§ß‡§æ‡§® ‡§∂‡•å‡§ï‡§ø‡§Ø‡§æ ‡§ö‡•à‡§Ç‡§™‡§ø‡§Ø‡§® ‡§•‡§æ.   \n",
       "\n",
       "       input_token_len  \n",
       "4450                26  \n",
       "7854                30  \n",
       "7050                21  \n",
       "12868               30  \n",
       "7242                16  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd321d92-6f3a-40ee-ba4a-907be30ea244",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['input_token_len'].describe()\n",
    "\n",
    "train_df = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a5e933a2-ae5f-4c20-87b4-4dbb99b2c5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will use a token length of 64 since it will cover the vast majority of examples\n",
    "from datasets import Dataset\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8ca6fab2-ae06-441f-807e-da87e843249b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "183"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.input.str.len().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d75fca39-9ccb-4bce-8a14-ca5d573cb60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the Dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class GrammarDataset(Dataset):\n",
    "    def __init__(self, dataset, tokenizer,print_text=False):         \n",
    "        self.dataset = dataset\n",
    "        self.pad_to_max_length = False\n",
    "        self.tokenizer = tokenizer\n",
    "        self.print_text = print_text\n",
    "        #self.max_len = 128\n",
    "        self.max_len = 64\n",
    "  \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "\n",
    "    def tokenize_data(self, example):\n",
    "        input_, target_ = example['input'], example['output']\n",
    "\n",
    "        # tokenize inputs\n",
    "        tokenized_inputs = tokenizer(input_, pad_to_max_length=self.pad_to_max_length, \n",
    "                                            max_length=self.max_len,\n",
    "                                            return_attention_mask=True)\n",
    "    \n",
    "        tokenized_targets = tokenizer(target_, pad_to_max_length=self.pad_to_max_length, \n",
    "                                            max_length=self.max_len,\n",
    "                                            return_attention_mask=True)\n",
    "\n",
    "        inputs={\"input_ids\": tokenized_inputs['input_ids'],\n",
    "            \"attention_mask\": tokenized_inputs['attention_mask'],\n",
    "            \"labels\": tokenized_targets['input_ids']\n",
    "        }\n",
    "        \n",
    "        return inputs\n",
    "\n",
    "  \n",
    "    def __getitem__(self, index):\n",
    "        inputs = self.tokenize_data(self.dataset[index])\n",
    "        \n",
    "        if self.print_text:\n",
    "            for k in inputs.keys():\n",
    "                print(k, len(inputs[k]))\n",
    "\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b8aa2940-f691-4bc5-9c05-d70ff42e05ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids 13\n",
      "attention_mask 13\n",
      "labels 13\n",
      "{'input_ids': [104, 1503, 23421, 6407, 2768, 2254, 7593, 1124, 2768, 13913, 1115, 121, 105], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [104, 1503, 23421, 6407, 2768, 2254, 7593, 1124, 2768, 13913, 1145, 121, 105]}\n"
     ]
    }
   ],
   "source": [
    "dataset = GrammarDataset(test_dataset, tokenizer, True)\n",
    "print(dataset[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfc0564-2706-4d95-8dfb-e9970a0e2a02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e6bd3fc-b11e-47a1-b473-10705ebe1d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Evaluator\n",
    "#!pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f50438a6-1ed2-460a-8bb0-307fa7b23806",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "rouge_metric = load_metric(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bf186c82-6bea-4bb3-b9f3-1b00df72ee70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Model\n",
    "#data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, padding='longest', return_tensors='pt')\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, padding='longest', return_tensors='pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "46056d09-d0ba-46ac-823e-adf72d83ac55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = 't5_gec_hindi_muRIL_1'\n",
    "#torch_device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
    "#model = T5ForConditionalGeneration.from_pretrained(model_name).to(torch_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7b108ae3-2088-44fa-af0f-8b3583bd157d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining training related arguments\n",
    "batch_size = 8\n",
    "'''\n",
    "args = Seq2SeqTrainingArguments(output_dir=\"models/hindi/T5_muRIL_3\",\n",
    "                        evaluation_strategy=\"epoch\",\n",
    "                        per_device_train_batch_size=batch_size,\n",
    "                        per_device_eval_batch_size=batch_size,\n",
    "                        learning_rate=2e-5,\n",
    "                        num_train_epochs=1,\n",
    "                        weight_decay=0.1,\n",
    "                        save_total_limit=2,\n",
    "                        predict_with_generate=True,\n",
    "                        fp16 = True,\n",
    "                        gradient_accumulation_steps = 6,\n",
    "                        #eval_steps = 500,\n",
    "                        #save_steps = 2000,\n",
    "                        #dataloader_num_workers= 4,\n",
    "                        load_best_model_at_end=True,\n",
    "                        logging_dir=\"logs/hindi/T5_muRIL_3\")\n",
    "'''\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"models/hindi/T5_muRIL_Full\",\n",
    "    #output_dir =None,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-3,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.3,\n",
    "    save_steps=300000,\n",
    "    num_train_epochs=10,\n",
    "    dataloader_num_workers= 2,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    #logging_dir=\"logs/hindi/T5_muRIL_3\"\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e2a430e6-c635-43bb-a305-357ac0773191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "#os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"false\"\n",
    "os.environ['TRANSFORMERS_NO_ADVISORY_WARNINGS'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bfbcd6b1-bdcb-4f9d-a7ca-cd6924d7e6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9d9743c7-8b58-4bee-9ab1-2fcd8032b17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuda_amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "# defining trainer using ü§ó\n",
    "trainer = Seq2SeqTrainer(model=model, \n",
    "                args=args, \n",
    "                train_dataset= GrammarDataset(train_dataset, tokenizer),\n",
    "                eval_dataset=GrammarDataset(test_dataset, tokenizer),\n",
    "                tokenizer=tokenizer,\n",
    "                data_collator=data_collator)\n",
    "                #compute_metrics=compute_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "50e692da-5dee-4325-b082-b660f82d1e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch\n",
    "#torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "daad0d94-9d45-428a-b04a-712301e66c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 14288\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 24\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5960\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5960' max='5960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5960/5960 1:17:29, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.464700</td>\n",
       "      <td>1.607950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.404500</td>\n",
       "      <td>1.396081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.327900</td>\n",
       "      <td>1.434922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.210000</td>\n",
       "      <td>1.267827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.144800</td>\n",
       "      <td>1.079509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.744200</td>\n",
       "      <td>0.838862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.432800</td>\n",
       "      <td>0.879704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.320200</td>\n",
       "      <td>0.538478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.999400</td>\n",
       "      <td>0.454238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.851300</td>\n",
       "      <td>0.404103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1429\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1429\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1429\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1429\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1429\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1429\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1429\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1429\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1429\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1429\n",
      "  Batch size = 24\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5960, training_loss=1.7238809111934381, metrics={'train_runtime': 4660.5741, 'train_samples_per_second': 30.657, 'train_steps_per_second': 1.279, 'total_flos': 5281501299793920.0, 'train_loss': 1.7238809111934381, 'epoch': 10.0})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"     #Disabling Wandb\n",
    "#model.resize_token_embeddings(len(tokenizer))\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8bfc48c8-a51f-4f22-94fb-59aec03306f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to t5_gec_hindi_muRIL_best_Full\n",
      "Configuration saved in t5_gec_hindi_muRIL_best_Full/config.json\n",
      "Model weights saved in t5_gec_hindi_muRIL_best_Full/pytorch_model.bin\n",
      "tokenizer config file saved in t5_gec_hindi_muRIL_best_Full/tokenizer_config.json\n",
      "Special tokens file saved in t5_gec_hindi_muRIL_best_Full/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "#Save the trained Model\n",
    "trainer.save_model('t5_gec_hindi_muRIL_best_Full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5878bd-b180-46db-b3e9-21b6f54f411d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65993d5a-b5f8-4578-b285-e63e6bdcc36e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2136d560-e522-4f3a-9828-e67211d9fc77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 12859\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 24\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1608\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1608' max='1608' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1608/1608 21:06, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.390700</td>\n",
       "      <td>0.628927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.384600</td>\n",
       "      <td>0.628927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.388100</td>\n",
       "      <td>0.628927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1429\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1429\n",
      "  Batch size = 24\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1429\n",
      "  Batch size = 24\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1608, training_loss=0.3878441734693537, metrics={'train_runtime': 1267.4907, 'train_samples_per_second': 30.436, 'train_steps_per_second': 1.269, 'total_flos': 1427035726725120.0, 'train_loss': 0.3878441734693537, 'epoch': 3.0})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"     #Disabling Wandb\n",
    "#model.resize_token_embeddings(len(tokenizer))\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "20205c3b-6918-4777-ad9f-e5a62d091c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to t5_gec_hindi_muRIL_best_Full\n",
      "Configuration saved in t5_gec_hindi_muRIL_best_Full/config.json\n",
      "Model weights saved in t5_gec_hindi_muRIL_best_Full/pytorch_model.bin\n",
      "tokenizer config file saved in t5_gec_hindi_muRIL_best_Full/tokenizer_config.json\n",
      "Special tokens file saved in t5_gec_hindi_muRIL_best_Full/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "#Save the trained Model\n",
    "trainer.save_model('t5_gec_hindi_muRIL_best_Full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba66188d-fed4-4bb9-9c41-23f8fc3d63c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5229eac7-5a16-4eb4-be00-c3f7ee5a9c1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cea8f05e-4128-4723-90ee-ae9e2ff96afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 2333596\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 24\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 97234\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='97234' max='97234' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [97234/97234 21:34:31, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.113900</td>\n",
       "      <td>0.088758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to models/hindi/T5_muRIL_Full/checkpoint-30000\n",
      "Configuration saved in models/hindi/T5_muRIL_Full/checkpoint-30000/config.json\n",
      "Model weights saved in models/hindi/T5_muRIL_Full/checkpoint-30000/pytorch_model.bin\n",
      "tokenizer config file saved in models/hindi/T5_muRIL_Full/checkpoint-30000/tokenizer_config.json\n",
      "Special tokens file saved in models/hindi/T5_muRIL_Full/checkpoint-30000/special_tokens_map.json\n",
      "Saving model checkpoint to models/hindi/T5_muRIL_Full/checkpoint-60000\n",
      "Configuration saved in models/hindi/T5_muRIL_Full/checkpoint-60000/config.json\n",
      "Model weights saved in models/hindi/T5_muRIL_Full/checkpoint-60000/pytorch_model.bin\n",
      "tokenizer config file saved in models/hindi/T5_muRIL_Full/checkpoint-60000/tokenizer_config.json\n",
      "Special tokens file saved in models/hindi/T5_muRIL_Full/checkpoint-60000/special_tokens_map.json\n",
      "Saving model checkpoint to models/hindi/T5_muRIL_Full/checkpoint-90000\n",
      "Configuration saved in models/hindi/T5_muRIL_Full/checkpoint-90000/config.json\n",
      "Model weights saved in models/hindi/T5_muRIL_Full/checkpoint-90000/pytorch_model.bin\n",
      "tokenizer config file saved in models/hindi/T5_muRIL_Full/checkpoint-90000/tokenizer_config.json\n",
      "Special tokens file saved in models/hindi/T5_muRIL_Full/checkpoint-90000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 259289\n",
      "  Batch size = 24\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=97234, training_loss=2.108593665541063, metrics={'train_runtime': 77686.3981, 'train_samples_per_second': 30.039, 'train_steps_per_second': 1.252, 'total_flos': 9.332473302411264e+16, 'train_loss': 2.108593665541063, 'epoch': 1.0})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"     #Disabling Wandb\n",
    "#model.resize_token_embeddings(len(tokenizer))\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0e7a11-1f66-4cfd-9a41-8cdefe7ea3aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ccc43f08-6d80-442d-83c5-543aac70e9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 2333596\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 24\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 97234\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='97234' max='97234' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [97234/97234 21:29:41, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.070400</td>\n",
       "      <td>0.059936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 259289\n",
      "  Batch size = 24\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=97234, training_loss=0.7156300433809912, metrics={'train_runtime': 77398.8282, 'train_samples_per_second': 30.15, 'train_steps_per_second': 1.256, 'total_flos': 9.332804423264256e+16, 'train_loss': 0.7156300433809912, 'epoch': 1.0})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"     #Disabling Wandb\n",
    "#model.resize_token_embeddings(len(tokenizer))\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aaaea036-afff-4988-b9c3-605dace1b50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 450000\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 24\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18750\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18750' max='18750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18750/18750 4:06:38, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.132100</td>\n",
       "      <td>0.107768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 24\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=18750, training_loss=0.6001573170979818, metrics={'train_runtime': 14814.4253, 'train_samples_per_second': 30.376, 'train_steps_per_second': 1.266, 'total_flos': 1.799350678020096e+16, 'train_loss': 0.6001573170979818, 'epoch': 1.0})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Wandb API Key: bcdbdd5ee9d76a20c90b5f2a246eb45f14b341a9\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"     #Disabling Wandb\n",
    "#model.resize_token_embeddings(len(tokenizer))\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f4ed8776-52ca-4d06-9e15-158994267915",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch_device = 'cuda' if torch.cuda.is_available() else 'cpu' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b68254c3-619e-464f-bfa6-01c21279c6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to t5_gec_hindi_muRIL_best\n",
      "Configuration saved in t5_gec_hindi_muRIL_best/config.json\n",
      "Model weights saved in t5_gec_hindi_muRIL_best/pytorch_model.bin\n",
      "tokenizer config file saved in t5_gec_hindi_muRIL_best/tokenizer_config.json\n",
      "Special tokens file saved in t5_gec_hindi_muRIL_best/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "#Save the trained Model\n",
    "trainer.save_model('t5_gec_hindi_muRIL_best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "627b9bd5-acdd-4728-8bb5-8ac6bb809b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to t5_gec_hindi_muRIL_best\n",
      "Configuration saved in t5_gec_hindi_muRIL_best/config.json\n",
      "Model weights saved in t5_gec_hindi_muRIL_best/pytorch_model.bin\n",
      "tokenizer config file saved in t5_gec_hindi_muRIL_best/tokenizer_config.json\n",
      "Special tokens file saved in t5_gec_hindi_muRIL_best/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "#Save the trained Model\n",
    "trainer.save_model('t5_gec_hindi_muRIL_best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa6e472-f983-4018-97ea-fd020ae3ea39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!zip -r 't5_gec_hindi_muRIL_2.zip' 't5_gec_hindi_muRIL_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3895631b-8f35-4ea2-930f-ef9c56e17072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained\n"
     ]
    }
   ],
   "source": [
    "print(\"Trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da45d37b-cd1f-43e7-a4e2-bc18ef984b14",
   "metadata": {},
   "source": [
    "# Testing Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6ea2de44-6fbe-40a6-ba4f-f074a82b6767",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /DATA/gupta92/.cache/huggingface/hub/models--google--muril-base-cased/snapshots/afd9f36c7923d54e97903922ff1b260d091d202f/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"google/muril-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.22.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 197285\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at /DATA/gupta92/.cache/huggingface/hub/models--google--muril-base-cased/snapshots/afd9f36c7923d54e97903922ff1b260d091d202f/vocab.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /DATA/gupta92/.cache/huggingface/hub/models--google--muril-base-cased/snapshots/afd9f36c7923d54e97903922ff1b260d091d202f/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /DATA/gupta92/.cache/huggingface/hub/models--google--muril-base-cased/snapshots/afd9f36c7923d54e97903922ff1b260d091d202f/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /DATA/gupta92/.cache/huggingface/hub/models--google--muril-base-cased/snapshots/afd9f36c7923d54e97903922ff1b260d091d202f/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"google/muril-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.22.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 197285\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /DATA/gupta92/.cache/huggingface/hub/models--google--muril-base-cased/snapshots/afd9f36c7923d54e97903922ff1b260d091d202f/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"google/muril-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.22.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 197285\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Testing\n",
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration,AutoTokenizer\n",
    "#model_name = 't5_gec_hindi_muRIL'\n",
    "#model_name = 't5_gec_hindi_muRIL_best'\n",
    "model_name = 't5_gec_hindi_muRIL_best_Full'\n",
    "torch_device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/muril-base-cased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "98143e4e-6280-4ab1-96a5-2be73cad8d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file t5_gec_hindi_muRIL_best_Full/config.json\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"t5_gec_hindi_muRIL_best_Full\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 3072,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.22.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 197285\n",
      "}\n",
      "\n",
      "loading weights file t5_gec_hindi_muRIL_best_Full/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
      "\n",
      "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at t5_gec_hindi_muRIL_best_Full.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "#tokenizer = AutoTokenizer.from_pretrained(\"surajp/RoBERTa-hindi-guj-san\")\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"google/muril-base-cased\")\n",
    "trained_model = T5ForConditionalGeneration.from_pretrained(model_name).to(torch_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7dee6d65-83bc-4bb6-bdbc-8511c6becea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cde5ea1c-2854-458b-bd0e-288c372d6768",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: continue\n",
    "        param = parameter.numel()\n",
    "        table.add_row([name, param])\n",
    "        total_params+=param\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params\n",
    "\n",
    "#count_parameters(trained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b6e20830-2f49-4050-b1cd-67ebdb5a4534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size: 1334.168MB\n"
     ]
    }
   ],
   "source": [
    "param_size = 0\n",
    "for param in trained_model.parameters():\n",
    "    param_size += param.nelement() * param.element_size()\n",
    "buffer_size = 0\n",
    "for buffer in trained_model.buffers():\n",
    "    buffer_size += buffer.nelement() * buffer.element_size()\n",
    "\n",
    "size_all_mb = (param_size + buffer_size) / 1024**2\n",
    "print('model size: {:.3f}MB'.format(size_all_mb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9669013c-f34f-44b1-a35c-f265f106a427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_grammar(input_text,num_return_sequences):\n",
    "    #batch = tokenizer([input_text],truncation=True,padding='max_length',max_length=64, return_tensors=\"pt\").to(torch_device)\n",
    "    batch = tokenizer([input_text],truncation=True,padding='max_length',max_length=64, return_tensors=\"pt\",return_token_type_ids=False).to(device)\n",
    "    #print(batch)\n",
    "    #translated = model1.generate(**batch,max_length=64,num_beams=4, num_return_sequences=num_return_sequences, temperature=1.5)\n",
    "    max_len =  train_df.input.str.len().max()\n",
    "    #translated= trained_model.generate(**batch,max_length=64,num_beams=4, num_return_sequences=num_return_sequences, temperature=1.5)\n",
    "    translated= trained_model.generate(**batch,max_length=max_len,num_beams=4, num_return_sequences=num_return_sequences, temperature=1.5)\n",
    "    \n",
    "    \n",
    "    #print(\"here\")\n",
    "    tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "    return tgt_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b786ccc2-8dea-4c4d-b60c-c242ef187a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(T5ForConditionalGeneration.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b28c83a6-7420-49d1-a2c1-369c78b33644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Sentence: ‡§®‡§æ‡§ó‡§∞‡§Æ‡•ã‡§•‡§æ ‡§ï‡•Ä ‡§ú‡§°‡§º ‡§Æ‡•á‡§Ç ‡§ï‡§∏‡•á‡§∞‡•Ç ‡§ï‡•Ä ‡§≠‡§æ‡§Ç‡§§‡§ø ‡§è‡§ï ‡§ï‡§®‡•ç‡§¶ ‡§®‡§ø‡§ï‡§≤‡§§‡§æ ‡§π‡•à ‡§ú‡§ø‡§∏‡•á ‡§®‡§æ‡§ó‡§∞‡§Æ‡•ã‡§•‡§æ ‡§ï‡§π‡§§‡•á ‡§π‡•à‡§Ç.\n",
      "Correct Seentence: ‡§®‡§æ‡§ó‡§∞‡§Æ‡•ã‡§•‡§æ ‡§ï‡•Ä ‡§ú‡§°‡§º ‡§Æ‡•á‡§Ç ‡§ï‡§∏‡•á‡§∞‡•Ç ‡§ï‡•Ä ‡§≠‡§æ‡§Ç‡§§‡§ø ‡§è‡§ï ‡§ï‡§®‡•ç‡§¶ ‡§®‡§ø‡§ï‡§≤‡§§‡§æ ‡§π‡•à‡§Ç ‡§ú‡§ø‡§∏‡•á ‡§®‡§æ‡§ó‡§∞‡§Æ‡•ã‡§•‡§æ ‡§ï‡§π‡§§‡•á ‡§π‡•à‡§Ç.\n",
      "Predicted Sentence: ‡§®‡§æ‡§ó‡§∞‡§Æ‡•ã‡§•‡§æ ‡§ï‡•á ‡§ú‡§°‡§º ‡§Æ‡•á‡§Ç ‡§ï‡§∏‡•á‡§∞‡•Ç ‡§ï‡•Ä ‡§≠‡§æ‡§Ç‡§§‡§ø ‡§è‡§ï ‡§ï‡§®‡•ç‡§¶ ‡§®‡§ø‡§ï‡§≤‡§§‡§æ ‡§π‡•à ‡§ú‡§ø‡§∏‡•á ‡§®‡§æ‡§ó‡§∞‡§Æ‡•ã‡§•‡§æ ‡§ï‡§π‡§§‡•á ‡§π‡•à‡§Ç. \n"
     ]
    }
   ],
   "source": [
    "text = test_df['input'].iat[200]\n",
    "correct = test_df['output'].iat[200]\n",
    "print(\"Incorrect Sentence:\", text)\n",
    "print(\"Correct Seentence:\",correct)\n",
    "l = len(correct)\n",
    "predicted_s = correct_grammar(text, num_return_sequences=4)[0]\n",
    "p = len(predicted_s)\n",
    "\n",
    "if(p>l):\n",
    "    predicted_s = predicted_s[:l]\n",
    "elif (p<l-4):\n",
    "    predicted_s = text\n",
    "print(\"Predicted Sentence:\",predicted_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d83c4e-4a3f-4cfd-bbb6-0d2d457e825a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2dc10f7d-909a-4d2b-917a-475e43619610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Sentence: ‡§Ø‡§π ‡§∂‡§π‡§∞ ‡§Æ‡§≤‡§ï‡•ç‡§ï‡§æ ‡§ú‡§≤‡§∏‡§®‡•ç‡§ß‡§ø ‡§™‡§∞ ‡§¨‡§∏‡§æ ‡§π‡•Å‡§Ü ‡§π‡•à‡§Ç.\n",
      "Correct Seentence: ‡§Ø‡§π ‡§∂‡§π‡§∞ ‡§Æ‡§≤‡§ï‡•ç‡§ï‡§æ ‡§ú‡§≤‡§∏‡§®‡•ç‡§ß‡§ø ‡§™‡§∞ ‡§¨‡§∏‡§æ ‡§π‡•Å‡§Ü ‡§π‡•à.\n",
      "Predicted Sentence: ‡§Ø‡§π ‡§∂‡§π‡§∞ ‡§Æ‡§≤‡§ï‡•ç‡§ï‡§æ ‡§ú‡§≤‡§∏‡§®‡•ç‡§ß‡§ø ‡§™‡§∞ ‡§¨‡§∏‡§æ ‡§π‡•Å‡§Ü ‡§π‡•à.\n"
     ]
    }
   ],
   "source": [
    "text = test_df['input'].iat[0]\n",
    "correct = test_df['output'].iat[0]\n",
    "print(\"Incorrect Sentence:\", text)\n",
    "print(\"Correct Seentence:\",correct)\n",
    "l = len(correct)\n",
    "predicted_s = correct_grammar(text, num_return_sequences=4)[0]\n",
    "p = len(predicted_s)\n",
    "\n",
    "if(p>l):\n",
    "    predicted_s = predicted_s[:l]\n",
    "elif (p<l-4):\n",
    "    predicted_s = text\n",
    "print(\"Predicted Sentence:\",predicted_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "33497c92-ccc5-4eba-89d9-004161a5e100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Sentence: ‡§¶‡§∞‡§≠‡§Ç‡§ó‡§æ, ‡§¨‡§ø‡§π‡§æ‡§∞ ‡§ï‡•á ‡§è‡§ï ‡§™‡•ç‡§∞‡§ñ‡§£‡•ç‡§°.\n",
      "Correct Seentence: ‡§¶‡§∞‡§≠‡§Ç‡§ó‡§æ, ‡§¨‡§ø‡§π‡§æ‡§∞ ‡§ï‡§æ ‡§è‡§ï ‡§™‡•ç‡§∞‡§ñ‡§£‡•ç‡§°.\n",
      "Predicted Sentence: ‡§¶‡§∞‡§≠‡§Ç‡§ó‡§æ, ‡§¨‡§ø‡§π‡§æ‡§∞ ‡§ï‡§æ ‡§è‡§ï ‡§™‡•ç‡§∞‡§ñ‡§£‡•ç‡§°.\n"
     ]
    }
   ],
   "source": [
    "text = test_df['input'].iat[0]\n",
    "correct = test_df['output'].iat[0]\n",
    "print(\"Incorrect Sentence:\", text)\n",
    "print(\"Correct Seentence:\",correct)\n",
    "l = len(correct)\n",
    "predicted_s = correct_grammar(text, num_return_sequences=2)[0]\n",
    "p = len(predicted_s)\n",
    "\n",
    "if(p>l):\n",
    "    predicted_s = predicted_s[:l]\n",
    "elif (p<l-4):\n",
    "    predicted_s = text\n",
    "\n",
    "\n",
    "print(\"Predicted Sentence:\",predicted_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e27fa025-97be-48b8-8e96-c59cbbd23fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Sentence: ‡§Ö‡§®‡•ç ‚Äç ‡§§ ‡§™‡•Å‡§∞ ‡§ï‡•ã ‡§≤‡•à ‡§ó‡§à‡§Ç, ‡§ú‡§π‡§æ‡§Ç ‡§® ‡§¶‡•Ç‡§ú‡•ã ‡§ú‡§æ‡§Ø.\n",
      "Correct Seentence: ‡§Ö‡§®‡•ç ‚Äç ‡§§ ‡§™‡•Å‡§∞ ‡§ï‡•ã ‡§≤‡•à ‡§ó‡§è, ‡§ú‡§π‡§æ‡§Ç ‡§® ‡§¶‡•Ç‡§ú‡•ã ‡§ú‡§æ‡§Ø.\n",
      "Predicted Sentence: ‡§Ö‡§®‡•ç ‡§§ ‡§™‡•Å‡§∞ ‡§ï‡•ã ‡§≤‡•à ‡§ó‡§Ø‡§æ, ‡§ú‡§π‡§æ‡§Ç ‡§® ‡§¶‡•Ç‡§ú‡•ã ‡§ú‡§æ‡§Ø. \n"
     ]
    }
   ],
   "source": [
    "text = test_df['input'].iat[100]\n",
    "correct = test_df['output'].iat[100]\n",
    "print(\"Incorrect Sentence:\", text)\n",
    "print(\"Correct Seentence:\",correct)\n",
    "l = len(correct)\n",
    "predicted_s = correct_grammar(text, num_return_sequences=2)[0]\n",
    "p = len(predicted_s)\n",
    "\n",
    "if(p>l):\n",
    "    predicted_s = predicted_s[:l]\n",
    "elif (p<l-4):\n",
    "    predicted_s = text\n",
    "\n",
    "\n",
    "print(\"Predicted Sentence:\",predicted_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f827ca3-b021-48c6-9d2f-caa01399511b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2021e0-7fe0-4db1-a0b5-db088775cbdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3f8b0823-1f45-41f2-a239-c4b724f58309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Sentence: ‡§Ö‡§Ç‡§§‡§∞ ‡§ï‡•á‡§µ‡§≤ ‡§á‡§§‡§®‡§æ ‡§π‡•Ä ‡§π‡•à ‡§ï‡§ø ‡§•‡•ã‡§°‡§º‡•á ‡§∏‡•ç‡§•‡§æ‡§® ‡§Æ‡•á‡§Ç ‡§∏‡§≠‡•Ä ‡§∏‡•Å‡§µ‡§ø‡§ß‡§æ‡§è‡§Ç ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§®‡•á ‡§ï‡§æ ‡§™‡•ç‡§∞‡§Ø‡§æ‡§∏ ‡§ï‡•Ä‡§Ç ‡§ú‡§æ‡§§‡§æ ‡§π‡•à.\n",
      "Correct Seentence: ‡§Ö‡§Ç‡§§‡§∞ ‡§ï‡•á‡§µ‡§≤ ‡§á‡§§‡§®‡§æ ‡§π‡•Ä ‡§π‡•à ‡§ï‡§ø ‡§•‡•ã‡§°‡§º‡•á ‡§∏‡•ç‡§•‡§æ‡§® ‡§Æ‡•á‡§Ç ‡§∏‡§≠‡•Ä ‡§∏‡•Å‡§µ‡§ø‡§ß‡§æ‡§è‡§Ç ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§®‡•á ‡§ï‡§æ ‡§™‡•ç‡§∞‡§Ø‡§æ‡§∏ ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ‡§§‡§æ ‡§π‡•à.\n",
      "Predicted Sentence: ‡§Ö‡§Ç‡§§‡§∞ ‡§ï‡•á‡§µ‡§≤ ‡§á‡§§‡§®‡§æ ‡§π‡•Ä ‡§π‡•à ‡§ï‡§ø ‡§•‡•ã‡§°‡§º‡•á ‡§∏‡•ç‡§•‡§æ‡§® ‡§Æ‡•á‡§Ç ‡§∏‡§≠‡•Ä ‡§∏‡•Å‡§µ‡§ø‡§ß‡§æ‡§è‡§Ç ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§®‡•á ‡§ï‡§æ ‡§™‡•ç‡§∞‡§Ø‡§æ‡§∏ ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ‡§§‡§æ ‡§π‡•à.\n"
     ]
    }
   ],
   "source": [
    "text = test_df['input'].iat[43]\n",
    "correct = test_df['output'].iat[43]\n",
    "print(\"Incorrect Sentence:\", text)\n",
    "print(\"Correct Seentence:\",correct)\n",
    "p = len(predicted_s)\n",
    "l = len(correct)\n",
    "predicted_s = correct_grammar(text, num_return_sequences=2)[0]\n",
    "p = len(predicted_s)\n",
    "if(p>l):\n",
    "    predicted_s = predicted_s[:l]\n",
    "\n",
    "print(\"Predicted Sentence:\",predicted_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "79771c80-b79f-4ac2-8086-4eb0a0d82051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Sentence: ‡§¶‡§ø‡§≤‡•ç‡§≤‡•Ä ‡§ï‡§æ ‡§ó‡•Å‡§∞‡•ç‡§ú‡§∞‡•ã‡§Ç ‡§®‡•á ‡§Æ‡§æ‡§≤‡§ó‡•Å‡§ú‡§æ‡§∞‡•Ä ‡§¨‡§π‡§æ‡§¶‡•Å‡§∞‡§∂‡§æ‡§π ‡§ú‡§´‡§∞ ‡§Æ‡•Å‡§ó‡§≤ ‡§¨‡§æ‡§¶‡§∂‡§æ‡§π ‡§ï‡•ã ‡§¶‡•á‡§®‡•Ä ‡§∂‡•Å‡§∞‡•Ç ‡§ï‡§∞ ‡§¶‡•Ä ‡§•‡•Ä.\n",
      "Correct Seentence: ‡§¶‡§ø‡§≤‡•ç‡§≤‡•Ä ‡§ï‡•á ‡§ó‡•Å‡§∞‡•ç‡§ú‡§∞‡•ã‡§Ç ‡§®‡•á ‡§Æ‡§æ‡§≤‡§ó‡•Å‡§ú‡§æ‡§∞‡•Ä ‡§¨‡§π‡§æ‡§¶‡•Å‡§∞‡§∂‡§æ‡§π ‡§ú‡§´‡§∞ ‡§Æ‡•Å‡§ó‡§≤ ‡§¨‡§æ‡§¶‡§∂‡§æ‡§π ‡§ï‡•ã ‡§¶‡•á‡§®‡•Ä ‡§∂‡•Å‡§∞‡•Ç ‡§ï‡§∞ ‡§¶‡•Ä ‡§•‡•Ä.\n",
      "Predicted Sentence: ‡§¶‡§ø‡§≤‡•ç‡§≤‡•Ä ‡§ï‡•á ‡§ó‡•Å‡§∞‡•ç‡§ú‡§∞‡•ã‡§Ç ‡§®‡•á ‡§Æ‡§æ‡§≤‡§ó‡•Å‡§ú‡§æ‡§∞‡•Ä ‡§¨‡§π‡§æ‡§¶‡•Å‡§∞‡§∂‡§æ‡§π ‡§ú‡§´‡§∞ ‡§Æ‡•Å‡§ó‡§≤ ‡§¨‡§æ‡§¶‡§∂‡§æ‡§π ‡§ï‡•ã ‡§¶‡•á‡§®‡§æ ‡§∂‡•Å‡§∞‡•Ç ‡§ï‡§∞ ‡§¶‡•Ä ‡§•‡•Ä.\n"
     ]
    }
   ],
   "source": [
    "text = test_df['input'].iat[1]\n",
    "correct = test_df['output'].iat[1]\n",
    "print(\"Incorrect Sentence:\", text)\n",
    "print(\"Correct Seentence:\",correct)\n",
    "p = len(predicted_s)\n",
    "l = len(correct)\n",
    "predicted_s = correct_grammar(text, num_return_sequences=4)[0][:l]\n",
    "print(\"Predicted Sentence:\",predicted_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a3c96d0d-6d65-42bc-8faa-30a3b931c57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Sentence: ‡§µ‡•á ‡§ê‡§∏‡•Ä ‡§™‡§π‡§≤‡•Ä ‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡§¶‡•á‡§µ‡•Ä ‡§π‡•à‡§Ç, ‡§ú‡§ø‡§®‡§ï‡•Ä ‡§Æ‡§æ‡§§‡•É‡§≠‡§æ‡§∑‡§æ ‡§Ö‡§Ç‡§ó‡•ç‡§∞‡•á‡§ú‡§º‡•Ä ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à.\n",
      "Correct Seentence: ‡§µ‡•á ‡§ê‡§∏‡•Ä ‡§™‡§π‡§≤‡•Ä ‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡§¶‡•á‡§µ‡•Ä ‡§π‡•à, ‡§ú‡§ø‡§®‡§ï‡•Ä ‡§Æ‡§æ‡§§‡•É‡§≠‡§æ‡§∑‡§æ ‡§Ö‡§Ç‡§ó‡•ç‡§∞‡•á‡§ú‡§º‡•Ä ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à.\n",
      "Predicted Sentence: ‡§µ‡•á ‡§ê‡§∏‡•Ä ‡§™‡§π‡§≤‡•Ä ‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡§¶‡•á‡§µ‡•Ä ‡§π‡•à‡§Ç, ‡§ú‡§ø‡§®‡§ï‡•Ä ‡§Æ‡§æ‡§§‡•É‡§≠‡§æ‡§∑‡§æ ‡§Ö‡§Ç‡§ó‡•ç‡§∞‡•á‡§ú‡§º‡•Ä ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à\n"
     ]
    }
   ],
   "source": [
    "text = test_df['input'].iat[50]\n",
    "correct = test_df['output'].iat[50]\n",
    "print(\"Incorrect Sentence:\", text)\n",
    "print(\"Correct Seentence:\",correct)\n",
    "predicted_s = correct_grammar(text, num_return_sequences=1)[0]\n",
    "l = len(correct)\n",
    "p = len(predicted_s)\n",
    "if(p>l):\n",
    "    predicted_s = predicted_s[:l]\n",
    "\n",
    "print(\"Predicted Sentence:\",predicted_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9f05b016-c983-4167-a2f7-c5f1736de779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Sentence: ‡§Æ‡§∞‡§æ‡§ï ‡§ó‡•Å‡§∞‡§∏‡•Å‡§§‡§æ  10 ‡§¶‡§ø‡§∏‡§Ç‡§¨‡§∞ 1945 09 ‡§Ö‡§ï‡•ç‡§ü‡•Ç‡§¨‡§∞ 2006  ‡§™‡•ã‡§≤‡•à‡§Ç‡§°‡•Ä ‡§ó‡§æ‡§Ø‡§ï, ‡§∏‡§Ç‡§ó‡•Ä‡§§‡§ï‡§æ‡§∞, ‡§ï‡§µ‡§ø ‡§î‡§∞ ‡§ö‡§ø‡§§‡•ç‡§∞‡§ï‡§æ‡§∞ ‡§•‡§æ.\n",
      "Correct Seentence: ‡§Æ‡§∞‡§æ‡§ï ‡§ó‡•Å‡§∞‡§∏‡•Å‡§§‡§æ  10 ‡§¶‡§ø‡§∏‡§Ç‡§¨‡§∞ 1945 09 ‡§Ö‡§ï‡•ç‡§ü‡•Ç‡§¨‡§∞ 2006  ‡§™‡•ã‡§≤‡•à‡§Ç‡§°‡•Ä ‡§ó‡§æ‡§Ø‡§ï, ‡§∏‡§Ç‡§ó‡•Ä‡§§‡§ï‡§æ‡§∞, ‡§ï‡§µ‡§ø ‡§î‡§∞ ‡§ö‡§ø‡§§‡•ç‡§∞‡§ï‡§æ‡§∞ ‡§π‡•à‡§Ç.\n",
      "Predicted Sentence: ‡§Æ‡§∞‡§æ‡§ï ‡§ó‡•Å‡§∞‡§∏‡•Å‡§§‡§æ 10 ‡§¶‡§ø‡§∏‡§Ç‡§¨‡§∞ 1945 09 ‡§Ö‡§ï‡•ç‡§ü‡•Ç‡§¨‡§∞ 2006 ‡§™‡•ã‡§≤‡•à‡§Ç‡§°‡•Ä ‡§ó‡§æ‡§Ø‡§ï, ‡§∏‡§Ç‡§ó‡•Ä‡§§‡§ï‡§æ‡§∞, ‡§ï‡§µ‡§ø ‡§î‡§∞ ‡§ö‡§ø‡§§‡•ç‡§∞‡§ï‡§æ‡§∞ ‡§•‡•á.\n"
     ]
    }
   ],
   "source": [
    "text = test_df['input'].iat[60]\n",
    "correct = test_df['output'].iat[60]\n",
    "print(\"Incorrect Sentence:\", text)\n",
    "print(\"Correct Seentence:\",correct)\n",
    "predicted_s = correct_grammar(text, num_return_sequences=1)[0]\n",
    "l = len(correct)\n",
    "p = len(predicted_s)\n",
    "if(p>l):\n",
    "    predicted_s = predicted_s[:l]\n",
    "print(\"Predicted Sentence:\",predicted_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7cf190-899c-4fc6-9954-59ba79ef6614",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d488748e-8345-4b94-baf3-84925a29ba2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Sentence: ‡§Ü‡§ú ‡§π‡§Æ ‡§Ü‡§™‡§ï‡•ã ‡§π‡§æ‡§∞‡•ç‡§¶‡§ø‡§ï ‡§™‡§æ‡§Ç‡§°‡•ç‡§Ø‡§æ ‡§ï‡•Ä ‡§ê‡§∏‡•Ä 5 ‡§¨‡§æ‡§§‡•á ‡§¨‡§§‡§æ‡§®‡•á ‡§ú‡§æ ‡§∞‡§π‡•á ‡§π‡•à ‡§ú‡§ø‡§®‡•ç‡§π‡•á‡§Ç ‡§Ü‡§™ ‡§∂‡§æ‡§Ø‡§¶ ‡§π‡•Ä ‡§ú‡§æ‡§®‡§§‡•á ‡§π‡•ã‡§Ç‡§ó‡•á.\n",
      "Correct Seentence: ‡§Ü‡§ú ‡§π‡§Æ ‡§Ü‡§™‡§ï‡•ã ‡§π‡§æ‡§∞‡•ç‡§¶‡§ø‡§ï ‡§™‡§æ‡§Ç‡§°‡•ç‡§Ø‡§æ ‡§ï‡•Ä ‡§ê‡§∏‡•Ä 5 ‡§¨‡§æ‡§§‡•á ‡§¨‡§§‡§æ‡§®‡•á ‡§ú‡§æ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç ‡§ú‡§ø‡§®‡•ç‡§π‡•á‡§Ç ‡§Ü‡§™ ‡§∂‡§æ‡§Ø‡§¶ ‡§π‡•Ä ‡§ú‡§æ‡§®‡§§‡•á ‡§π‡•ã‡§Ç‡§ó‡•á.\n",
      "Predicted Sentence: ‡§Ü‡§ú ‡§π‡§Æ ‡§Ü‡§™‡§ï‡•ã ‡§π‡§æ‡§∞‡•ç‡§¶‡§ø‡§ï ‡§™‡§æ‡§Ç‡§°‡•ç‡§Ø‡§æ ‡§ï‡•Ä ‡§ê‡§∏‡•Ä 5 ‡§¨‡§æ‡§§‡•á ‡§¨‡§§‡§æ‡§®‡•á ‡§ú‡§æ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç ‡§ú‡§ø‡§®‡•ç‡§π‡•á‡§Ç ‡§Ü‡§™ ‡§∂‡§æ‡§Ø‡§¶ ‡§π‡•Ä ‡§ú‡§æ‡§®‡§§‡•á ‡§π‡•ã‡§Ç‡§ó‡•á.\n"
     ]
    }
   ],
   "source": [
    "text = test_df['input'].iat[51]\n",
    "correct = test_df['output'].iat[51]\n",
    "print(\"Incorrect Sentence:\", text)\n",
    "print(\"Correct Seentence:\",correct)\n",
    "predicted_s = correct_grammar(text, num_return_sequences=1)[0]\n",
    "print(\"Predicted Sentence:\",predicted_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a2adc94a-4fc3-4eb6-b336-574d99c230eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Sentence: ‡§™‡•ç‡§∞‡§æ‡§∞‡§Ç‡§≠‡§ø‡§ï ‡§ú‡•Ä‡§µ‡§® ‡§î‡§∞ ‡§™‡§∞‡§ø‡§µ‡§æ‡§∞ ‡§ï‡•á ‡§á‡§§‡§ø‡§π‡§æ‡§∏.\n",
      "Correct Seentence: ‡§™‡•ç‡§∞‡§æ‡§∞‡§Ç‡§≠‡§ø‡§ï ‡§ú‡•Ä‡§µ‡§® ‡§î‡§∞ ‡§™‡§∞‡§ø‡§µ‡§æ‡§∞ ‡§ï‡§æ ‡§á‡§§‡§ø‡§π‡§æ‡§∏.\n",
      "Predicted Sentence: ‡§™‡•ç‡§∞‡§æ‡§∞‡§Ç‡§≠‡§ø‡§ï ‡§ú‡•Ä‡§µ‡§® ‡§î‡§∞ ‡§™‡§∞‡§ø‡§µ‡§æ‡§∞ ‡§ï‡•Ä ‡§á‡§§‡§ø‡§π‡§æ‡§∏.\n"
     ]
    }
   ],
   "source": [
    "text = test_df['input'].iat[20]\n",
    "correct = test_df['output'].iat[20]\n",
    "print(\"Incorrect Sentence:\", text)\n",
    "print(\"Correct Seentence:\",correct)\n",
    "predicted_s = correct_grammar(text, num_return_sequences=1)[0]\n",
    "p=len(predicted_s)\n",
    "l = len(text)\n",
    "if(p>l):\n",
    "    predicted_s = predicted_s[:l]\n",
    "print(\"Predicted Sentence:\",predicted_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b37d9f-25df-483f-a3c3-29603e854408",
   "metadata": {},
   "source": [
    "# Performance Analysis\n",
    "1. BLEU Score\n",
    "2. GLEU Score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "18317b87-03d3-4d73-ae22-9cf8cb8e1db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(259289, 3)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "da058ef4-524c-4808-a1ba-bbd143f534d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>input_token_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>677358</th>\n",
       "      <td>‡§Ö‡§¨ ‡§ï‡§ø‡§∂‡§® ‡§Ö‡§™‡§®‡•á ‡§≠‡§æ‡§à ‡§ï‡§æ ‡§¨‡§¶‡§≤‡§æ ‡§≤‡•á‡§®‡•á ‡§ï‡•Ä ‡§∏‡•ã‡§ö‡§§‡§æ ‡§π‡•à, ‡§™‡§∞ ‡§ï‡§à ‡§ì‡§∞ ‡§∏‡•á ‡§ò‡§ø‡§∞‡•Ä ‡§≠‡•Ä ‡§π‡•ã‡§§‡§æ ‡§π‡•à.</td>\n",
       "      <td>‡§Ö‡§¨ ‡§ï‡§ø‡§∂‡§® ‡§Ö‡§™‡§®‡•á ‡§≠‡§æ‡§à ‡§ï‡§æ ‡§¨‡§¶‡§≤‡§æ ‡§≤‡•á‡§®‡•á ‡§ï‡•Ä ‡§∏‡•ã‡§ö‡§§‡§æ ‡§π‡•à, ‡§™‡§∞ ‡§ï‡§à ‡§ì‡§∞ ‡§∏‡•á ‡§ò‡§ø‡§∞‡§æ ‡§≠‡•Ä ‡§π‡•ã‡§§‡§æ ‡§π‡•à.</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2028550</th>\n",
       "      <td>‡§á‡§∏‡•á ‡§á‡§≤‡•ç‡§¶‡•á‡§ú‡§ø‡§ú‡§º ‡§ï‡•á ‡§¶‡•ã‡§®‡•ã‡§Ç ‡§™‡•Å‡§§‡•ç‡§∞‡•ã‡§Ç ‡§Æ‡•Å‡§π‡§Æ‡•ç‡§Æ‡§¶ ‡§î‡§∞ ‡§ï‡§ø‡§ú‡§º‡§ø‡§≤ ‡§Ö‡§∞‡§∏‡§§‡§® ‡§ï‡•ã ‡§∏‡§Æ‡§∞‡•ç‡§™‡§ø‡§§ ‡§ï‡•Ä‡§Ç ‡§ó‡§Ø‡§æ ‡§•‡§æ.</td>\n",
       "      <td>‡§á‡§∏‡•á ‡§á‡§≤‡•ç‡§¶‡•á‡§ú‡§ø‡§ú‡§º ‡§ï‡•á ‡§¶‡•ã‡§®‡•ã‡§Ç ‡§™‡•Å‡§§‡•ç‡§∞‡•ã‡§Ç ‡§Æ‡•Å‡§π‡§Æ‡•ç‡§Æ‡§¶ ‡§î‡§∞ ‡§ï‡§ø‡§ú‡§º‡§ø‡§≤ ‡§Ö‡§∞‡§∏‡§§‡§® ‡§ï‡•ã ‡§∏‡§Æ‡§∞‡•ç‡§™‡§ø‡§§ ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§•‡§æ.</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328281</th>\n",
       "      <td>‡§∂‡§µ ‡§ï‡•ã ‡§°‡•á‡§¢‡§º ‡§≤‡§æ‡§ñ ‡§≤‡•ã‡§ó‡•ã‡§Ç ‡§®‡•á ‡§ú‡•Å‡§≤‡•Ç‡§∏ ‡§®‡§ø‡§ï‡§æ‡§≤ ‡§ï‡§∞ ‡§™‡•Ç‡§∞‡•á ‡§∂‡§π‡§∞ ‡§Æ‡•á‡§Ç ‡§ò‡•Å‡§Æ‡§æ‡§§‡•á ‡§π‡•Å‡§è ‡§∞‡§æ‡§™‡•ç‡§§‡•Ä ‡§®‡§¶‡•Ä ‡§ï‡•á ‡§ï‡§ø‡§®‡§æ‡§∞‡•á ‡§∞‡§æ‡§ú‡§ò‡§æ‡§ü ‡§™‡§∞ ‡§â‡§∏‡§ï‡§æ ‡§Ö‡§®‡•ç‡§§‡§ø‡§Æ ‡§∏‡§Ç‡§∏‡•ç‡§ï‡§æ‡§∞ ‡§ï‡§∞ ‡§¶‡•Ä.</td>\n",
       "      <td>‡§∂‡§µ ‡§ï‡•ã ‡§°‡•á‡§¢‡§º ‡§≤‡§æ‡§ñ ‡§≤‡•ã‡§ó‡•ã‡§Ç ‡§®‡•á ‡§ú‡•Å‡§≤‡•Ç‡§∏ ‡§®‡§ø‡§ï‡§æ‡§≤ ‡§ï‡§∞ ‡§™‡•Ç‡§∞‡•á ‡§∂‡§π‡§∞ ‡§Æ‡•á‡§Ç ‡§ò‡•Å‡§Æ‡§æ‡§§‡•á ‡§π‡•Å‡§è ‡§∞‡§æ‡§™‡•ç‡§§‡•Ä ‡§®‡§¶‡•Ä ‡§ï‡•á ‡§ï‡§ø‡§®‡§æ‡§∞‡•á ‡§∞‡§æ‡§ú‡§ò‡§æ‡§ü ‡§™‡§∞ ‡§â‡§∏‡§ï‡§æ ‡§Ö‡§®‡•ç‡§§‡§ø‡§Æ ‡§∏‡§Ç‡§∏‡•ç‡§ï‡§æ‡§∞ ‡§ï‡§∞ ‡§¶‡§ø‡§Ø‡§æ.</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188804</th>\n",
       "      <td>‡§∏‡•Ç‡§ñ‡•Ä ‡§Æ‡§π‡•Ä‡§®‡•ã‡§Ç ‡§Ø‡§æ ‡§µ‡§∞‡•ç‡§∑‡•ã‡§Ç ‡§§‡§ï ‡§∞‡§π ‡§∏‡§ï‡§§‡§æ ‡§π‡•à, ‡§î‡§∞ ‡§á‡§∏‡•á 15 ‡§¶‡§ø‡§®‡•ã‡§Ç ‡§ï‡•á ‡§¨‡§æ‡§¶ ‡§ò‡•ã‡§∑‡§ø‡§§ ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à.</td>\n",
       "      <td>‡§∏‡•Ç‡§ñ‡§æ ‡§Æ‡§π‡•Ä‡§®‡•ã‡§Ç ‡§Ø‡§æ ‡§µ‡§∞‡•ç‡§∑‡•ã‡§Ç ‡§§‡§ï ‡§∞‡§π ‡§∏‡§ï‡§§‡§æ ‡§π‡•à, ‡§î‡§∞ ‡§á‡§∏‡•á 15 ‡§¶‡§ø‡§®‡•ã‡§Ç ‡§ï‡•á ‡§¨‡§æ‡§¶ ‡§ò‡•ã‡§∑‡§ø‡§§ ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à.</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2513989</th>\n",
       "      <td>‡§≠‡§æ‡§Ç‡§°‡•Å‡§™ ‡§Æ‡•Å‡§Ç‡§¨‡§à ‡§ï‡•Ä ‡§è‡§ï ‡§â‡§™‡§®‡§ó‡§∞ ‡§π‡•à.</td>\n",
       "      <td>‡§≠‡§æ‡§Ç‡§°‡•Å‡§™ ‡§Æ‡•Å‡§Ç‡§¨‡§à ‡§ï‡§æ ‡§è‡§ï ‡§â‡§™‡§®‡§ó‡§∞ ‡§π‡•à.</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                            input  \\\n",
       "677358                                                    ‡§Ö‡§¨ ‡§ï‡§ø‡§∂‡§® ‡§Ö‡§™‡§®‡•á ‡§≠‡§æ‡§à ‡§ï‡§æ ‡§¨‡§¶‡§≤‡§æ ‡§≤‡•á‡§®‡•á ‡§ï‡•Ä ‡§∏‡•ã‡§ö‡§§‡§æ ‡§π‡•à, ‡§™‡§∞ ‡§ï‡§à ‡§ì‡§∞ ‡§∏‡•á ‡§ò‡§ø‡§∞‡•Ä ‡§≠‡•Ä ‡§π‡•ã‡§§‡§æ ‡§π‡•à.   \n",
       "2028550                                             ‡§á‡§∏‡•á ‡§á‡§≤‡•ç‡§¶‡•á‡§ú‡§ø‡§ú‡§º ‡§ï‡•á ‡§¶‡•ã‡§®‡•ã‡§Ç ‡§™‡•Å‡§§‡•ç‡§∞‡•ã‡§Ç ‡§Æ‡•Å‡§π‡§Æ‡•ç‡§Æ‡§¶ ‡§î‡§∞ ‡§ï‡§ø‡§ú‡§º‡§ø‡§≤ ‡§Ö‡§∞‡§∏‡§§‡§® ‡§ï‡•ã ‡§∏‡§Æ‡§∞‡•ç‡§™‡§ø‡§§ ‡§ï‡•Ä‡§Ç ‡§ó‡§Ø‡§æ ‡§•‡§æ.   \n",
       "328281   ‡§∂‡§µ ‡§ï‡•ã ‡§°‡•á‡§¢‡§º ‡§≤‡§æ‡§ñ ‡§≤‡•ã‡§ó‡•ã‡§Ç ‡§®‡•á ‡§ú‡•Å‡§≤‡•Ç‡§∏ ‡§®‡§ø‡§ï‡§æ‡§≤ ‡§ï‡§∞ ‡§™‡•Ç‡§∞‡•á ‡§∂‡§π‡§∞ ‡§Æ‡•á‡§Ç ‡§ò‡•Å‡§Æ‡§æ‡§§‡•á ‡§π‡•Å‡§è ‡§∞‡§æ‡§™‡•ç‡§§‡•Ä ‡§®‡§¶‡•Ä ‡§ï‡•á ‡§ï‡§ø‡§®‡§æ‡§∞‡•á ‡§∞‡§æ‡§ú‡§ò‡§æ‡§ü ‡§™‡§∞ ‡§â‡§∏‡§ï‡§æ ‡§Ö‡§®‡•ç‡§§‡§ø‡§Æ ‡§∏‡§Ç‡§∏‡•ç‡§ï‡§æ‡§∞ ‡§ï‡§∞ ‡§¶‡•Ä.   \n",
       "188804                                         ‡§∏‡•Ç‡§ñ‡•Ä ‡§Æ‡§π‡•Ä‡§®‡•ã‡§Ç ‡§Ø‡§æ ‡§µ‡§∞‡•ç‡§∑‡•ã‡§Ç ‡§§‡§ï ‡§∞‡§π ‡§∏‡§ï‡§§‡§æ ‡§π‡•à, ‡§î‡§∞ ‡§á‡§∏‡•á 15 ‡§¶‡§ø‡§®‡•ã‡§Ç ‡§ï‡•á ‡§¨‡§æ‡§¶ ‡§ò‡•ã‡§∑‡§ø‡§§ ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à.   \n",
       "2513989                                                                                              ‡§≠‡§æ‡§Ç‡§°‡•Å‡§™ ‡§Æ‡•Å‡§Ç‡§¨‡§à ‡§ï‡•Ä ‡§è‡§ï ‡§â‡§™‡§®‡§ó‡§∞ ‡§π‡•à.   \n",
       "\n",
       "                                                                                                                             output  \\\n",
       "677358                                                      ‡§Ö‡§¨ ‡§ï‡§ø‡§∂‡§® ‡§Ö‡§™‡§®‡•á ‡§≠‡§æ‡§à ‡§ï‡§æ ‡§¨‡§¶‡§≤‡§æ ‡§≤‡•á‡§®‡•á ‡§ï‡•Ä ‡§∏‡•ã‡§ö‡§§‡§æ ‡§π‡•à, ‡§™‡§∞ ‡§ï‡§à ‡§ì‡§∞ ‡§∏‡•á ‡§ò‡§ø‡§∞‡§æ ‡§≠‡•Ä ‡§π‡•ã‡§§‡§æ ‡§π‡•à.   \n",
       "2028550                                              ‡§á‡§∏‡•á ‡§á‡§≤‡•ç‡§¶‡•á‡§ú‡§ø‡§ú‡§º ‡§ï‡•á ‡§¶‡•ã‡§®‡•ã‡§Ç ‡§™‡•Å‡§§‡•ç‡§∞‡•ã‡§Ç ‡§Æ‡•Å‡§π‡§Æ‡•ç‡§Æ‡§¶ ‡§î‡§∞ ‡§ï‡§ø‡§ú‡§º‡§ø‡§≤ ‡§Ö‡§∞‡§∏‡§§‡§® ‡§ï‡•ã ‡§∏‡§Æ‡§∞‡•ç‡§™‡§ø‡§§ ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§•‡§æ.   \n",
       "328281   ‡§∂‡§µ ‡§ï‡•ã ‡§°‡•á‡§¢‡§º ‡§≤‡§æ‡§ñ ‡§≤‡•ã‡§ó‡•ã‡§Ç ‡§®‡•á ‡§ú‡•Å‡§≤‡•Ç‡§∏ ‡§®‡§ø‡§ï‡§æ‡§≤ ‡§ï‡§∞ ‡§™‡•Ç‡§∞‡•á ‡§∂‡§π‡§∞ ‡§Æ‡•á‡§Ç ‡§ò‡•Å‡§Æ‡§æ‡§§‡•á ‡§π‡•Å‡§è ‡§∞‡§æ‡§™‡•ç‡§§‡•Ä ‡§®‡§¶‡•Ä ‡§ï‡•á ‡§ï‡§ø‡§®‡§æ‡§∞‡•á ‡§∞‡§æ‡§ú‡§ò‡§æ‡§ü ‡§™‡§∞ ‡§â‡§∏‡§ï‡§æ ‡§Ö‡§®‡•ç‡§§‡§ø‡§Æ ‡§∏‡§Ç‡§∏‡•ç‡§ï‡§æ‡§∞ ‡§ï‡§∞ ‡§¶‡§ø‡§Ø‡§æ.   \n",
       "188804                                           ‡§∏‡•Ç‡§ñ‡§æ ‡§Æ‡§π‡•Ä‡§®‡•ã‡§Ç ‡§Ø‡§æ ‡§µ‡§∞‡•ç‡§∑‡•ã‡§Ç ‡§§‡§ï ‡§∞‡§π ‡§∏‡§ï‡§§‡§æ ‡§π‡•à, ‡§î‡§∞ ‡§á‡§∏‡•á 15 ‡§¶‡§ø‡§®‡•ã‡§Ç ‡§ï‡•á ‡§¨‡§æ‡§¶ ‡§ò‡•ã‡§∑‡§ø‡§§ ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à.   \n",
       "2513989                                                                                                ‡§≠‡§æ‡§Ç‡§°‡•Å‡§™ ‡§Æ‡•Å‡§Ç‡§¨‡§à ‡§ï‡§æ ‡§è‡§ï ‡§â‡§™‡§®‡§ó‡§∞ ‡§π‡•à.   \n",
       "\n",
       "         input_token_len  \n",
       "677358                23  \n",
       "2028550               24  \n",
       "328281                31  \n",
       "188804                23  \n",
       "2513989               11  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a70f87cd-f789-4070-898d-25f6937deb4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>input_token_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>677358</th>\n",
       "      <td>‡§Ö‡§¨ ‡§ï‡§ø‡§∂‡§® ‡§Ö‡§™‡§®‡•á ‡§≠‡§æ‡§à ‡§ï‡§æ ‡§¨‡§¶‡§≤‡§æ ‡§≤‡•á‡§®‡•á ‡§ï‡•Ä ‡§∏‡•ã‡§ö‡§§‡§æ ‡§π‡•à, ‡§™‡§∞ ‡§ï‡§à ‡§ì‡§∞ ‡§∏‡•á ‡§ò‡§ø‡§∞‡•Ä ‡§≠‡•Ä ‡§π‡•ã‡§§‡§æ ‡§π‡•à.</td>\n",
       "      <td>‡§Ö‡§¨ ‡§ï‡§ø‡§∂‡§® ‡§Ö‡§™‡§®‡•á ‡§≠‡§æ‡§à ‡§ï‡§æ ‡§¨‡§¶‡§≤‡§æ ‡§≤‡•á‡§®‡•á ‡§ï‡•Ä ‡§∏‡•ã‡§ö‡§§‡§æ ‡§π‡•à, ‡§™‡§∞ ‡§ï‡§à ‡§ì‡§∞ ‡§∏‡•á ‡§ò‡§ø‡§∞‡§æ ‡§≠‡•Ä ‡§π‡•ã‡§§‡§æ ‡§π‡•à.</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2028550</th>\n",
       "      <td>‡§á‡§∏‡•á ‡§á‡§≤‡•ç‡§¶‡•á‡§ú‡§ø‡§ú‡§º ‡§ï‡•á ‡§¶‡•ã‡§®‡•ã‡§Ç ‡§™‡•Å‡§§‡•ç‡§∞‡•ã‡§Ç ‡§Æ‡•Å‡§π‡§Æ‡•ç‡§Æ‡§¶ ‡§î‡§∞ ‡§ï‡§ø‡§ú‡§º‡§ø‡§≤ ‡§Ö‡§∞‡§∏‡§§‡§® ‡§ï‡•ã ‡§∏‡§Æ‡§∞‡•ç‡§™‡§ø‡§§ ‡§ï‡•Ä‡§Ç ‡§ó‡§Ø‡§æ ‡§•‡§æ.</td>\n",
       "      <td>‡§á‡§∏‡•á ‡§á‡§≤‡•ç‡§¶‡•á‡§ú‡§ø‡§ú‡§º ‡§ï‡•á ‡§¶‡•ã‡§®‡•ã‡§Ç ‡§™‡•Å‡§§‡•ç‡§∞‡•ã‡§Ç ‡§Æ‡•Å‡§π‡§Æ‡•ç‡§Æ‡§¶ ‡§î‡§∞ ‡§ï‡§ø‡§ú‡§º‡§ø‡§≤ ‡§Ö‡§∞‡§∏‡§§‡§® ‡§ï‡•ã ‡§∏‡§Æ‡§∞‡•ç‡§™‡§ø‡§§ ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§•‡§æ.</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328281</th>\n",
       "      <td>‡§∂‡§µ ‡§ï‡•ã ‡§°‡•á‡§¢‡§º ‡§≤‡§æ‡§ñ ‡§≤‡•ã‡§ó‡•ã‡§Ç ‡§®‡•á ‡§ú‡•Å‡§≤‡•Ç‡§∏ ‡§®‡§ø‡§ï‡§æ‡§≤ ‡§ï‡§∞ ‡§™‡•Ç‡§∞‡•á ‡§∂‡§π‡§∞ ‡§Æ‡•á‡§Ç ‡§ò‡•Å‡§Æ‡§æ‡§§‡•á ‡§π‡•Å‡§è ‡§∞‡§æ‡§™‡•ç‡§§‡•Ä ‡§®‡§¶‡•Ä ‡§ï‡•á ‡§ï‡§ø‡§®‡§æ‡§∞‡•á ‡§∞‡§æ‡§ú‡§ò‡§æ‡§ü ‡§™‡§∞ ‡§â‡§∏‡§ï‡§æ ‡§Ö‡§®‡•ç‡§§‡§ø‡§Æ ‡§∏‡§Ç‡§∏‡•ç‡§ï‡§æ‡§∞ ‡§ï‡§∞ ‡§¶‡•Ä.</td>\n",
       "      <td>‡§∂‡§µ ‡§ï‡•ã ‡§°‡•á‡§¢‡§º ‡§≤‡§æ‡§ñ ‡§≤‡•ã‡§ó‡•ã‡§Ç ‡§®‡•á ‡§ú‡•Å‡§≤‡•Ç‡§∏ ‡§®‡§ø‡§ï‡§æ‡§≤ ‡§ï‡§∞ ‡§™‡•Ç‡§∞‡•á ‡§∂‡§π‡§∞ ‡§Æ‡•á‡§Ç ‡§ò‡•Å‡§Æ‡§æ‡§§‡•á ‡§π‡•Å‡§è ‡§∞‡§æ‡§™‡•ç‡§§‡•Ä ‡§®‡§¶‡•Ä ‡§ï‡•á ‡§ï‡§ø‡§®‡§æ‡§∞‡•á ‡§∞‡§æ‡§ú‡§ò‡§æ‡§ü ‡§™‡§∞ ‡§â‡§∏‡§ï‡§æ ‡§Ö‡§®‡•ç‡§§‡§ø‡§Æ ‡§∏‡§Ç‡§∏‡•ç‡§ï‡§æ‡§∞ ‡§ï‡§∞ ‡§¶‡§ø‡§Ø‡§æ.</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188804</th>\n",
       "      <td>‡§∏‡•Ç‡§ñ‡•Ä ‡§Æ‡§π‡•Ä‡§®‡•ã‡§Ç ‡§Ø‡§æ ‡§µ‡§∞‡•ç‡§∑‡•ã‡§Ç ‡§§‡§ï ‡§∞‡§π ‡§∏‡§ï‡§§‡§æ ‡§π‡•à, ‡§î‡§∞ ‡§á‡§∏‡•á 15 ‡§¶‡§ø‡§®‡•ã‡§Ç ‡§ï‡•á ‡§¨‡§æ‡§¶ ‡§ò‡•ã‡§∑‡§ø‡§§ ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à.</td>\n",
       "      <td>‡§∏‡•Ç‡§ñ‡§æ ‡§Æ‡§π‡•Ä‡§®‡•ã‡§Ç ‡§Ø‡§æ ‡§µ‡§∞‡•ç‡§∑‡•ã‡§Ç ‡§§‡§ï ‡§∞‡§π ‡§∏‡§ï‡§§‡§æ ‡§π‡•à, ‡§î‡§∞ ‡§á‡§∏‡•á 15 ‡§¶‡§ø‡§®‡•ã‡§Ç ‡§ï‡•á ‡§¨‡§æ‡§¶ ‡§ò‡•ã‡§∑‡§ø‡§§ ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à.</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2513989</th>\n",
       "      <td>‡§≠‡§æ‡§Ç‡§°‡•Å‡§™ ‡§Æ‡•Å‡§Ç‡§¨‡§à ‡§ï‡•Ä ‡§è‡§ï ‡§â‡§™‡§®‡§ó‡§∞ ‡§π‡•à.</td>\n",
       "      <td>‡§≠‡§æ‡§Ç‡§°‡•Å‡§™ ‡§Æ‡•Å‡§Ç‡§¨‡§à ‡§ï‡§æ ‡§è‡§ï ‡§â‡§™‡§®‡§ó‡§∞ ‡§π‡•à.</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2405409</th>\n",
       "      <td>‡§Ü‡§ö‡§æ‡§∞‡•ç‡§Ø ‡§ß‡§∞‡•ç‡§Æ‡§™‡§æ‡§≤ ‡§®‡§æ‡§≤‡§Ç‡§¶‡§æ ‡§Æ‡§π‡§æ‡§µ‡§ø‡§π‡§æ‡§∞ ‡§ï‡•á ‡§ï‡•Å‡§≤‡§™‡§§‡§ø ‡§•‡•á ‡§ú‡§ø‡§®‡§ï‡§æ ‡§∂‡§ø‡§∑‡•ç‡§Ø ‡§∂‡•Ä‡§≤‡§≠‡§¶‡•ç‡§∞ ‡§π‡•ç‡§µ‡•á‡§®‡•ç‡§§‡•ç‡§∏‡§æ‡§Ç‡§ó ‡§ï‡•ã ‡§Æ‡§π‡§æ‡§Ø‡§æ‡§® ‡§ï‡•á ‡§™‡•ç‡§∞‡§Æ‡•Å‡§ñ ‡§ó‡•ç‡§∞‡§Ç‡§•‡•ã‡§Ç ‡§ï‡§æ ‡§Ö‡§ß‡•ç‡§Ø‡§æ‡§™‡§® ‡§ï‡§∞‡§æ‡§Ø‡§æ ‡§•‡§æ.</td>\n",
       "      <td>‡§Ü‡§ö‡§æ‡§∞‡•ç‡§Ø ‡§ß‡§∞‡•ç‡§Æ‡§™‡§æ‡§≤ ‡§®‡§æ‡§≤‡§Ç‡§¶‡§æ ‡§Æ‡§π‡§æ‡§µ‡§ø‡§π‡§æ‡§∞ ‡§ï‡•á ‡§ï‡•Å‡§≤‡§™‡§§‡§ø ‡§•‡•á ‡§ú‡§ø‡§®‡§ï‡•á ‡§∂‡§ø‡§∑‡•ç‡§Ø ‡§∂‡•Ä‡§≤‡§≠‡§¶‡•ç‡§∞ ‡§π‡•ç‡§µ‡•á‡§®‡•ç‡§§‡•ç‡§∏‡§æ‡§Ç‡§ó ‡§ï‡•ã ‡§Æ‡§π‡§æ‡§Ø‡§æ‡§® ‡§ï‡•á ‡§™‡•ç‡§∞‡§Æ‡•Å‡§ñ ‡§ó‡•ç‡§∞‡§Ç‡§•‡•ã‡§Ç ‡§ï‡§æ ‡§Ö‡§ß‡•ç‡§Ø‡§æ‡§™‡§® ‡§ï‡§∞‡§æ‡§Ø‡§æ ‡§•‡§æ.</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985351</th>\n",
       "      <td>‡§î‡§∞‡§§‡•á‡§Ç ‡§§‡•Ä‡§ú ‡§î‡§∞ ‡§ï‡§∞‡§µ‡•Ä ‡§ö‡•å‡§• ‡§ï‡•Ä ‡§ú‡§ó‡§π ‡§∏‡•ç‡§µ‡§§‡§Ç‡§§‡•ç‡§∞‡§§‡§æ ‡§¶‡§ø‡§µ‡§∏ ‡§î‡§∞ ‡§ó‡§£‡§§‡§Ç‡§§‡•ç‡§∞‡§§‡§æ ‡§¶‡§ø‡§µ‡§∏ ‡§ï‡§æ ‡§Ü‡§®‡§Ç‡§¶ ‡§≤‡•á‡§ó‡•Ä.</td>\n",
       "      <td>‡§î‡§∞‡§§‡•á‡§Ç ‡§§‡•Ä‡§ú ‡§î‡§∞ ‡§ï‡§∞‡§µ‡§æ ‡§ö‡•å‡§• ‡§ï‡•Ä ‡§ú‡§ó‡§π ‡§∏‡•ç‡§µ‡§§‡§Ç‡§§‡•ç‡§∞‡§§‡§æ ‡§¶‡§ø‡§µ‡§∏ ‡§î‡§∞ ‡§ó‡§£‡§§‡§Ç‡§§‡•ç‡§∞‡§§‡§æ ‡§¶‡§ø‡§µ‡§∏ ‡§ï‡§æ ‡§Ü‡§®‡§Ç‡§¶ ‡§≤‡•á‡§ó‡•Ä.</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911740</th>\n",
       "      <td>‡§è‡§ï‡§¶‡§∞‡§¨‡•á‡§≤‡§æ ‡§®‡•á‡§™‡§æ‡§≤ ‡§ï‡•á ‡§ú‡§®‡§ï‡§™‡•Å‡§∞ ‡§Ö‡§Ç‡§ö‡§≤ ‡§ï‡§æ ‡§Æ‡§π‡•ã‡§§‡•ç‡§§‡§∞‡•Ä ‡§ú‡§ø‡§≤‡§æ ‡§ï‡•á ‡§è‡§ï ‡§ó‡§æ‡§Ç‡§µ ‡§µ‡§ø‡§ï‡§æ‡§∏ ‡§∏‡§Æ‡§ø‡§§‡§ø ‡§π‡•à.</td>\n",
       "      <td>‡§è‡§ï‡§¶‡§∞‡§¨‡•á‡§≤‡§æ ‡§®‡•á‡§™‡§æ‡§≤ ‡§ï‡•á ‡§ú‡§®‡§ï‡§™‡•Å‡§∞ ‡§Ö‡§Ç‡§ö‡§≤ ‡§ï‡§æ ‡§Æ‡§π‡•ã‡§§‡•ç‡§§‡§∞‡•Ä ‡§ú‡§ø‡§≤‡§æ ‡§ï‡§æ ‡§è‡§ï ‡§ó‡§æ‡§Ç‡§µ ‡§µ‡§ø‡§ï‡§æ‡§∏ ‡§∏‡§Æ‡§ø‡§§‡§ø ‡§π‡•à.</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621202</th>\n",
       "      <td>‡§Ø‡§π‡§æ‡§Ç ‡§∞‡§π‡§®‡•á ‡§µ‡§æ‡§≤‡•á ‡§ï‡§à ‡§ú‡•Ä‡§µ‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§ú‡•Ä‡§µ‡§¶‡•Ä‡§™‡•ç‡§§‡§ø ‡§≠‡•Ä ‡§¶‡•á‡§ñ‡•Ä ‡§ú‡§æ‡§§‡•Ä ‡§π‡•à‡§Ç.</td>\n",
       "      <td>‡§Ø‡§π‡§æ‡§Ç ‡§∞‡§π‡§®‡•á ‡§µ‡§æ‡§≤‡•á ‡§ï‡§à ‡§ú‡•Ä‡§µ‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§ú‡•Ä‡§µ‡§¶‡•Ä‡§™‡•ç‡§§‡§ø ‡§≠‡•Ä ‡§¶‡•á‡§ñ‡•Ä ‡§ú‡§æ‡§§‡•Ä ‡§π‡•à.</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068003</th>\n",
       "      <td>‡§≤‡•ã‡§Ö‡§∞ ‡§ó‡§Ç‡§ó‡§æ ‡§Ö‡§¨ ‡§≠‡•Ä ‡§¨‡§π‡•Å‡§§ ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§π‡•à‡§Ç, ‡§î‡§∞ ‡§∏‡§≠‡•Ä ‡§µ‡§∞‡•ç‡§∑ ‡§¶‡•å‡§∞ ‡§Æ‡•á‡§Ç ‡§Ø‡§æ‡§§‡§æ‡§Ø‡§æ‡§§ ‡§π‡•à.</td>\n",
       "      <td>‡§≤‡•ã‡§Ö‡§∞ ‡§ó‡§Ç‡§ó‡§æ ‡§Ö‡§¨ ‡§≠‡•Ä ‡§¨‡§π‡•Å‡§§ ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§π‡•à, ‡§î‡§∞ ‡§∏‡§≠‡•Ä ‡§µ‡§∞‡•ç‡§∑ ‡§¶‡•å‡§∞ ‡§Æ‡•á‡§Ç ‡§Ø‡§æ‡§§‡§æ‡§Ø‡§æ‡§§ ‡§π‡•à.</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>259289 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                 input  \\\n",
       "677358                                                         ‡§Ö‡§¨ ‡§ï‡§ø‡§∂‡§® ‡§Ö‡§™‡§®‡•á ‡§≠‡§æ‡§à ‡§ï‡§æ ‡§¨‡§¶‡§≤‡§æ ‡§≤‡•á‡§®‡•á ‡§ï‡•Ä ‡§∏‡•ã‡§ö‡§§‡§æ ‡§π‡•à, ‡§™‡§∞ ‡§ï‡§à ‡§ì‡§∞ ‡§∏‡•á ‡§ò‡§ø‡§∞‡•Ä ‡§≠‡•Ä ‡§π‡•ã‡§§‡§æ ‡§π‡•à.   \n",
       "2028550                                                  ‡§á‡§∏‡•á ‡§á‡§≤‡•ç‡§¶‡•á‡§ú‡§ø‡§ú‡§º ‡§ï‡•á ‡§¶‡•ã‡§®‡•ã‡§Ç ‡§™‡•Å‡§§‡•ç‡§∞‡•ã‡§Ç ‡§Æ‡•Å‡§π‡§Æ‡•ç‡§Æ‡§¶ ‡§î‡§∞ ‡§ï‡§ø‡§ú‡§º‡§ø‡§≤ ‡§Ö‡§∞‡§∏‡§§‡§® ‡§ï‡•ã ‡§∏‡§Æ‡§∞‡•ç‡§™‡§ø‡§§ ‡§ï‡•Ä‡§Ç ‡§ó‡§Ø‡§æ ‡§•‡§æ.   \n",
       "328281        ‡§∂‡§µ ‡§ï‡•ã ‡§°‡•á‡§¢‡§º ‡§≤‡§æ‡§ñ ‡§≤‡•ã‡§ó‡•ã‡§Ç ‡§®‡•á ‡§ú‡•Å‡§≤‡•Ç‡§∏ ‡§®‡§ø‡§ï‡§æ‡§≤ ‡§ï‡§∞ ‡§™‡•Ç‡§∞‡•á ‡§∂‡§π‡§∞ ‡§Æ‡•á‡§Ç ‡§ò‡•Å‡§Æ‡§æ‡§§‡•á ‡§π‡•Å‡§è ‡§∞‡§æ‡§™‡•ç‡§§‡•Ä ‡§®‡§¶‡•Ä ‡§ï‡•á ‡§ï‡§ø‡§®‡§æ‡§∞‡•á ‡§∞‡§æ‡§ú‡§ò‡§æ‡§ü ‡§™‡§∞ ‡§â‡§∏‡§ï‡§æ ‡§Ö‡§®‡•ç‡§§‡§ø‡§Æ ‡§∏‡§Ç‡§∏‡•ç‡§ï‡§æ‡§∞ ‡§ï‡§∞ ‡§¶‡•Ä.   \n",
       "188804                                              ‡§∏‡•Ç‡§ñ‡•Ä ‡§Æ‡§π‡•Ä‡§®‡•ã‡§Ç ‡§Ø‡§æ ‡§µ‡§∞‡•ç‡§∑‡•ã‡§Ç ‡§§‡§ï ‡§∞‡§π ‡§∏‡§ï‡§§‡§æ ‡§π‡•à, ‡§î‡§∞ ‡§á‡§∏‡•á 15 ‡§¶‡§ø‡§®‡•ã‡§Ç ‡§ï‡•á ‡§¨‡§æ‡§¶ ‡§ò‡•ã‡§∑‡§ø‡§§ ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à.   \n",
       "2513989                                                                                                   ‡§≠‡§æ‡§Ç‡§°‡•Å‡§™ ‡§Æ‡•Å‡§Ç‡§¨‡§à ‡§ï‡•Ä ‡§è‡§ï ‡§â‡§™‡§®‡§ó‡§∞ ‡§π‡•à.   \n",
       "...                                                                                                                                ...   \n",
       "2405409  ‡§Ü‡§ö‡§æ‡§∞‡•ç‡§Ø ‡§ß‡§∞‡•ç‡§Æ‡§™‡§æ‡§≤ ‡§®‡§æ‡§≤‡§Ç‡§¶‡§æ ‡§Æ‡§π‡§æ‡§µ‡§ø‡§π‡§æ‡§∞ ‡§ï‡•á ‡§ï‡•Å‡§≤‡§™‡§§‡§ø ‡§•‡•á ‡§ú‡§ø‡§®‡§ï‡§æ ‡§∂‡§ø‡§∑‡•ç‡§Ø ‡§∂‡•Ä‡§≤‡§≠‡§¶‡•ç‡§∞ ‡§π‡•ç‡§µ‡•á‡§®‡•ç‡§§‡•ç‡§∏‡§æ‡§Ç‡§ó ‡§ï‡•ã ‡§Æ‡§π‡§æ‡§Ø‡§æ‡§® ‡§ï‡•á ‡§™‡•ç‡§∞‡§Æ‡•Å‡§ñ ‡§ó‡•ç‡§∞‡§Ç‡§•‡•ã‡§Ç ‡§ï‡§æ ‡§Ö‡§ß‡•ç‡§Ø‡§æ‡§™‡§® ‡§ï‡§∞‡§æ‡§Ø‡§æ ‡§•‡§æ.   \n",
       "985351                                                    ‡§î‡§∞‡§§‡•á‡§Ç ‡§§‡•Ä‡§ú ‡§î‡§∞ ‡§ï‡§∞‡§µ‡•Ä ‡§ö‡•å‡§• ‡§ï‡•Ä ‡§ú‡§ó‡§π ‡§∏‡•ç‡§µ‡§§‡§Ç‡§§‡•ç‡§∞‡§§‡§æ ‡§¶‡§ø‡§µ‡§∏ ‡§î‡§∞ ‡§ó‡§£‡§§‡§Ç‡§§‡•ç‡§∞‡§§‡§æ ‡§¶‡§ø‡§µ‡§∏ ‡§ï‡§æ ‡§Ü‡§®‡§Ç‡§¶ ‡§≤‡•á‡§ó‡•Ä.   \n",
       "1911740                                                      ‡§è‡§ï‡§¶‡§∞‡§¨‡•á‡§≤‡§æ ‡§®‡•á‡§™‡§æ‡§≤ ‡§ï‡•á ‡§ú‡§®‡§ï‡§™‡•Å‡§∞ ‡§Ö‡§Ç‡§ö‡§≤ ‡§ï‡§æ ‡§Æ‡§π‡•ã‡§§‡•ç‡§§‡§∞‡•Ä ‡§ú‡§ø‡§≤‡§æ ‡§ï‡•á ‡§è‡§ï ‡§ó‡§æ‡§Ç‡§µ ‡§µ‡§ø‡§ï‡§æ‡§∏ ‡§∏‡§Æ‡§ø‡§§‡§ø ‡§π‡•à.   \n",
       "621202                                                                         ‡§Ø‡§π‡§æ‡§Ç ‡§∞‡§π‡§®‡•á ‡§µ‡§æ‡§≤‡•á ‡§ï‡§à ‡§ú‡•Ä‡§µ‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§ú‡•Ä‡§µ‡§¶‡•Ä‡§™‡•ç‡§§‡§ø ‡§≠‡•Ä ‡§¶‡•á‡§ñ‡•Ä ‡§ú‡§æ‡§§‡•Ä ‡§π‡•à‡§Ç.   \n",
       "2068003                                                           ‡§≤‡•ã‡§Ö‡§∞ ‡§ó‡§Ç‡§ó‡§æ ‡§Ö‡§¨ ‡§≠‡•Ä ‡§¨‡§π‡•Å‡§§ ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§π‡•à‡§Ç, ‡§î‡§∞ ‡§∏‡§≠‡•Ä ‡§µ‡§∞‡•ç‡§∑ ‡§¶‡•å‡§∞ ‡§Æ‡•á‡§Ç ‡§Ø‡§æ‡§§‡§æ‡§Ø‡§æ‡§§ ‡§π‡•à.   \n",
       "\n",
       "                                                                                                                                output  \\\n",
       "677358                                                         ‡§Ö‡§¨ ‡§ï‡§ø‡§∂‡§® ‡§Ö‡§™‡§®‡•á ‡§≠‡§æ‡§à ‡§ï‡§æ ‡§¨‡§¶‡§≤‡§æ ‡§≤‡•á‡§®‡•á ‡§ï‡•Ä ‡§∏‡•ã‡§ö‡§§‡§æ ‡§π‡•à, ‡§™‡§∞ ‡§ï‡§à ‡§ì‡§∞ ‡§∏‡•á ‡§ò‡§ø‡§∞‡§æ ‡§≠‡•Ä ‡§π‡•ã‡§§‡§æ ‡§π‡•à.   \n",
       "2028550                                                 ‡§á‡§∏‡•á ‡§á‡§≤‡•ç‡§¶‡•á‡§ú‡§ø‡§ú‡§º ‡§ï‡•á ‡§¶‡•ã‡§®‡•ã‡§Ç ‡§™‡•Å‡§§‡•ç‡§∞‡•ã‡§Ç ‡§Æ‡•Å‡§π‡§Æ‡•ç‡§Æ‡§¶ ‡§î‡§∞ ‡§ï‡§ø‡§ú‡§º‡§ø‡§≤ ‡§Ö‡§∞‡§∏‡§§‡§® ‡§ï‡•ã ‡§∏‡§Æ‡§∞‡•ç‡§™‡§ø‡§§ ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§•‡§æ.   \n",
       "328281      ‡§∂‡§µ ‡§ï‡•ã ‡§°‡•á‡§¢‡§º ‡§≤‡§æ‡§ñ ‡§≤‡•ã‡§ó‡•ã‡§Ç ‡§®‡•á ‡§ú‡•Å‡§≤‡•Ç‡§∏ ‡§®‡§ø‡§ï‡§æ‡§≤ ‡§ï‡§∞ ‡§™‡•Ç‡§∞‡•á ‡§∂‡§π‡§∞ ‡§Æ‡•á‡§Ç ‡§ò‡•Å‡§Æ‡§æ‡§§‡•á ‡§π‡•Å‡§è ‡§∞‡§æ‡§™‡•ç‡§§‡•Ä ‡§®‡§¶‡•Ä ‡§ï‡•á ‡§ï‡§ø‡§®‡§æ‡§∞‡•á ‡§∞‡§æ‡§ú‡§ò‡§æ‡§ü ‡§™‡§∞ ‡§â‡§∏‡§ï‡§æ ‡§Ö‡§®‡•ç‡§§‡§ø‡§Æ ‡§∏‡§Ç‡§∏‡•ç‡§ï‡§æ‡§∞ ‡§ï‡§∞ ‡§¶‡§ø‡§Ø‡§æ.   \n",
       "188804                                              ‡§∏‡•Ç‡§ñ‡§æ ‡§Æ‡§π‡•Ä‡§®‡•ã‡§Ç ‡§Ø‡§æ ‡§µ‡§∞‡•ç‡§∑‡•ã‡§Ç ‡§§‡§ï ‡§∞‡§π ‡§∏‡§ï‡§§‡§æ ‡§π‡•à, ‡§î‡§∞ ‡§á‡§∏‡•á 15 ‡§¶‡§ø‡§®‡•ã‡§Ç ‡§ï‡•á ‡§¨‡§æ‡§¶ ‡§ò‡•ã‡§∑‡§ø‡§§ ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à.   \n",
       "2513989                                                                                                   ‡§≠‡§æ‡§Ç‡§°‡•Å‡§™ ‡§Æ‡•Å‡§Ç‡§¨‡§à ‡§ï‡§æ ‡§è‡§ï ‡§â‡§™‡§®‡§ó‡§∞ ‡§π‡•à.   \n",
       "...                                                                                                                                ...   \n",
       "2405409  ‡§Ü‡§ö‡§æ‡§∞‡•ç‡§Ø ‡§ß‡§∞‡•ç‡§Æ‡§™‡§æ‡§≤ ‡§®‡§æ‡§≤‡§Ç‡§¶‡§æ ‡§Æ‡§π‡§æ‡§µ‡§ø‡§π‡§æ‡§∞ ‡§ï‡•á ‡§ï‡•Å‡§≤‡§™‡§§‡§ø ‡§•‡•á ‡§ú‡§ø‡§®‡§ï‡•á ‡§∂‡§ø‡§∑‡•ç‡§Ø ‡§∂‡•Ä‡§≤‡§≠‡§¶‡•ç‡§∞ ‡§π‡•ç‡§µ‡•á‡§®‡•ç‡§§‡•ç‡§∏‡§æ‡§Ç‡§ó ‡§ï‡•ã ‡§Æ‡§π‡§æ‡§Ø‡§æ‡§® ‡§ï‡•á ‡§™‡•ç‡§∞‡§Æ‡•Å‡§ñ ‡§ó‡•ç‡§∞‡§Ç‡§•‡•ã‡§Ç ‡§ï‡§æ ‡§Ö‡§ß‡•ç‡§Ø‡§æ‡§™‡§® ‡§ï‡§∞‡§æ‡§Ø‡§æ ‡§•‡§æ.   \n",
       "985351                                                    ‡§î‡§∞‡§§‡•á‡§Ç ‡§§‡•Ä‡§ú ‡§î‡§∞ ‡§ï‡§∞‡§µ‡§æ ‡§ö‡•å‡§• ‡§ï‡•Ä ‡§ú‡§ó‡§π ‡§∏‡•ç‡§µ‡§§‡§Ç‡§§‡•ç‡§∞‡§§‡§æ ‡§¶‡§ø‡§µ‡§∏ ‡§î‡§∞ ‡§ó‡§£‡§§‡§Ç‡§§‡•ç‡§∞‡§§‡§æ ‡§¶‡§ø‡§µ‡§∏ ‡§ï‡§æ ‡§Ü‡§®‡§Ç‡§¶ ‡§≤‡•á‡§ó‡•Ä.   \n",
       "1911740                                                      ‡§è‡§ï‡§¶‡§∞‡§¨‡•á‡§≤‡§æ ‡§®‡•á‡§™‡§æ‡§≤ ‡§ï‡•á ‡§ú‡§®‡§ï‡§™‡•Å‡§∞ ‡§Ö‡§Ç‡§ö‡§≤ ‡§ï‡§æ ‡§Æ‡§π‡•ã‡§§‡•ç‡§§‡§∞‡•Ä ‡§ú‡§ø‡§≤‡§æ ‡§ï‡§æ ‡§è‡§ï ‡§ó‡§æ‡§Ç‡§µ ‡§µ‡§ø‡§ï‡§æ‡§∏ ‡§∏‡§Æ‡§ø‡§§‡§ø ‡§π‡•à.   \n",
       "621202                                                                          ‡§Ø‡§π‡§æ‡§Ç ‡§∞‡§π‡§®‡•á ‡§µ‡§æ‡§≤‡•á ‡§ï‡§à ‡§ú‡•Ä‡§µ‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§ú‡•Ä‡§µ‡§¶‡•Ä‡§™‡•ç‡§§‡§ø ‡§≠‡•Ä ‡§¶‡•á‡§ñ‡•Ä ‡§ú‡§æ‡§§‡•Ä ‡§π‡•à.   \n",
       "2068003                                                            ‡§≤‡•ã‡§Ö‡§∞ ‡§ó‡§Ç‡§ó‡§æ ‡§Ö‡§¨ ‡§≠‡•Ä ‡§¨‡§π‡•Å‡§§ ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§π‡•à, ‡§î‡§∞ ‡§∏‡§≠‡•Ä ‡§µ‡§∞‡•ç‡§∑ ‡§¶‡•å‡§∞ ‡§Æ‡•á‡§Ç ‡§Ø‡§æ‡§§‡§æ‡§Ø‡§æ‡§§ ‡§π‡•à.   \n",
       "\n",
       "         input_token_len  \n",
       "677358                23  \n",
       "2028550               24  \n",
       "328281                31  \n",
       "188804                23  \n",
       "2513989               11  \n",
       "...                  ...  \n",
       "2405409               30  \n",
       "985351                20  \n",
       "1911740               19  \n",
       "621202                16  \n",
       "2068003               18  \n",
       "\n",
       "[259289 rows x 3 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676fdee8-3408-49be-a09a-f466f9599502",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "acc0b282-2efa-4674-9c26-7c282fc86759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:04,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [04:22,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  100  data point 0.9157751050731273\n",
      "GELU Score =  0.9157751050731273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.gleu_score import sentence_gleu\n",
    "GLEU_val_emb = []\n",
    "test_data = test_df.head(100)\n",
    "print(test_data.shape)\n",
    "#print(\"here\")\n",
    "itr = 0\n",
    "for ind,i in tqdm(test_data.iterrows(),position=0):\n",
    "    try:\n",
    "        #print(ind,i)\n",
    "        itr+=1\n",
    "        text = str(i.input)\n",
    "        #print(text)\n",
    "        #pred = predict(str(i.enc_input),model)[0].split()\n",
    "        pred = correct_grammar(text, num_return_sequences=1)[0]\n",
    "        l = len(text)\n",
    "        p = len(pred)\n",
    "        if(p>l):\n",
    "            pred = pred[:l]\n",
    "            \n",
    "        act = [str(i.output).split()]\n",
    "        pred_s = str(pred).split()\n",
    "        b = sentence_gleu(act,pred_s)\n",
    "        GLEU_val_emb.append(b)\n",
    "        if(itr%100 ==0):\n",
    "            print(\"GELU Score for \",itr,\" data point\",np.mean(GLEU_val_emb))\n",
    "    except:\n",
    "        print(\"Error\") \n",
    "        continue\n",
    "print(\"GELU Score = \",np.mean(GLEU_val_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2130e4-b422-40d3-be84-730ada29c6a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a435a7a2-f401-4454-bbb9-eef3ea7dace1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "47644d73-5446-4f03-a811-e22af050f85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [02:39,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  100  data point 0.9369473923868874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [05:21,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  200  data point 0.9203796555842938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "300it [08:04,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  300  data point 0.9054771818357039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400it [10:47,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  400  data point 0.9113628405396466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [13:28,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  500  data point 0.908630569472634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "600it [16:08,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  600  data point 0.9102320813490103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "700it [18:49,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  700  data point 0.9118186679206834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "800it [21:30,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  800  data point 0.9100877590947873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "900it [24:12,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  900  data point 0.9116741504812822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [26:55,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  1000  data point 0.9137746486265554\n",
      "GELU Score =  0.9137746486265554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.gleu_score import sentence_gleu\n",
    "GLEU_val_emb = []\n",
    "test_data = test_df.head(100)\n",
    "print(test_data.shape)\n",
    "#print(\"here\")\n",
    "itr = 0\n",
    "for ind,i in tqdm(test_data.iterrows(),position=0):\n",
    "    try:\n",
    "        #print(ind,i)\n",
    "        itr+=1\n",
    "        text = str(i.input)\n",
    "        #print(text)\n",
    "        #pred = predict(str(i.enc_input),model)[0].split()\n",
    "        pred = correct_grammar(text, num_return_sequences=1)[0]\n",
    "        l = len(text)\n",
    "        p = len(pred)\n",
    "        if(p>l):\n",
    "            pred = pred[:l]\n",
    "            \n",
    "        act = [str(i.output).split()]\n",
    "        pred_s = str(pred).split()\n",
    "        b = sentence_gleu(act,pred_s)\n",
    "        GLEU_val_emb.append(b)\n",
    "        if(itr%100 ==0):\n",
    "            print(\"GELU Score for \",itr,\" data point\",np.mean(GLEU_val_emb))\n",
    "    except:\n",
    "        print(\"Error\") \n",
    "        continue\n",
    "print(\"GELU Score = \",np.mean(GLEU_val_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4147c9-ef27-49bd-ace2-618bbfffe21a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d88fd148-1e9a-462c-87d1-ca731d01098c",
   "metadata": {},
   "source": [
    "# Evaluation on Etoori's Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c922895e-82d6-43db-a2c8-113bacd42372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_test = pd.read_csv('DATA/etoori_test.csv')\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab40e4eb-00a5-429e-a837-ed75ea61cc2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enc_input</th>\n",
       "      <th>dec_input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‡§á‡§∏‡§ï‡•á ‡§Ö‡§≤‡§æ‡§µ‡§æ ‡§Æ‡§æ‡§á‡§ï‡§≤ ‡§∂‡•Ç‡§Æ‡§æ‡§ï‡§∞ ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§ö‡§≤‡§æ‡§à ‡§ó‡§à ‡§è‡§ï ‡§´‡§∞‡§æ‡§∞...</td>\n",
       "      <td>‡§á‡§∏‡§ï‡•á ‡§Ö‡§≤‡§æ‡§µ‡§æ ‡§Æ‡§æ‡§á‡§ï‡§≤ ‡§∂‡•Ç‡§Æ‡§æ‡§ï‡§∞ ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§ö‡§≤‡§æ‡§à ‡§ó‡§à ‡§è‡§ï ‡§´‡§∞‡§æ‡§∞...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>‡§Ø‡§π ‡§Æ‡§® ‡§ï‡•ã ‡§ï‡§æ‡§¨‡•Ç ‡§Æ‡•á‡§Ç ‡§ï‡§∞‡§®‡•á ‡§µ‡§æ‡§≤‡•Ä ‡§Æ‡•Å‡§¶‡•ç‡§∞‡§æ ‡§π‡•à‡§Ç ‡§á‡§∏‡•Ä‡§≤‡§ø‡§è ...</td>\n",
       "      <td>‡§Ø‡§π ‡§Æ‡§® ‡§ï‡•ã ‡§ï‡§æ‡§¨‡•Ç ‡§Æ‡•á‡§Ç ‡§ï‡§∞‡§®‡•á ‡§µ‡§æ‡§≤‡•Ä ‡§Æ‡•Å‡§¶‡•ç‡§∞‡§æ ‡§π‡•à ‡§á‡§∏‡•Ä‡§≤‡§ø‡§è ‡§á...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‡§Ü‡§™ ‡§™‡•Å‡§∏‡•ç‡§§‡§ï ‡§™‡§¢‡§º‡§®‡•á ‡§Æ‡•á‡§Ç ‡§§‡§≤‡•ç‡§≤‡•Ä‡§® ‡§π‡•à‡§Ç ‡§î‡§∞ ‡§¨‡§ö‡•ç‡§ö‡§æ ‡§â‡§∏‡§®‡•á‡§æ‡§Å...</td>\n",
       "      <td>‡§Ü‡§™ ‡§™‡•Å‡§∏‡•ç‡§§‡§ï ‡§™‡§¢‡§º‡§®‡•á ‡§Æ‡•á‡§Ç ‡§§‡§≤‡•ç‡§≤‡•Ä‡§® ‡§π‡•à‡§Ç ‡§î‡§∞ ‡§¨‡§ö‡•ç‡§ö‡§æ ‡§µ‡§π‡§æ‡§Å ‡§™...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>‡§™‡§∞‡§ø‡§µ‡§æ‡§∞ ‡§ï‡•á ‡§Æ‡•Å‡§§‡§æ‡§¨‡§ø‡§ï ‡§ß‡§Æ‡§æ‡§ï‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§π‡§ø‡§∏‡•ç‡§∏‡§æ ‡§≤‡•á‡§®‡•á ‡§µ‡§æ‡§≤‡•á ...</td>\n",
       "      <td>‡§™‡§∞‡§ø‡§µ‡§æ‡§∞ ‡§ï‡•á ‡§Æ‡•Å‡§§‡§æ‡§¨‡§ø‡§ï ‡§ß‡§Æ‡§æ‡§ï‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§π‡§ø‡§∏‡•ç‡§∏‡§æ ‡§≤‡•á‡§®‡•á ‡§µ‡§æ‡§≤‡•á ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>‡§â‡§®‡§ï‡•Ä ‡§µ‡•ã ‡§µ‡§æ‡§≤‡•Ä ‡§¨‡§æ‡§§ ‡§≠‡•Ä ‡§Ö‡§®‡§ø‡§∂‡•ç‡§ö‡§ø‡§§ ‡§∞‡§π‡§§‡•Ä ‡§π‡•à‡§Ç ‡•§</td>\n",
       "      <td>‡§â‡§®‡§ï‡•Ä ‡§µ‡•ã ‡§µ‡§æ‡§≤‡•Ä ‡§¨‡§æ‡§§ ‡§≠‡•Ä ‡§Ö‡§®‡§ø‡§∂‡•ç‡§ö‡§ø‡§§ ‡§∞‡§π‡§§‡•Ä ‡§π‡•à ‡•§</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           enc_input  \\\n",
       "0  ‡§á‡§∏‡§ï‡•á ‡§Ö‡§≤‡§æ‡§µ‡§æ ‡§Æ‡§æ‡§á‡§ï‡§≤ ‡§∂‡•Ç‡§Æ‡§æ‡§ï‡§∞ ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§ö‡§≤‡§æ‡§à ‡§ó‡§à ‡§è‡§ï ‡§´‡§∞‡§æ‡§∞...   \n",
       "1  ‡§Ø‡§π ‡§Æ‡§® ‡§ï‡•ã ‡§ï‡§æ‡§¨‡•Ç ‡§Æ‡•á‡§Ç ‡§ï‡§∞‡§®‡•á ‡§µ‡§æ‡§≤‡•Ä ‡§Æ‡•Å‡§¶‡•ç‡§∞‡§æ ‡§π‡•à‡§Ç ‡§á‡§∏‡•Ä‡§≤‡§ø‡§è ...   \n",
       "2  ‡§Ü‡§™ ‡§™‡•Å‡§∏‡•ç‡§§‡§ï ‡§™‡§¢‡§º‡§®‡•á ‡§Æ‡•á‡§Ç ‡§§‡§≤‡•ç‡§≤‡•Ä‡§® ‡§π‡•à‡§Ç ‡§î‡§∞ ‡§¨‡§ö‡•ç‡§ö‡§æ ‡§â‡§∏‡§®‡•á‡§æ‡§Å...   \n",
       "3  ‡§™‡§∞‡§ø‡§µ‡§æ‡§∞ ‡§ï‡•á ‡§Æ‡•Å‡§§‡§æ‡§¨‡§ø‡§ï ‡§ß‡§Æ‡§æ‡§ï‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§π‡§ø‡§∏‡•ç‡§∏‡§æ ‡§≤‡•á‡§®‡•á ‡§µ‡§æ‡§≤‡•á ...   \n",
       "4            ‡§â‡§®‡§ï‡•Ä ‡§µ‡•ã ‡§µ‡§æ‡§≤‡•Ä ‡§¨‡§æ‡§§ ‡§≠‡•Ä ‡§Ö‡§®‡§ø‡§∂‡•ç‡§ö‡§ø‡§§ ‡§∞‡§π‡§§‡•Ä ‡§π‡•à‡§Ç ‡•§   \n",
       "\n",
       "                                           dec_input  \n",
       "0  ‡§á‡§∏‡§ï‡•á ‡§Ö‡§≤‡§æ‡§µ‡§æ ‡§Æ‡§æ‡§á‡§ï‡§≤ ‡§∂‡•Ç‡§Æ‡§æ‡§ï‡§∞ ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§ö‡§≤‡§æ‡§à ‡§ó‡§à ‡§è‡§ï ‡§´‡§∞‡§æ‡§∞...  \n",
       "1  ‡§Ø‡§π ‡§Æ‡§® ‡§ï‡•ã ‡§ï‡§æ‡§¨‡•Ç ‡§Æ‡•á‡§Ç ‡§ï‡§∞‡§®‡•á ‡§µ‡§æ‡§≤‡•Ä ‡§Æ‡•Å‡§¶‡•ç‡§∞‡§æ ‡§π‡•à ‡§á‡§∏‡•Ä‡§≤‡§ø‡§è ‡§á...  \n",
       "2  ‡§Ü‡§™ ‡§™‡•Å‡§∏‡•ç‡§§‡§ï ‡§™‡§¢‡§º‡§®‡•á ‡§Æ‡•á‡§Ç ‡§§‡§≤‡•ç‡§≤‡•Ä‡§® ‡§π‡•à‡§Ç ‡§î‡§∞ ‡§¨‡§ö‡•ç‡§ö‡§æ ‡§µ‡§π‡§æ‡§Å ‡§™...  \n",
       "3  ‡§™‡§∞‡§ø‡§µ‡§æ‡§∞ ‡§ï‡•á ‡§Æ‡•Å‡§§‡§æ‡§¨‡§ø‡§ï ‡§ß‡§Æ‡§æ‡§ï‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§π‡§ø‡§∏‡•ç‡§∏‡§æ ‡§≤‡•á‡§®‡•á ‡§µ‡§æ‡§≤‡•á ...  \n",
       "4            ‡§â‡§®‡§ï‡•Ä ‡§µ‡•ã ‡§µ‡§æ‡§≤‡•Ä ‡§¨‡§æ‡§§ ‡§≠‡•Ä ‡§Ö‡§®‡§ø‡§∂‡•ç‡§ö‡§ø‡§§ ‡§∞‡§π‡§§‡•Ä ‡§π‡•à ‡•§   "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9216427e-77e4-4d58-a4c1-0fd582745e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Sentence: ‡§á‡§∏‡§ï‡•á ‡§Ö‡§≤‡§æ‡§µ‡§æ ‡§Æ‡§æ‡§á‡§ï‡§≤ ‡§∂‡•Ç‡§Æ‡§æ‡§ï‡§∞ ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§ö‡§≤‡§æ‡§à ‡§ó‡§à ‡§è‡§ï ‡§´‡§∞‡§æ‡§∞‡•Ä ‡§ï‡§æ‡§∞ ‡§≠‡•Ä ‡§ï‡•ã ‡§Æ‡§ø‡§≤‡§ø‡§Ø‡§® ‡§°‡•â‡§≤‡§∞ ‡§ï‡•ç‡§≤‡§¨ ‡§Æ‡•á‡§Ç ‡§Æ‡§æ‡§®‡§æ ‡§ú‡§æ ‡§∞‡§π‡§æ ‡§π‡•à ‡•§\n",
      "Correct Seentence: ‡§á‡§∏‡§ï‡•á ‡§Ö‡§≤‡§æ‡§µ‡§æ ‡§Æ‡§æ‡§á‡§ï‡§≤ ‡§∂‡•Ç‡§Æ‡§æ‡§ï‡§∞ ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§ö‡§≤‡§æ‡§à ‡§ó‡§à ‡§è‡§ï ‡§´‡§∞‡§æ‡§∞‡•Ä ‡§ï‡§æ‡§∞ ‡§ï‡•ã ‡§≠‡•Ä ‡§Æ‡§ø‡§≤‡§ø‡§Ø‡§® ‡§°‡•â‡§≤‡§∞ ‡§ï‡•ç‡§≤‡§¨ ‡§Æ‡•á‡§Ç ‡§Æ‡§æ‡§®‡§æ ‡§ú‡§æ ‡§∞‡§π‡§æ ‡§π‡•à ‡•§ \n",
      "Predicted Sentence: ‡§á‡§∏‡§ï‡•á ‡§Ö‡§≤‡§æ‡§µ‡§æ ‡§Æ‡§æ‡§á‡§ï‡§≤ ‡§∂‡•Ç‡§Æ‡§æ‡§ï‡§∞ ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§ö‡§≤‡§æ‡§à ‡§ó‡§à ‡§è‡§ï ‡§´‡§∞‡§æ‡§∞‡•Ä ‡§ï‡§æ‡§∞ ‡§ï‡•ã ‡§≠‡•Ä ‡§Æ‡§ø‡§≤‡§ø‡§Ø‡§® ‡§°‡•â‡§≤‡§∞ ‡§ï‡•ç‡§≤‡§¨ ‡§Æ‡•á‡§Ç ‡§Æ‡§æ‡§®‡§æ ‡§ú‡§æ ‡§∞‡§π‡§æ ‡§π‡•à ‡•§\n"
     ]
    }
   ],
   "source": [
    "text = df_test['enc_input'].iat[0]\n",
    "correct = df_test['dec_input'].iat[0]\n",
    "print(\"Incorrect Sentence:\", text)\n",
    "print(\"Correct Seentence:\",correct)\n",
    "predicted_s = correct_grammar(text, num_return_sequences=1)[0]\n",
    "l = len(correct)\n",
    "p = len(predicted_s)\n",
    "if(p>l):\n",
    "    predicted_s = predicted_s[:l]\n",
    "\n",
    "print(\"Predicted Sentence:\",predicted_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9eef891-a11f-47ae-9f15-17cf039ec8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Sentence: ‡§ò‡§∞ ‡§Æ‡•á‡§Ç ‡§ò‡•Å‡§∏ ‡§ï‡•á ‡§¨‡§æ‡§¶ ‡§≠‡•Ä ‡§∏‡•Å‡§ï‡•Ç‡§® ‡§®‡§π‡•Ä‡§Ç ‡•§\n",
      "Correct Seentence: ‡§ò‡§∞ ‡§Æ‡•á‡§Ç ‡§ò‡•Å‡§∏‡§®‡•á ‡§ï‡•á ‡§¨‡§æ‡§¶ ‡§≠‡•Ä ‡§∏‡•Å‡§ï‡•Ç‡§® ‡§®‡§π‡•Ä‡§Ç ‡•§ \n",
      "Predicted Sentence: ‡§ò‡§∞ ‡§Æ‡•á‡§Ç ‡§ò‡•Å‡§∏‡§®‡•á ‡§ï‡•á ‡§¨‡§æ‡§¶ ‡§≠‡•Ä ‡§∏‡•Å‡§ï‡•Ç‡§® ‡§®‡§π‡•Ä‡§Ç ‡•§\n"
     ]
    }
   ],
   "source": [
    "text = df_test['enc_input'].iat[50]\n",
    "correct = df_test['dec_input'].iat[50]\n",
    "print(\"Incorrect Sentence:\", text)\n",
    "print(\"Correct Seentence:\",correct)\n",
    "predicted_s = correct_grammar(text, num_return_sequences=1)[0]\n",
    "l = len(correct)\n",
    "p = len(predicted_s)\n",
    "if(p>l):\n",
    "    predicted_s = predicted_s[:l]\n",
    "\n",
    "print(\"Predicted Sentence:\",predicted_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7fa5d601-9ba5-4961-8b1c-cb658cbcfdd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.26 s, sys: 84.4 ms, total: 1.34 s\n",
      "Wall time: 1.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predicted_s = correct_grammar(text, num_return_sequences=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d972ce-dab2-46ac-9de8-f0ffcfb53f85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ba007951-7c5e-4d99-8ca6-e9a4aa81d026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Sentence: ‡§Ø‡§π ‡§Æ‡§® ‡§ï‡•ã ‡§ï‡§æ‡§¨‡•Ç ‡§Æ‡•á‡§Ç ‡§ï‡§∞‡§®‡•á ‡§µ‡§æ‡§≤‡•Ä ‡§Æ‡•Å‡§¶‡•ç‡§∞‡§æ ‡§π‡•à‡§Ç ‡§á‡§∏‡•Ä‡§≤‡§ø‡§è ‡§á‡§∏‡•á ‡§ö‡§ø‡§§‡•ç‡§§ ‡§π‡§∏‡•ç‡§§ ‡§Æ‡•Å‡§¶‡•ç‡§∞‡§æ ‡§Ø‡•ã‡§ó ‡§ï‡§π‡§§‡•á ‡§π‡•à‡§Ç‡§Ç ‡•§\n",
      "Correct Seentence: ‡§Ø‡§π ‡§Æ‡§® ‡§ï‡•ã ‡§ï‡§æ‡§¨‡•Ç ‡§Æ‡•á‡§Ç ‡§ï‡§∞‡§®‡•á ‡§µ‡§æ‡§≤‡•Ä ‡§Æ‡•Å‡§¶‡•ç‡§∞‡§æ ‡§π‡•à ‡§á‡§∏‡•Ä‡§≤‡§ø‡§è ‡§á‡§∏‡•á ‡§ö‡§ø‡§§‡•ç‡§§ ‡§π‡§∏‡•ç‡§§ ‡§Æ‡•Å‡§¶‡•ç‡§∞‡§æ ‡§Ø‡•ã‡§ó ‡§ï‡§π‡§§‡•á ‡§π‡•à‡§Ç ‡•§ \n",
      "Predicted Sentence: ‡§Ø‡§π ‡§Æ‡§® ‡§ï‡•ã ‡§ï‡§æ‡§¨‡•Ç ‡§Æ‡•á‡§Ç ‡§ï‡§∞‡§®‡•á ‡§µ‡§æ‡§≤‡•Ä ‡§Æ‡•Å‡§¶‡•ç‡§∞‡§æ ‡§π‡•à ‡§á‡§∏‡•Ä‡§≤‡§ø‡§è ‡§á‡§∏‡•á ‡§ö‡§ø‡§§‡•ç‡§§ ‡§π‡§∏‡•ç‡§§ ‡§Æ‡•Å‡§¶‡•ç‡§∞‡§æ ‡§Ø‡•ã‡§ó ‡§ï‡§π‡§§‡•á ‡§π‡•à‡§Ç ‡•§\n"
     ]
    }
   ],
   "source": [
    "text = df_test['enc_input'].iat[1]\n",
    "correct = df_test['dec_input'].iat[1]\n",
    "print(\"Incorrect Sentence:\", text)\n",
    "print(\"Correct Seentence:\",correct)\n",
    "predicted_s = correct_grammar(text, num_return_sequences=1)[0]\n",
    "l = len(correct)\n",
    "p = len(predicted_s)\n",
    "if(p>l):\n",
    "    predicted_s = predicted_s[:l]\n",
    "print(\"Predicted Sentence:\",predicted_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0b3169-ccf8-4ce1-adf8-4dd112c41f20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9c0c0e87-c89e-4143-bacf-d6fe15b9cca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Sentence: ‡§Ü‡§™ ‡§™‡•Å‡§∏‡•ç‡§§‡§ï ‡§™‡§¢‡§º‡§®‡•á ‡§Æ‡•á‡§Ç ‡§§‡§≤‡•ç‡§≤‡•Ä‡§® ‡§π‡•à‡§Ç ‡§î‡§∞ ‡§¨‡§ö‡•ç‡§ö‡§æ ‡§â‡§∏‡§®‡•á‡§æ‡§Å ‡§™‡§∞ ‡§∂‡•ã‡§∞ ‡§Æ‡§ö‡§æ ‡§∞‡§π‡§æ ‡§π‡•à ‡•§\n",
      "Correct Seentence: ‡§Ü‡§™ ‡§™‡•Å‡§∏‡•ç‡§§‡§ï ‡§™‡§¢‡§º‡§®‡•á ‡§Æ‡•á‡§Ç ‡§§‡§≤‡•ç‡§≤‡•Ä‡§® ‡§π‡•à‡§Ç ‡§î‡§∞ ‡§¨‡§ö‡•ç‡§ö‡§æ ‡§µ‡§π‡§æ‡§Å ‡§™‡§∞ ‡§∂‡•ã‡§∞ ‡§Æ‡§ö‡§æ ‡§∞‡§π‡§æ ‡§π‡•à ‡•§ \n",
      "Predicted Sentence: ‡§Ü‡§™ ‡§™‡•Å‡§∏‡•ç‡§§‡§ï ‡§™‡§¢‡§º‡§®‡•á ‡§Æ‡•á‡§Ç ‡§§‡§≤‡•ç‡§≤‡•Ä‡§® ‡§π‡•à‡§Ç ‡§î‡§∞ ‡§¨‡§ö‡•ç‡§ö‡§æ ‡§µ‡§π‡§æ‡§Å ‡§™‡§∞ ‡§∂‡•ã‡§∞ ‡§Æ‡§ö‡§æ ‡§∞‡§π‡§æ ‡§π‡•à ‡•§\n"
     ]
    }
   ],
   "source": [
    "text = df_test['enc_input'].iat[2]\n",
    "correct = df_test['dec_input'].iat[2]\n",
    "print(\"Incorrect Sentence:\", text)\n",
    "print(\"Correct Seentence:\",correct)\n",
    "predicted_s = correct_grammar(text, num_return_sequences=1)[0]\n",
    "l = len(correct)\n",
    "p = len(predicted_s)\n",
    "if(p>l):\n",
    "    predicted_s = predicted_s[:l]\n",
    "print(\"Predicted Sentence:\",predicted_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6f233a47-440e-49b7-ba4f-b952be54da5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Sentence: ‡§™‡§∞‡§ø‡§µ‡§æ‡§∞ ‡§ï‡•á ‡§Æ‡•Å‡§§‡§æ‡§¨‡§ø‡§ï ‡§ß‡§Æ‡§æ‡§ï‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§π‡§ø‡§∏‡•ç‡§∏‡§æ ‡§≤‡•á‡§®‡•á ‡§µ‡§æ‡§≤‡•á ‡§ï‡•ã‡§à ‡§¶‡•Ç‡§∏‡§∞‡•á ‡§≤‡•ã‡§ó ‡§•‡•á ‡§î‡§∞ ‡§Ø‡•á ‡§ó‡§≤‡§§ ‡§™‡§π‡§ö‡§æ‡§® ‡§ï‡§æ ‡§Æ‡§æ‡§Æ‡§≤‡§æ ‡§π‡•à‡§Ç ‡•§\n",
      "Correct Seentence: ‡§™‡§∞‡§ø‡§µ‡§æ‡§∞ ‡§ï‡•á ‡§Æ‡•Å‡§§‡§æ‡§¨‡§ø‡§ï ‡§ß‡§Æ‡§æ‡§ï‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§π‡§ø‡§∏‡•ç‡§∏‡§æ ‡§≤‡•á‡§®‡•á ‡§µ‡§æ‡§≤‡•á ‡§ï‡•ã‡§à ‡§¶‡•Ç‡§∏‡§∞‡•á ‡§≤‡•ã‡§ó ‡§•‡•á ‡§î‡§∞ ‡§Ø‡•á ‡§ó‡§≤‡§§ ‡§™‡§π‡§ö‡§æ‡§® ‡§ï‡§æ ‡§Æ‡§æ‡§Æ‡§≤‡§æ ‡§π‡•à ‡•§ \n",
      "Predicted Sentence: ‡§™‡§∞‡§ø‡§µ‡§æ‡§∞ ‡§ï‡•á ‡§Æ‡•Å‡§§‡§æ‡§¨‡§ø‡§ï ‡§ß‡§Æ‡§æ‡§ï‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§π‡§ø‡§∏‡•ç‡§∏‡§æ ‡§≤‡•á‡§®‡•á ‡§µ‡§æ‡§≤‡•á ‡§ï‡•ã‡§à ‡§¶‡•Ç‡§∏‡§∞‡•á ‡§≤‡•ã‡§ó ‡§•‡•á ‡§î‡§∞ ‡§Ø‡•á ‡§ó‡§≤‡§§ ‡§™‡§π‡§ö‡§æ‡§® ‡§ï‡§æ ‡§Æ‡§æ‡§Æ‡§≤‡§æ ‡§π‡•à ‡•§\n"
     ]
    }
   ],
   "source": [
    "text = df_test['enc_input'].iat[3]\n",
    "correct = df_test['dec_input'].iat[3]\n",
    "print(\"Incorrect Sentence:\", text)\n",
    "print(\"Correct Seentence:\",correct)\n",
    "predicted_s = correct_grammar(text, num_return_sequences=1)[0]\n",
    "l = len(correct)\n",
    "p = len(predicted_s)\n",
    "if(p>l):\n",
    "    predicted_s = predicted_s[:l]\n",
    "print(\"Predicted Sentence:\",predicted_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7ff4d00c-6d49-4e6e-b4f9-a765967fa1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Sentence: ‡§â‡§®‡§ï‡•Ä ‡§µ‡•ã ‡§µ‡§æ‡§≤‡•Ä ‡§¨‡§æ‡§§ ‡§≠‡•Ä ‡§Ö‡§®‡§ø‡§∂‡•ç‡§ö‡§ø‡§§ ‡§∞‡§π‡§§‡•Ä ‡§π‡•à‡§Ç ‡•§\n",
      "Correct Seentence: ‡§â‡§®‡§ï‡•Ä ‡§µ‡•ã ‡§µ‡§æ‡§≤‡•Ä ‡§¨‡§æ‡§§ ‡§≠‡•Ä ‡§Ö‡§®‡§ø‡§∂‡•ç‡§ö‡§ø‡§§ ‡§∞‡§π‡§§‡•Ä ‡§π‡•à ‡•§ \n",
      "Predicted Sentence: ‡§â‡§®‡§ï‡•Ä ‡§µ‡•ã ‡§µ‡§æ‡§≤‡•Ä ‡§¨‡§æ‡§§ ‡§≠‡•Ä ‡§Ö‡§®‡§ø‡§∂‡•ç‡§ö‡§ø‡§§ ‡§∞‡§π‡§§‡•Ä ‡§π‡•à ‡•§\n"
     ]
    }
   ],
   "source": [
    "text = df_test['enc_input'].iat[4]\n",
    "correct = df_test['dec_input'].iat[4]\n",
    "print(\"Incorrect Sentence:\", text)\n",
    "print(\"Correct Seentence:\",correct)\n",
    "predicted_s = correct_grammar(text, num_return_sequences=1)[0]\n",
    "l = len(correct)\n",
    "p = len(predicted_s)\n",
    "if(p>l):\n",
    "    predicted_s = predicted_s[:l]\n",
    "print(\"Predicted Sentence:\",predicted_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0ad90991-9465-4991-9562-bd6e88cfe5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Sentence: ‡§Æ‡•à‡§Ç‡§®‡•á ‡§≤‡§≤‡§ø‡§§ ‡§π‡•Ç‡§Å ‡•§\n",
      "Correct Seentence: ‡§Æ‡•à‡§Ç ‡§≤‡§≤‡§ø‡§§ ‡§π‡•Ç‡§Å ‡•§ \n",
      "Predicted Sentence: ‡§Æ‡•à‡§Ç ‡§≤‡§≤‡§ø‡§§ ‡§π‡•Ç‡§Å ‡•§ \n"
     ]
    }
   ],
   "source": [
    "text = df_test['enc_input'].iat[9]\n",
    "correct = df_test['dec_input'].iat[9]\n",
    "print(\"Incorrect Sentence:\", text)\n",
    "print(\"Correct Seentence:\",correct)\n",
    "predicted_s = correct_grammar(text, num_return_sequences=1)[0]\n",
    "l = len(correct)\n",
    "p = len(predicted_s)\n",
    "if(p>l):\n",
    "    predicted_s = predicted_s[:l]\n",
    "print(\"Predicted Sentence:\",predicted_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f63ceef-8b22-4af4-85b7-3b8ea69b275b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ffee1d-4065-4509-98cf-069cb233593b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf1c130-a68b-4bf1-86d9-d677f8ed9e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.translate.bleu_score as bleu\n",
    "BLEU = []\n",
    "index = []\n",
    "test_data = df_test.head(10000)\n",
    "np.random.seed(1)\n",
    "for ind,i in tqdm(test_data.iterrows(),position=0):\n",
    "    try:\n",
    "        text = str(i.enc_input)\n",
    "        #pred = predict(str(i.enc_input),model)[0].split()\n",
    "        pred = correct_grammar(text, num_return_sequences=1)[0]\n",
    "        act = [str(i.dec_input).split()]\n",
    "        pred_s = str(pred).split()\n",
    "        #print(act)\n",
    "        #print(pred_s)\n",
    "        b = bleu.sentence_bleu(act,pred_s)\n",
    "        BLEU.append(b)\n",
    "    except:\n",
    "        index.append(ind)\n",
    "        continue\n",
    "print(\"BELU = \", np.mean(BLEU))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cb825de7-9bcd-4d6e-8ba4-433f7ac00ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  1  data point 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [21:58,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  1001  data point 0.9150283140478553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2001it [42:44,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  2001  data point 0.9204379715628371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3001it [1:01:56,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  3001  data point 0.9182989341695741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4001it [1:20:27,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  4001  data point 0.9186494493296361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5001it [1:38:55,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  5001  data point 0.91909503414758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6001it [1:57:23,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  6001  data point 0.918329036146066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7001it [2:16:38,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  7001  data point 0.9192907337567936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8001it [2:35:05,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  8001  data point 0.9201028812376454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9001it [2:53:42,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  9001  data point 0.9205000001846352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [3:12:33,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score =  0.9208625332430048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.gleu_score import sentence_gleu\n",
    "GLEU_val_emb = []\n",
    "test_data = df_test.head(10000)\n",
    "print(test_data.shape)\n",
    "for ind,i in tqdm(test_data.iterrows(),position=0):\n",
    "    try:\n",
    "        text = str(i.enc_input)\n",
    "        #pred = predict(str(i.enc_input),model)[0].split()\n",
    "        pred = correct_grammar(text, num_return_sequences=1)[0]\n",
    "        l = len(text)\n",
    "        p = len(pred)\n",
    "        if(p>l):\n",
    "            pred = pred[:l]\n",
    "            \n",
    "        act = [str(i.dec_input).split()]\n",
    "        pred_s = str(pred).split()\n",
    "        b = sentence_gleu(act,pred_s)\n",
    "        GLEU_val_emb.append(b)\n",
    "        if(ind%1000 ==0):\n",
    "            print(\"GELU Score for \",ind+1,\" data point\",np.mean(GLEU_val_emb))\n",
    "    except:\n",
    "        continue\n",
    "print(\"GELU Score = \",np.mean(GLEU_val_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8f776a52-2f84-4b17-a268-62f049e9cc11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score =  0.9208625332430048\n"
     ]
    }
   ],
   "source": [
    "print(\"GELU Score = \",np.mean(GLEU_val_emb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b12e786-b7d7-4c70-8bce-592d1b146bcc",
   "metadata": {},
   "source": [
    "# Testing HiWikEd test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b3252f34-628a-4e12-9569-b81228062c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_test1 = pd.read_csv('DATA/HiWikEd.csv')\n",
    "df_test1.shape\n",
    "df_test1 = df_test1.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "875fa5f4-1261-42a1-a57e-021fe3debaf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enc_input</th>\n",
       "      <th>dec_input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‡§ö‡§æ‡§Ø ‡§ï‡•Ä ‡§¶‡•Å‡§ï‡§æ‡§® ‡§∏‡•á ‡§≤‡•á‡§ï‡§∞ ‡§µ‡§æ‡§π‡§®‡•ã‡§Ç ‡§î‡§∞ ‡§¶‡§ø‡§µ‡§æ‡§∞‡•ã‡§Ç ‡§§‡§ï ‡§π‡§∞ ‡§ú‡§ó‡§π ‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§™‡§® ‡§π‡•Ä ‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§™‡§® ‡§¶‡§ø‡§ñ‡§æ‡§à ‡§¶‡•á‡§§‡•á ‡§π‡•à.</td>\n",
       "      <td>‡§ö‡§æ‡§Ø ‡§ï‡•Ä ‡§¶‡•Å‡§ï‡§æ‡§® ‡§∏‡•á ‡§≤‡•á‡§ï‡§∞ ‡§µ‡§æ‡§π‡§®‡•ã‡§Ç ‡§î‡§∞ ‡§¶‡§ø‡§µ‡§æ‡§∞‡•ã‡§Ç ‡§§‡§ï ‡§π‡§∞ ‡§ú‡§ó‡§π ‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§™‡§® ‡§π‡•Ä ‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§™‡§® ‡§¶‡§ø‡§ñ‡§æ‡§à ‡§¶‡•á‡§§‡•á ‡§π‡•à‡§Ç.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>‡§Ø‡•á ‡§ï‡§π‡•Ä‡§Ç ‡§™‡•á ‡§®‡§ø‡§ó‡§æ‡§π‡•á‡§Ç, ‡§ï‡§π‡•Ä ‡§™‡•á ‡§®‡§ø‡§∂‡§æ‡§®‡§æ ‡§ï‡§æ ‡§∏‡§æ ‡§Ö‡§®‡•ç‡§¶‡§æ‡§ú ‡§π‡•à.</td>\n",
       "      <td>‡§Ø‡§π ‡§ï‡§π‡•Ä‡§Ç ‡§™‡•á ‡§®‡§ø‡§ó‡§æ‡§π‡•á‡§Ç, ‡§ï‡§π‡•Ä ‡§™‡•á ‡§®‡§ø‡§∂‡§æ‡§®‡§æ ‡§ï‡§æ ‡§∏‡§æ ‡§Ö‡§®‡•ç‡§¶‡§æ‡§ú ‡§π‡•à.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‡§Ü‡§ú ‡§π‡§Æ ‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§™‡§® ‡§Ø‡•Å‡§ó ‡§ï‡•á ‡§∏‡•Ä‡§Æ‡§æ‡§®‡•ç‡§§ ‡§™‡§∞ ‡§Ü ‡§ñ‡§°‡§º‡•á ‡§π‡•Å‡§è ‡§π‡•à.</td>\n",
       "      <td>‡§Ü‡§ú ‡§π‡§Æ ‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§™‡§® ‡§Ø‡•Å‡§ó ‡§ï‡•á ‡§∏‡•Ä‡§Æ‡§æ‡§®‡•ç‡§§ ‡§™‡§∞ ‡§Ü ‡§ñ‡§°‡§º‡•á ‡§π‡•Å‡§è ‡§π‡•à‡§Ç.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>‡§ò‡§∞ ‡§ï‡•á ‡§¨‡§æ‡§π‡§∞ ‡§™‡•à‡§∞ ‡§∞‡§ñ‡§§‡•á ‡§π‡•Ä ‡§π‡§Æ ‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§™‡§® ‡§ï‡•Ä ‡§¶‡•Å‡§®‡§ø‡§Ø‡§æ ‡§Æ‡•á‡§Ç ‡§ò‡§ø‡§∞ ‡§ú‡§æ‡§§‡•á ‡§π‡•à.</td>\n",
       "      <td>‡§ò‡§∞ ‡§ï‡•á ‡§¨‡§æ‡§π‡§∞ ‡§™‡•à‡§∞ ‡§∞‡§ñ‡§§‡•á ‡§π‡•Ä ‡§π‡§Æ ‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§™‡§® ‡§ï‡•Ä ‡§¶‡•Å‡§®‡§ø‡§Ø‡§æ ‡§∏‡•á ‡§ò‡§ø‡§∞ ‡§ú‡§æ‡§§‡•á ‡§π‡•à.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>‡§µ‡§∞‡•ç‡§§‡§Æ‡§æ‡§® ‡§∏‡§Æ‡§Ø ‡§Æ‡•á‡§Ç ‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§™‡§® ‡§ï‡•á ‡§ï‡•ã‡§à ‡§∞‡•Ç‡§™ ‡§π‡§Æ‡§æ‡§∞‡•á ‡§∏‡§æ‡§Æ‡§®‡•á ‡§Ü‡§§‡•á ‡§π‡•à.</td>\n",
       "      <td>‡§µ‡§∞‡•ç‡§§‡§Æ‡§æ‡§® ‡§∏‡§Æ‡§Ø ‡§Æ‡•á‡§Ç ‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§™‡§® ‡§ï‡•á ‡§ï‡§à ‡§∞‡•Ç‡§™ ‡§π‡§Æ‡§æ‡§∞‡•á ‡§∏‡§æ‡§Æ‡§®‡•á ‡§Ü‡§§‡•á ‡§π‡•à.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                              enc_input  \\\n",
       "0  ‡§ö‡§æ‡§Ø ‡§ï‡•Ä ‡§¶‡•Å‡§ï‡§æ‡§® ‡§∏‡•á ‡§≤‡•á‡§ï‡§∞ ‡§µ‡§æ‡§π‡§®‡•ã‡§Ç ‡§î‡§∞ ‡§¶‡§ø‡§µ‡§æ‡§∞‡•ã‡§Ç ‡§§‡§ï ‡§π‡§∞ ‡§ú‡§ó‡§π ‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§™‡§® ‡§π‡•Ä ‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§™‡§® ‡§¶‡§ø‡§ñ‡§æ‡§à ‡§¶‡•á‡§§‡•á ‡§π‡•à.   \n",
       "1                                    ‡§Ø‡•á ‡§ï‡§π‡•Ä‡§Ç ‡§™‡•á ‡§®‡§ø‡§ó‡§æ‡§π‡•á‡§Ç, ‡§ï‡§π‡•Ä ‡§™‡•á ‡§®‡§ø‡§∂‡§æ‡§®‡§æ ‡§ï‡§æ ‡§∏‡§æ ‡§Ö‡§®‡•ç‡§¶‡§æ‡§ú ‡§π‡•à.   \n",
       "2                                       ‡§Ü‡§ú ‡§π‡§Æ ‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§™‡§® ‡§Ø‡•Å‡§ó ‡§ï‡•á ‡§∏‡•Ä‡§Æ‡§æ‡§®‡•ç‡§§ ‡§™‡§∞ ‡§Ü ‡§ñ‡§°‡§º‡•á ‡§π‡•Å‡§è ‡§π‡•à.   \n",
       "3                         ‡§ò‡§∞ ‡§ï‡•á ‡§¨‡§æ‡§π‡§∞ ‡§™‡•à‡§∞ ‡§∞‡§ñ‡§§‡•á ‡§π‡•Ä ‡§π‡§Æ ‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§™‡§® ‡§ï‡•Ä ‡§¶‡•Å‡§®‡§ø‡§Ø‡§æ ‡§Æ‡•á‡§Ç ‡§ò‡§ø‡§∞ ‡§ú‡§æ‡§§‡•á ‡§π‡•à.   \n",
       "4                               ‡§µ‡§∞‡•ç‡§§‡§Æ‡§æ‡§® ‡§∏‡§Æ‡§Ø ‡§Æ‡•á‡§Ç ‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§™‡§® ‡§ï‡•á ‡§ï‡•ã‡§à ‡§∞‡•Ç‡§™ ‡§π‡§Æ‡§æ‡§∞‡•á ‡§∏‡§æ‡§Æ‡§®‡•á ‡§Ü‡§§‡•á ‡§π‡•à.   \n",
       "\n",
       "                                                                               dec_input  \n",
       "0  ‡§ö‡§æ‡§Ø ‡§ï‡•Ä ‡§¶‡•Å‡§ï‡§æ‡§® ‡§∏‡•á ‡§≤‡•á‡§ï‡§∞ ‡§µ‡§æ‡§π‡§®‡•ã‡§Ç ‡§î‡§∞ ‡§¶‡§ø‡§µ‡§æ‡§∞‡•ã‡§Ç ‡§§‡§ï ‡§π‡§∞ ‡§ú‡§ó‡§π ‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§™‡§® ‡§π‡•Ä ‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§™‡§® ‡§¶‡§ø‡§ñ‡§æ‡§à ‡§¶‡•á‡§§‡•á ‡§π‡•à‡§Ç.  \n",
       "1                                     ‡§Ø‡§π ‡§ï‡§π‡•Ä‡§Ç ‡§™‡•á ‡§®‡§ø‡§ó‡§æ‡§π‡•á‡§Ç, ‡§ï‡§π‡•Ä ‡§™‡•á ‡§®‡§ø‡§∂‡§æ‡§®‡§æ ‡§ï‡§æ ‡§∏‡§æ ‡§Ö‡§®‡•ç‡§¶‡§æ‡§ú ‡§π‡•à.  \n",
       "2                                       ‡§Ü‡§ú ‡§π‡§Æ ‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§™‡§® ‡§Ø‡•Å‡§ó ‡§ï‡•á ‡§∏‡•Ä‡§Æ‡§æ‡§®‡•ç‡§§ ‡§™‡§∞ ‡§Ü ‡§ñ‡§°‡§º‡•á ‡§π‡•Å‡§è ‡§π‡•à‡§Ç.  \n",
       "3                           ‡§ò‡§∞ ‡§ï‡•á ‡§¨‡§æ‡§π‡§∞ ‡§™‡•à‡§∞ ‡§∞‡§ñ‡§§‡•á ‡§π‡•Ä ‡§π‡§Æ ‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§™‡§® ‡§ï‡•Ä ‡§¶‡•Å‡§®‡§ø‡§Ø‡§æ ‡§∏‡•á ‡§ò‡§ø‡§∞ ‡§ú‡§æ‡§§‡•á ‡§π‡•à.  \n",
       "4                                 ‡§µ‡§∞‡•ç‡§§‡§Æ‡§æ‡§® ‡§∏‡§Æ‡§Ø ‡§Æ‡•á‡§Ç ‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§™‡§® ‡§ï‡•á ‡§ï‡§à ‡§∞‡•Ç‡§™ ‡§π‡§Æ‡§æ‡§∞‡•á ‡§∏‡§æ‡§Æ‡§®‡•á ‡§Ü‡§§‡•á ‡§π‡•à.  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2982ca8d-6fdb-4c1c-b153-1006de98725c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Sentence: ‡§¨‡§æ‡§¶‡§∂‡§æ‡§π ‡§ï‡•á ‡§∏‡§Æ‡§ï‡•ç‡§∑ ‡§è‡§ï ‡§≤‡§°‡§º‡§æ‡§à ‡§Æ‡•á‡§Ç ‡§∏‡§ø‡§∞ ‡§ï‡§æ‡§ü‡•á ‡§ú‡§æ‡§®‡•á ‡§™‡§∞ ‡§≠‡•Ä ‡§â‡§∏‡§ï‡§æ ‡§ß‡§°‡§º ‡§¨‡§π‡•Å‡§§ ‡§∏‡§Æ‡§Ø ‡§§‡§ï ‡§≤‡§°‡§º‡§§‡§æ ‡§∞‡§π‡§æ ‡§•‡§æ.\n",
      "Correct Seentence: ‡§¨‡§æ‡§¶‡§∂‡§æ‡§π ‡§ï‡•á ‡§∏‡§Æ‡§ï‡•ç‡§∑ ‡§è‡§ï ‡§≤‡§°‡§º‡§æ‡§à ‡§Æ‡•á‡§Ç ‡§∏‡§ø‡§∞ ‡§ï‡§æ‡§ü‡•á ‡§ú‡§æ‡§®‡•á ‡§™‡§∞ ‡§≠‡•Ä ‡§â‡§®‡§ï‡§æ ‡§ß‡§°‡§º ‡§¨‡§π‡•Å‡§§ ‡§∏‡§Æ‡§Ø ‡§§‡§ï ‡§≤‡§°‡§º‡§§‡§æ ‡§∞‡§π‡§æ ‡§•‡§æ.\n",
      "Predicted Sentence: ‡§¨‡§æ‡§¶‡§∂‡§æ‡§π ‡§ï‡•á ‡§∏‡§Æ‡§ï‡•ç‡§∑ ‡§è‡§ï ‡§≤‡§°‡§º‡§æ‡§à ‡§Æ‡•á‡§Ç ‡§∏‡§ø‡§∞ ‡§ï‡§æ‡§ü‡•á ‡§ú‡§æ‡§®‡•á ‡§™‡§∞ ‡§≠‡•Ä ‡§â‡§∏‡§ï‡§æ ‡§ß‡§°‡§º ‡§¨‡§π‡•Å‡§§ ‡§∏‡§Æ‡§Ø ‡§§‡§ï ‡§≤‡§°‡§º‡§§‡§æ ‡§∞‡§π‡§æ ‡§•‡§æ.\n"
     ]
    }
   ],
   "source": [
    "text = df_test1['enc_input'].iat[45]\n",
    "correct = df_test1['dec_input'].iat[45]\n",
    "print(\"Incorrect Sentence:\", text)\n",
    "print(\"Correct Seentence:\",correct)\n",
    "predicted_s = correct_grammar(text, num_return_sequences=1)[0]\n",
    "l = len(correct)\n",
    "p = len(predicted_s)\n",
    "if(p>l):\n",
    "    predicted_s = predicted_s[:l]\n",
    "\n",
    "print(\"Predicted Sentence:\",predicted_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06b1632b-6e87-4f62-a306-097d41556f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Sentence: ‡§á‡§∏‡•á ‡§ó‡•å‡§∞‡•Ä ‡§∂‡§Ç‡§ï‡§∞ ‡§Æ‡§Ç‡§¶‡§ø‡§∞ ‡§≠‡•Ä ‡§ï‡§π‡§§‡•á ‡§π‡•à.\n",
      "Correct Seentence: ‡§á‡§∏‡•á ‡§ó‡•å‡§∞‡•Ä ‡§∂‡§Ç‡§ï‡§∞ ‡§Æ‡§Ç‡§¶‡§ø‡§∞ ‡§≠‡•Ä ‡§ï‡§π‡§§‡•á ‡§π‡•à‡§Ç.\n",
      "Predicted Sentence: ‡§á‡§∏‡•á ‡§ó‡•å‡§∞‡•Ä ‡§∂‡§Ç‡§ï‡§∞ ‡§Æ‡§Ç‡§¶‡§ø‡§∞ ‡§≠‡•Ä ‡§ï‡§π‡§§‡•á ‡§π‡•à‡§Ç.\n"
     ]
    }
   ],
   "source": [
    "text = df_test1['enc_input'].iat[40]\n",
    "correct = df_test1['dec_input'].iat[40]\n",
    "print(\"Incorrect Sentence:\", text)\n",
    "print(\"Correct Seentence:\",correct)\n",
    "predicted_s = correct_grammar(text, num_return_sequences=1)[0]\n",
    "l = len(correct)\n",
    "p = len(predicted_s)\n",
    "if(p>l):\n",
    "    predicted_s = predicted_s[:l]\n",
    "\n",
    "print(\"Predicted Sentence:\",predicted_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ff017077-1056-4b4b-a24e-966a05fbc2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:02,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  1  data point 0.9354838709677419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [04:20,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score =  0.8107857635662435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from nltk.translate.gleu_score import sentence_gleu\n",
    "\n",
    "\n",
    "GLEU_val_emb = []\n",
    "test_data = df_test1.head(100)\n",
    "print(test_data.shape)\n",
    "\n",
    "for ind,i in tqdm(test_data.iterrows(),position=0):\n",
    "    try:\n",
    "        text = str(i.enc_input)\n",
    "        #pred = predict(str(i.enc_input),model)[0].split()\n",
    "        pred = correct_grammar(text, num_return_sequences=1)[0]\n",
    "        l = len(text)\n",
    "        p = len(pred)\n",
    "        if(p>l):\n",
    "            pred = pred[:l]\n",
    "            \n",
    "        act = [str(i.dec_input).split()]\n",
    "        pred_s = str(pred).split()\n",
    "        b = sentence_gleu(act,pred_s)\n",
    "        GLEU_val_emb.append(b)\n",
    "        if(ind%100 ==0):\n",
    "            print(\"GELU Score for \",ind+1,\" data point\",np.mean(GLEU_val_emb))\n",
    "    except:\n",
    "        continue\n",
    "print(\"GELU Score = \",np.mean(GLEU_val_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece44c76-ddbd-4136-8ab0-c2f84f33caea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8131416a-f3d2-484b-8a46-af8d0b6f7056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRON_INFL: (496, 2)\n",
      "ADJ_INFL: (150, 2)\n",
      "ADP_INFL: (1101, 2)\n",
      "VERB_INFL: (5241, 2)\n",
      "NOUN_INFL: (182, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_test_pron_infl = pd.read_csv('DATA/Wikiedits_PRON_INFL.csv')\n",
    "print(\"PRON_INFL:\", df_test_pron_infl.shape)\n",
    "\n",
    "df_test_adj_infl = pd.read_csv('DATA/Wikiedits_ADJ_INFL.csv')\n",
    "print(\"ADJ_INFL:\", df_test_adj_infl.shape)\n",
    "\n",
    "df_test_adp_infl = pd.read_csv('DATA/Wikiedits_ADP_INFL.csv')\n",
    "print(\"ADP_INFL:\", df_test_adp_infl.shape)\n",
    "\n",
    "df_test_verb_infl = pd.read_csv('DATA/Wikiedits_VERB_INFL.csv')\n",
    "print(\"VERB_INFL:\", df_test_verb_infl.shape)\n",
    "\n",
    "df_test_noun_infl = pd.read_csv('DATA/Wikiedits_NOUN_INFL.csv')\n",
    "print(\"NOUN_INFL:\", df_test_noun_infl.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa07c8d1-c006-4718-a6eb-9fb4004319ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enc_input</th>\n",
       "      <th>dec_input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‡§®‡•à‡§¨‡§∞‡§ø‡§ú‡§æ ‡§®‡•á ‡§Ö‡§™‡§®‡•Ä ‡§≠‡§æ‡§∑‡§æ ‡§™‡§†‡§® ‡§Ö‡§ß‡•ç‡§Ø‡§Ø‡§® ‡§ï‡•ã ‡§ö‡§æ‡§∞ ‡§™‡•Å‡§∏‡•ç‡§§‡§ï‡•ã...</td>\n",
       "      <td>‡§®‡•à‡§¨‡§∞‡§ø‡§ú‡§æ ‡§®‡•á ‡§Ö‡§™‡§®‡•á ‡§≠‡§æ‡§∑‡§æ ‡§™‡§†‡§® ‡§Ö‡§ß‡•ç‡§Ø‡§Ø‡§® ‡§ï‡•ã ‡§ö‡§æ‡§∞ ‡§™‡•Å‡§∏‡•ç‡§§‡§ï‡•ã...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>‡§Ö‡§™‡§®‡•á ‡§Æ‡•Ç‡§≤ ‡§™‡•ç‡§∞‡§æ‡§ï‡•É‡§§‡§ø‡§ï ‡§∏‡•ç‡§•‡§ø‡§§‡§ø ‡§Æ‡•á‡§Ç ‡§Ø‡•á ‡§â‡§§‡•ç‡§§‡§∞ ‡§Ö‡§Æ‡•á‡§∞‡§ø‡§ï‡§æ...</td>\n",
       "      <td>‡§Ö‡§™‡§®‡•Ä ‡§Æ‡•Ç‡§≤ ‡§™‡•ç‡§∞‡§æ‡§ï‡•É‡§§‡§ø‡§ï ‡§∏‡•ç‡§•‡§ø‡§§‡§ø ‡§Æ‡•á‡§Ç ‡§Ø‡•á ‡§â‡§§‡•ç‡§§‡§∞ ‡§Ö‡§Æ‡•á‡§∞‡§ø‡§ï‡§æ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           enc_input  \\\n",
       "0  ‡§®‡•à‡§¨‡§∞‡§ø‡§ú‡§æ ‡§®‡•á ‡§Ö‡§™‡§®‡•Ä ‡§≠‡§æ‡§∑‡§æ ‡§™‡§†‡§® ‡§Ö‡§ß‡•ç‡§Ø‡§Ø‡§® ‡§ï‡•ã ‡§ö‡§æ‡§∞ ‡§™‡•Å‡§∏‡•ç‡§§‡§ï‡•ã...   \n",
       "1  ‡§Ö‡§™‡§®‡•á ‡§Æ‡•Ç‡§≤ ‡§™‡•ç‡§∞‡§æ‡§ï‡•É‡§§‡§ø‡§ï ‡§∏‡•ç‡§•‡§ø‡§§‡§ø ‡§Æ‡•á‡§Ç ‡§Ø‡•á ‡§â‡§§‡•ç‡§§‡§∞ ‡§Ö‡§Æ‡•á‡§∞‡§ø‡§ï‡§æ...   \n",
       "\n",
       "                                           dec_input  \n",
       "0  ‡§®‡•à‡§¨‡§∞‡§ø‡§ú‡§æ ‡§®‡•á ‡§Ö‡§™‡§®‡•á ‡§≠‡§æ‡§∑‡§æ ‡§™‡§†‡§® ‡§Ö‡§ß‡•ç‡§Ø‡§Ø‡§® ‡§ï‡•ã ‡§ö‡§æ‡§∞ ‡§™‡•Å‡§∏‡•ç‡§§‡§ï‡•ã...  \n",
       "1  ‡§Ö‡§™‡§®‡•Ä ‡§Æ‡•Ç‡§≤ ‡§™‡•ç‡§∞‡§æ‡§ï‡•É‡§§‡§ø‡§ï ‡§∏‡•ç‡§•‡§ø‡§§‡§ø ‡§Æ‡•á‡§Ç ‡§Ø‡•á ‡§â‡§§‡•ç‡§§‡§∞ ‡§Ö‡§Æ‡•á‡§∞‡§ø‡§ï‡§æ...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_pron_infl.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebff85c3-855f-4c3b-97d7-1dda8a7f6c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enc_input</th>\n",
       "      <th>dec_input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‡§™‡§π‡§≤‡•Ä ‡§∏‡§Æ‡§æ‡§® ‡§µ‡§ø‡§¶‡•ç‡§Ø‡§æ‡§≤‡§Ø ‡§µ‡•ç‡§Ø‡§µ‡§∏‡•ç‡§•‡§æ ‡§î‡§∞ ‡§¶‡•Ç‡§∏‡§∞‡•Ä ‡§¶‡•á‡§∂ ‡§ï‡•Ä ‡§∂‡§ø...</td>\n",
       "      <td>‡§™‡§π‡§≤‡•Ä ‡§∏‡§Æ‡§æ‡§® ‡§µ‡§ø‡§¶‡•ç‡§Ø‡§æ‡§≤‡§Ø ‡§µ‡•ç‡§Ø‡§µ‡§∏‡•ç‡§•‡§æ ‡§î‡§∞ ‡§¶‡•Ç‡§∏‡§∞‡•á ‡§¶‡•á‡§∂ ‡§ï‡•Ä ‡§∂‡§ø...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>‡§®‡•ã‡§è‡§°‡§æ ‡§è‡§∂‡§ø‡§Ø‡§æ ‡§ï‡•Ä ‡§∏‡§¨‡§∏‡•á ‡§¨‡§°‡§º‡•Ä ‡§î‡§¶‡•ç‡§Ø‡•ã‡§ó‡§ø‡§ï ‡§â‡§™‡§®‡§ó‡§∞‡•ã‡§Ç ‡§Æ‡•á‡§Ç ...</td>\n",
       "      <td>‡§®‡•ã‡§è‡§°‡§æ ‡§è‡§∂‡§ø‡§Ø‡§æ ‡§ï‡•á ‡§∏‡§¨‡§∏‡•á ‡§¨‡§°‡§º‡•á ‡§î‡§¶‡•ç‡§Ø‡•ã‡§ó‡§ø‡§ï ‡§â‡§™‡§®‡§ó‡§∞‡•ã‡§Ç ‡§Æ‡•á‡§Ç ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           enc_input  \\\n",
       "0  ‡§™‡§π‡§≤‡•Ä ‡§∏‡§Æ‡§æ‡§® ‡§µ‡§ø‡§¶‡•ç‡§Ø‡§æ‡§≤‡§Ø ‡§µ‡•ç‡§Ø‡§µ‡§∏‡•ç‡§•‡§æ ‡§î‡§∞ ‡§¶‡•Ç‡§∏‡§∞‡•Ä ‡§¶‡•á‡§∂ ‡§ï‡•Ä ‡§∂‡§ø...   \n",
       "1  ‡§®‡•ã‡§è‡§°‡§æ ‡§è‡§∂‡§ø‡§Ø‡§æ ‡§ï‡•Ä ‡§∏‡§¨‡§∏‡•á ‡§¨‡§°‡§º‡•Ä ‡§î‡§¶‡•ç‡§Ø‡•ã‡§ó‡§ø‡§ï ‡§â‡§™‡§®‡§ó‡§∞‡•ã‡§Ç ‡§Æ‡•á‡§Ç ...   \n",
       "\n",
       "                                           dec_input  \n",
       "0  ‡§™‡§π‡§≤‡•Ä ‡§∏‡§Æ‡§æ‡§® ‡§µ‡§ø‡§¶‡•ç‡§Ø‡§æ‡§≤‡§Ø ‡§µ‡•ç‡§Ø‡§µ‡§∏‡•ç‡§•‡§æ ‡§î‡§∞ ‡§¶‡•Ç‡§∏‡§∞‡•á ‡§¶‡•á‡§∂ ‡§ï‡•Ä ‡§∂‡§ø...  \n",
       "1  ‡§®‡•ã‡§è‡§°‡§æ ‡§è‡§∂‡§ø‡§Ø‡§æ ‡§ï‡•á ‡§∏‡§¨‡§∏‡•á ‡§¨‡§°‡§º‡•á ‡§î‡§¶‡•ç‡§Ø‡•ã‡§ó‡§ø‡§ï ‡§â‡§™‡§®‡§ó‡§∞‡•ã‡§Ç ‡§Æ‡•á‡§Ç ...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_adj_infl.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5a82a24-47bb-427a-a3d9-13d8bf9062b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  1  data point 0.8484848484848485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "51it [01:13,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  51  data point 0.7370891501571076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [02:19,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  101  data point 0.7305455277794598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150it [03:24,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score =  0.7434265640344555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from nltk.translate.gleu_score import sentence_gleu\n",
    "\n",
    "\n",
    "GLEU_val_emb = []\n",
    "test_data = df_test_adj_infl\n",
    "print(test_data.shape)\n",
    "\n",
    "for ind,i in tqdm(test_data.iterrows(),position=0):\n",
    "    try:\n",
    "        text = str(i.enc_input)\n",
    "        #pred = predict(str(i.enc_input),model)[0].split()\n",
    "        pred = correct_grammar(text, num_return_sequences=1)[0]\n",
    "        l = len(text)\n",
    "        p = len(pred)\n",
    "        if(p>l):\n",
    "            pred = pred[:l]\n",
    "            \n",
    "        act = [str(i.dec_input).split()]\n",
    "        pred_s = str(pred).split()\n",
    "        b = sentence_gleu(act,pred_s)\n",
    "        GLEU_val_emb.append(b)\n",
    "        if(ind%50 ==0):\n",
    "            print(\"GELU Score for \",ind+1,\" data point\",np.mean(GLEU_val_emb))\n",
    "    except:\n",
    "        continue\n",
    "print(\"GELU Score = \",np.mean(GLEU_val_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fad9cba8-9fc0-425b-a12a-9cf6d051116d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for ADJ_INFL Error=  0.7434265640344555\n"
     ]
    }
   ],
   "source": [
    "print(\"GELU Score for ADJ_INFL Error= \",np.mean(GLEU_val_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050f72db-9bb9-40d3-97af-ee0d85a3678a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48d3387c-c24c-4275-bc5e-efa3f9755f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(496, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  1  data point 0.6578947368421053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [02:15,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  101  data point 0.8025024854959928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [04:25,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  201  data point 0.805107032082467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [06:38,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  301  data point 0.8094019378566462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "401it [08:51,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  401  data point 0.8143655029809677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "496it [10:57,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score =  0.8095978571769412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from nltk.translate.gleu_score import sentence_gleu\n",
    "\n",
    "\n",
    "GLEU_val_emb = []\n",
    "test_data = df_test_pron_infl\n",
    "print(test_data.shape)\n",
    "\n",
    "for ind,i in tqdm(test_data.iterrows(),position=0):\n",
    "    try:\n",
    "        text = str(i.enc_input)\n",
    "        #pred = predict(str(i.enc_input),model)[0].split()\n",
    "        pred = correct_grammar(text, num_return_sequences=1)[0]\n",
    "        l = len(text)\n",
    "        p = len(pred)\n",
    "        if(p>l):\n",
    "            pred = pred[:l]\n",
    "            \n",
    "        act = [str(i.dec_input).split()]\n",
    "        pred_s = str(pred).split()\n",
    "        b = sentence_gleu(act,pred_s)\n",
    "        GLEU_val_emb.append(b)\n",
    "        if(ind%100 ==0):\n",
    "            print(\"GELU Score for \",ind+1,\" data point\",np.mean(GLEU_val_emb))\n",
    "    except:\n",
    "        continue\n",
    "print(\"GELU Score = \",np.mean(GLEU_val_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07da7565-b8c4-48c2-9d03-10e333bdd0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for PRON_INFL Error=  0.8095978571769412\n"
     ]
    }
   ],
   "source": [
    "print(\"GELU Score for PRON_INFL Error= \",np.mean(GLEU_val_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a058e9-f76a-4fc2-ae80-c4228f9bc61c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6df3b060-3da3-4c7d-a469-dcd1c3e4b6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:04,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  1  data point 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [07:03,  4.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score =  0.7324791038189717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from nltk.translate.gleu_score import sentence_gleu\n",
    "\n",
    "\n",
    "GLEU_val_emb = []\n",
    "test_data = df_test_adp_infl.head(100)\n",
    "print(test_data.shape)\n",
    "\n",
    "for ind,i in tqdm(test_data.iterrows(),position=0):\n",
    "    try:\n",
    "        text = str(i.enc_input)\n",
    "        #pred = predict(str(i.enc_input),model)[0].split()\n",
    "        pred = correct_grammar(text, num_return_sequences=1)[0]\n",
    "        l = len(text)\n",
    "        p = len(pred)\n",
    "        if(p>l):\n",
    "            pred = pred[:l]\n",
    "            \n",
    "        act = [str(i.dec_input).split()]\n",
    "        pred_s = str(pred).split()\n",
    "        b = sentence_gleu(act,pred_s)\n",
    "        GLEU_val_emb.append(b)\n",
    "        if(ind%200 ==0):\n",
    "            print(\"GELU Score for \",ind+1,\" data point\",np.mean(GLEU_val_emb))\n",
    "    except:\n",
    "        continue\n",
    "print(\"GELU Score = \",np.mean(GLEU_val_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4152590f-11cb-44b5-8ccd-44e032bcea58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for ADP_INFL Error=  0.7324791038189717\n"
     ]
    }
   ],
   "source": [
    "print(\"GELU Score for ADP_INFL Error= \",np.mean(GLEU_val_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4637706-5c90-4f2c-b7b8-25936a08af65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32093bfa-50f9-4d5c-8df0-ac9fecfca16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1101, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  1  data point 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [04:24,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  201  data point 0.827990913010508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "401it [08:48,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  401  data point 0.8107513856181036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "601it [13:11,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  601  data point 0.8063863263104685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "801it [17:33,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  801  data point 0.8080139789093645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [21:57,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  1001  data point 0.8102707580849008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1101it [24:11,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score =  0.8082467684365293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from nltk.translate.gleu_score import sentence_gleu\n",
    "\n",
    "\n",
    "GLEU_val_emb = []\n",
    "test_data = df_test_adp_infl\n",
    "print(test_data.shape)\n",
    "\n",
    "for ind,i in tqdm(test_data.iterrows(),position=0):\n",
    "    try:\n",
    "        text = str(i.enc_input)\n",
    "        #pred = predict(str(i.enc_input),model)[0].split()\n",
    "        pred = correct_grammar(text, num_return_sequences=1)[0]\n",
    "        l = len(text)\n",
    "        p = len(pred)\n",
    "        if(p>l):\n",
    "            pred = pred[:l]\n",
    "            \n",
    "        act = [str(i.dec_input).split()]\n",
    "        pred_s = str(pred).split()\n",
    "        b = sentence_gleu(act,pred_s)\n",
    "        GLEU_val_emb.append(b)\n",
    "        if(ind%200 ==0):\n",
    "            print(\"GELU Score for \",ind+1,\" data point\",np.mean(GLEU_val_emb))\n",
    "    except:\n",
    "        continue\n",
    "print(\"GELU Score = \",np.mean(GLEU_val_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1921f5d8-7445-4d60-8374-7908ef93654c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for ADP_INFL Error=  0.8082467684365293\n"
     ]
    }
   ],
   "source": [
    "print(\"GELU Score for ADP_INFL Error= \",np.mean(GLEU_val_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73af636-f27a-480b-a6a5-4339d2c7c23f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d211e56c-9bd1-4d2b-8723-da6e715e50db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5241, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  1  data point 0.9354838709677419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [21:59,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  1001  data point 0.8282614573022717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2001it [43:57,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  2001  data point 0.8175798609854311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3001it [1:05:55,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  3001  data point 0.8289549014661719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4001it [1:27:49,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  4001  data point 0.8287928854774717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5001it [1:49:50,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  5001  data point 0.8294709694830051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5241it [1:55:08,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score =  0.8298811959742303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from nltk.translate.gleu_score import sentence_gleu\n",
    "\n",
    "\n",
    "GLEU_val_emb = []\n",
    "test_data = df_test_verb_infl\n",
    "print(test_data.shape)\n",
    "\n",
    "for ind,i in tqdm(test_data.iterrows(),position=0):\n",
    "    try:\n",
    "        text = str(i.enc_input)\n",
    "        #pred = predict(str(i.enc_input),model)[0].split()\n",
    "        pred = correct_grammar(text, num_return_sequences=1)[0]\n",
    "        l = len(text)\n",
    "        p = len(pred)\n",
    "        if(p>l):\n",
    "            pred = pred[:l]\n",
    "            \n",
    "        act = [str(i.dec_input).split()]\n",
    "        pred_s = str(pred).split()\n",
    "        b = sentence_gleu(act,pred_s)\n",
    "        GLEU_val_emb.append(b)\n",
    "        if(ind%1000 ==0):\n",
    "            print(\"GELU Score for \",ind+1,\" data point\",np.mean(GLEU_val_emb))\n",
    "    except:\n",
    "        continue\n",
    "print(\"GELU Score = \",np.mean(GLEU_val_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ab474a7-400b-4eac-a752-1d7c3de32b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for VERB_INFL Error=  0.8298811959742303\n"
     ]
    }
   ],
   "source": [
    "print(\"GELU Score for VERB_INFL Error= \",np.mean(GLEU_val_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9a2cd3d7-1af4-4f5d-8993-33876292444d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(182, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:06,  6.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  1  data point 0.8780487804878049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "51it [05:44,  6.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  51  data point 0.693378284921975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [11:18,  6.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  101  data point 0.7262667914196586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "151it [16:52,  6.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  151  data point 0.7131101355914514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "182it [20:14,  6.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score =  0.7170992122074078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from nltk.translate.gleu_score import sentence_gleu\n",
    "\n",
    "\n",
    "GLEU_val_emb = []\n",
    "test_data = df_test_noun_infl\n",
    "print(test_data.shape)\n",
    "\n",
    "for ind,i in tqdm(test_data.iterrows(),position=0):\n",
    "    try:\n",
    "        text = str(i.enc_input)\n",
    "        #pred = predict(str(i.enc_input),model)[0].split()\n",
    "        pred = correct_grammar(text, num_return_sequences=1)[0]\n",
    "        l = len(text)\n",
    "        p = len(pred)\n",
    "        if(p>l):\n",
    "            pred = pred[:l]\n",
    "            \n",
    "        act = [str(i.dec_input).split()]\n",
    "        pred_s = str(pred).split()\n",
    "        b = sentence_gleu(act,pred_s)\n",
    "        GLEU_val_emb.append(b)\n",
    "        if(ind%50 ==0):\n",
    "            print(\"GELU Score for \",ind+1,\" data point\",np.mean(GLEU_val_emb))\n",
    "    except:\n",
    "        continue\n",
    "print(\"GELU Score = \",np.mean(GLEU_val_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "febf2bac-ff9d-4673-81da-1af6588e898e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for NOUN_INFL Error=  0.7170992122074078\n"
     ]
    }
   ],
   "source": [
    "print(\"GELU Score for NOUN_INFL Error= \",np.mean(GLEU_val_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc57a01-df6a-4982-b7b3-1c2be5ed2e68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "105e14f5-5def-40b4-89a3-be9dc31126c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13187, 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bc825034-6750-4534-bf2a-710b7471f5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13187, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:06,  6.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  1  data point 0.9354838709677419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [02:13,  6.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  21  data point 0.8085319589371981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "41it [04:16,  6.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  41  data point 0.8105983845524973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "61it [06:21,  6.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  61  data point 0.8078555837400341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [08:29,  6.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  81  data point 0.808525934806311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [10:30,  6.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score =  0.8067715348990488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from nltk.translate.gleu_score import sentence_gleu\n",
    "\n",
    "\n",
    "GLEU_val_emb = []\n",
    "test_data = df_test1.head(100)\n",
    "print(df_test1.shape)\n",
    "\n",
    "for ind,i in tqdm(test_data.iterrows(),position=0):\n",
    "    try:\n",
    "        text = str(i.enc_input)\n",
    "        #pred = predict(str(i.enc_input),model)[0].split()\n",
    "        pred = correct_grammar(text, num_return_sequences=1)[0]\n",
    "        l = len(text)\n",
    "        p = len(pred)\n",
    "        if(p>l):\n",
    "            pred = pred[:l]\n",
    "            \n",
    "        act = [str(i.dec_input).split()]\n",
    "        pred_s = str(pred).split()\n",
    "        b = sentence_gleu(act,pred_s)\n",
    "        GLEU_val_emb.append(b)\n",
    "        if(ind%20 ==0):\n",
    "            print(\"GELU Score for \",ind+1,\" data point\",np.mean(GLEU_val_emb))\n",
    "    except:\n",
    "        continue\n",
    "print(\"GELU Score = \",np.mean(GLEU_val_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febc574f-b357-4e0c-a9d5-68f7c1284733",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad474e87-62ca-401e-96e6-dad1e0179408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13187, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  1  data point 0.9354838709677419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [22:02,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  1001  data point 0.8039029214744148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2001it [43:37,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  2001  data point 0.8022953277285528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3001it [1:05:26,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  3001  data point 0.8045893234170699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4001it [1:26:50,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  4001  data point 0.8055452305729768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5001it [1:48:24,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  5001  data point 0.8044970005640886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6001it [2:09:51,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  6001  data point 0.812802730339381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7001it [2:31:06,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  7001  data point 0.8140137103670035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8001it [2:52:25,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  8001  data point 0.8129554474102898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9001it [3:13:58,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  9001  data point 0.8119726115275038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10001it [3:35:23,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  10001  data point 0.8115315126822349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11001it [3:56:50,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  11001  data point 0.8104934399514466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12001it [4:18:13,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  12001  data point 0.810914551153518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13001it [4:39:33,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  13001  data point 0.8095086869544634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13187it [4:43:27,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score =  0.8095147417782044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from nltk.translate.gleu_score import sentence_gleu\n",
    "\n",
    "\n",
    "GLEU_val_emb = []\n",
    "test_data = df_test1\n",
    "print(df_test1.shape)\n",
    "\n",
    "for ind,i in tqdm(test_data.iterrows(),position=0):\n",
    "    try:\n",
    "        text = str(i.enc_input)\n",
    "        #pred = predict(str(i.enc_input),model)[0].split()\n",
    "        pred = correct_grammar(text, num_return_sequences=1)[0]\n",
    "        l = len(text)\n",
    "        p = len(pred)\n",
    "        if(p>l):\n",
    "            pred = pred[:l]\n",
    "            \n",
    "        act = [str(i.dec_input).split()]\n",
    "        pred_s = str(pred).split()\n",
    "        b = sentence_gleu(act,pred_s)\n",
    "        GLEU_val_emb.append(b)\n",
    "        if(ind%1000 ==0):\n",
    "            print(\"GELU Score for \",ind+1,\" data point\",np.mean(GLEU_val_emb))\n",
    "    except:\n",
    "        continue\n",
    "print(\"GELU Score = \",np.mean(GLEU_val_emb))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
