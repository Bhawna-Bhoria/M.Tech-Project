{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a9c7780-28f4-4676-8620-cfeffba88c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Mar  1 14:20:23 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.84       Driver Version: 460.84       CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:04:00.0 Off |                  N/A |\n",
      "| 20%   21C    P8     8W / 250W |    447MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:06:00.0 Off |                  N/A |\n",
      "| 20%   21C    P8     6W / 250W |      2MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce GTX 108...  Off  | 00000000:07:00.0 Off |                  N/A |\n",
      "| 20%   43C    P2    56W / 250W |  10902MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce GTX 108...  Off  | 00000000:08:00.0 Off |                  N/A |\n",
      "| 20%   24C    P8     8W / 250W |      2MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  GeForce GTX 108...  Off  | 00000000:0C:00.0 Off |                  N/A |\n",
      "| 20%   38C    P8     8W / 250W |      2MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  GeForce GTX 108...  Off  | 00000000:0D:00.0 Off |                  N/A |\n",
      "| 20%   22C    P8     7W / 250W |    795MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  GeForce GTX 108...  Off  | 00000000:0E:00.0 Off |                  N/A |\n",
      "| 53%   82C    P2   208W / 250W |   6609MiB / 11178MiB |     99%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  GeForce GTX 108...  Off  | 00000000:0F:00.0 Off |                  N/A |\n",
      "| 32%   64C    P2    79W / 250W |   3183MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     38504      C   /opt/conda/bin/python             445MiB |\n",
      "|    2   N/A  N/A     14515      C   python3                          2919MiB |\n",
      "|    2   N/A  N/A     30017      C   /usr/bin/python3                 7981MiB |\n",
      "|    5   N/A  N/A     32689      C   /usr/bin/python3                  793MiB |\n",
      "|    6   N/A  N/A     40050      C   python3                          6607MiB |\n",
      "|    7   N/A  N/A      9775      C   python3                          3181MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1472674-e209-489e-93b9-3d3c8da03a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'GeForce GTX 1080 Ti'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# The GPU id to use, \"0\" to  \"7\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "#torch.cuda.set_device(0)\n",
    "n_gpu = torch.cuda.device_count()\n",
    "print(n_gpu)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.get_device_name(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ba40e0c-5fcc-43a9-8d28-47ff9e9870f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "340acc79-3319-47aa-8140-07059948a04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /DATA/gupta92/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "import random\n",
    "import re\n",
    "from itertools import chain\n",
    "from string import punctuation\n",
    "#Set a seed\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import datasets\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    T5ForConditionalGeneration,\n",
    "    T5Tokenizer,\n",
    "    get_linear_schedule_with_warmup\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7712b672-2f06-47dd-906a-42ab51326a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fc22694-eff1-4618-ad9c-8b6110972cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4aaf87c-52e6-4e3d-870c-1955b9afd376",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e4420cd-d086-467d-8384-bc29bb4d91ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140000, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('DATA/etoori_train.csv')\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fc84c40-1152-4f97-b749-186365fff1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = {'enc_input':'input'}, inplace = True)\n",
    "df.rename(columns = {'dec_input':'output'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a0a74f8-b795-47a1-aa0a-e3a293a0165b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>परन्तु वे दोनों उन बातों को ज़्यादा समय तक अप हृदय में गाँठ बनाकर नहीं रखते थे ।</td>\n",
       "      <td>परन्तु वे दोनों उन बातों को ज़्यादा समय तक अपने हृदय में गाँठ बनाकर नहीं रखते थे ।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>देश में हिन्दी को विस्थापित कर का षड़यंत्र चल रहा है जो चिंता का विषय है ।</td>\n",
       "      <td>देश में हिन्दी को विस्थापित करने का षड़यंत्र चल रहा है जो चिंता का विषय है ।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>तीन साल पहले कातिलाना हमले के प्रकरण में एफआर लग जा के बाद डेरा प्रेमी इस बार दर्ज हुए मुकदमे में सभी अभियुक्तों की गिरफ्तारी की मांग को लेकर आंदोलनरत हैं ।</td>\n",
       "      <td>तीन साल पहले कातिलाना हमले के प्रकरण में एफआर लग जाने के बाद डेरा प्रेमी इस बार दर्ज हुए मुकदमे में सभी अभियुक्तों की गिरफ्तारी की मांग को लेकर आंदोलनरत हैं ।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>रामायण रिविजिटेड अ टेल ऑफ लव एंड एडवेंचर नाम से सिंगापुर के पेरानांका म्यूजियम में प्रदर्शनी लगाई गई हैं ।</td>\n",
       "      <td>रामायण रिविजिटेड अ टेल ऑफ लव एंड एडवेंचर नाम से सिंगापुर के पेरानांका म्यूजियम में प्रदर्शनी लगाई गई है ।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>तब तक के लिए हमें विराम ले की अनुमति दीजिए ।</td>\n",
       "      <td>तब तक के लिए हमें विराम लेने की अनुमति दीजिए ।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>देव स्थेन तक सड़क बनाने की परियोजना चल रही है ।</td>\n",
       "      <td>देव स्थान तक सड़क बनाने की परियोजना चल रही है ।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>वर्ड वाचर व प्रसिद्ध चित्रकार अनूप साह आरएनएस को बताया कि श्वेतकंठ चिलचिल पक्षी का वैज्ञानिक नाम ह्वाइट थ्रोटेट लाफिंग थ्रस है ।</td>\n",
       "      <td>वर्ड वाचर व प्रसिद्ध चित्रकार अनूप साह ने आरएनएस को बताया कि श्वेतकंठ चिलचिल पक्षी का वैज्ञानिक नाम ह्वाइट थ्रोटेट लाफिंग थ्रस है ।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>दो दिन पहले ज्ञानजी पोस्ट ठेली जिसमें</td>\n",
       "      <td>दो दिन पहले ज्ञानजी ने पोस्ट ठेली जिसमें</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>दुर्घटना की स्थिति में बीमा कम्पनी द्वारा दी जा वाली राशि निर्धारित कर दी गई है ।</td>\n",
       "      <td>दुर्घटना की स्थिति में बीमा कम्पनी द्वारा दी जाने वाली राशि निर्धारित कर दी गई है ।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>देर से जाऊंगा तो दुकां बंद हो जाएंगी ।</td>\n",
       "      <td>देर से जाऊंगा तो दुकानें बंद हो जाएंगी ।</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                          input  \\\n",
       "0                                                                              परन्तु वे दोनों उन बातों को ज़्यादा समय तक अप हृदय में गाँठ बनाकर नहीं रखते थे ।   \n",
       "1                                                                                    देश में हिन्दी को विस्थापित कर का षड़यंत्र चल रहा है जो चिंता का विषय है ।   \n",
       "2  तीन साल पहले कातिलाना हमले के प्रकरण में एफआर लग जा के बाद डेरा प्रेमी इस बार दर्ज हुए मुकदमे में सभी अभियुक्तों की गिरफ्तारी की मांग को लेकर आंदोलनरत हैं ।   \n",
       "3                                                    रामायण रिविजिटेड अ टेल ऑफ लव एंड एडवेंचर नाम से सिंगापुर के पेरानांका म्यूजियम में प्रदर्शनी लगाई गई हैं ।   \n",
       "4                                                                                                                  तब तक के लिए हमें विराम ले की अनुमति दीजिए ।   \n",
       "5                                                                                                               देव स्थेन तक सड़क बनाने की परियोजना चल रही है ।   \n",
       "6                              वर्ड वाचर व प्रसिद्ध चित्रकार अनूप साह आरएनएस को बताया कि श्वेतकंठ चिलचिल पक्षी का वैज्ञानिक नाम ह्वाइट थ्रोटेट लाफिंग थ्रस है ।   \n",
       "7                                                                                                                         दो दिन पहले ज्ञानजी पोस्ट ठेली जिसमें   \n",
       "8                                                                             दुर्घटना की स्थिति में बीमा कम्पनी द्वारा दी जा वाली राशि निर्धारित कर दी गई है ।   \n",
       "9                                                                                                                        देर से जाऊंगा तो दुकां बंद हो जाएंगी ।   \n",
       "\n",
       "                                                                                                                                                            output  \n",
       "0                                                                              परन्तु वे दोनों उन बातों को ज़्यादा समय तक अपने हृदय में गाँठ बनाकर नहीं रखते थे ।   \n",
       "1                                                                                    देश में हिन्दी को विस्थापित करने का षड़यंत्र चल रहा है जो चिंता का विषय है ।   \n",
       "2  तीन साल पहले कातिलाना हमले के प्रकरण में एफआर लग जाने के बाद डेरा प्रेमी इस बार दर्ज हुए मुकदमे में सभी अभियुक्तों की गिरफ्तारी की मांग को लेकर आंदोलनरत हैं ।   \n",
       "3                                                       रामायण रिविजिटेड अ टेल ऑफ लव एंड एडवेंचर नाम से सिंगापुर के पेरानांका म्यूजियम में प्रदर्शनी लगाई गई है ।   \n",
       "4                                                                                                                  तब तक के लिए हमें विराम लेने की अनुमति दीजिए ।   \n",
       "5                                                                                                                 देव स्थान तक सड़क बनाने की परियोजना चल रही है ।   \n",
       "6                             वर्ड वाचर व प्रसिद्ध चित्रकार अनूप साह ने आरएनएस को बताया कि श्वेतकंठ चिलचिल पक्षी का वैज्ञानिक नाम ह्वाइट थ्रोटेट लाफिंग थ्रस है ।   \n",
       "7                                                                                                                         दो दिन पहले ज्ञानजी ने पोस्ट ठेली जिसमें  \n",
       "8                                                                             दुर्घटना की स्थिति में बीमा कम्पनी द्वारा दी जाने वाली राशि निर्धारित कर दी गई है ।   \n",
       "9                                                                                                                        देर से जाऊंगा तो दुकानें बंद हो जाएंगी ।   "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c81e7ec2-d0fa-45d6-be30-7c2e2877dc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    T5ForConditionalGeneration, T5Tokenizer, \n",
    "    Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq\n",
    "  )\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c509b356-7320-4dbb-9184-9750dd208a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/muril-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fc016f6-2311-4978-a799-f40e96abaef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='google/muril-base-cased', vocab_size=197285, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbc19d2f-5c42-46ea-8c21-decc47553c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98a081dd-fbb1-4b1d-a762-4d99ecc0ad9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First Initialize with t5-base, then have trained and saved t5_gec_hindi_muRIL_1, t5_gec_hindi_muRIL_2, t5_gec_hindi_muRIL_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b199d7a2-2b5d-4904-b204-a379c34aefca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "#model_name = 't5-base'\n",
    "#tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "#model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "model_name = 't5_gec_hindi_muRIL_3'\n",
    "torch_device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name).to(torch_device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ca44d0-39fd-48a8-a0a2-466fd4ce1d60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aca04df4-d7de-4f44-9800-94eb1c5296ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_token_len(example):\n",
    "    return len(tokenizer(example).input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9821b86-5a8b-4956-856c-d4c88d482f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((126000, 2), (14000, 2))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train - Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df, test_size=0.10, shuffle=True)\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c514352d-1338-4a42-95a6-36151e6b0306",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['input_token_len'] = test_df['input'].apply(calc_token_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9df2945-fb4d-4f63-b24b-2571dceba51b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>input_token_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40665</th>\n",
       "      <td>अँगरेज़ी सहभाषा के रूप में व्यवहत्त होनी चाहिए थी परंतु आज भी उसकी वर्चस्व सर्वत्र स्थापित है ।</td>\n",
       "      <td>अँगरेज़ी सहभाषा के रूप में व्यवहत्त होनी चाहिए थी परंतु आज भी उसका वर्चस्व सर्वत्र स्थापित है ।</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48520</th>\n",
       "      <td>तथे गौशाला का</td>\n",
       "      <td>तथा गौशाला का</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138403</th>\n",
       "      <td>बच्चे खेल रहे है किलकारियाँ गूंज रही है ब्रह्माण्ड में</td>\n",
       "      <td>बच्चे खेल रहे हैं किलकारियाँ गूंज रही हैं ब्रह्माण्ड में</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130079</th>\n",
       "      <td>धरने पर किसानो ने कहा कि अब समय आ गया हैं कि गन्ने की खेती किसानो के लिये नुकसान का सौदा हो गयी हैं ।</td>\n",
       "      <td>धरने पर किसानो ने कहा कि अब समय आ गया है कि गन्ने की खेती किसानो के लिये नुकसान का सौदा हो गयी है ।</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50146</th>\n",
       "      <td>सड़क मलबे का ढेर होने से दुपहिया व चार पहिया वाहन चालकों को परेशान होना पड़ रहा हैं ।</td>\n",
       "      <td>सड़क मलबे का ढेर होने से दुपहिया व चार पहिया वाहन चालकों को परेशान होना पड़ रहा है ।</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                        input  \\\n",
       "40665         अँगरेज़ी सहभाषा के रूप में व्यवहत्त होनी चाहिए थी परंतु आज भी उसकी वर्चस्व सर्वत्र स्थापित है ।   \n",
       "48520                                                                                           तथे गौशाला का   \n",
       "138403                                                 बच्चे खेल रहे है किलकारियाँ गूंज रही है ब्रह्माण्ड में   \n",
       "130079  धरने पर किसानो ने कहा कि अब समय आ गया हैं कि गन्ने की खेती किसानो के लिये नुकसान का सौदा हो गयी हैं ।   \n",
       "50146                   सड़क मलबे का ढेर होने से दुपहिया व चार पहिया वाहन चालकों को परेशान होना पड़ रहा हैं ।   \n",
       "\n",
       "                                                                                                      output  \\\n",
       "40665       अँगरेज़ी सहभाषा के रूप में व्यवहत्त होनी चाहिए थी परंतु आज भी उसका वर्चस्व सर्वत्र स्थापित है ।    \n",
       "48520                                                                                          तथा गौशाला का   \n",
       "138403                                              बच्चे खेल रहे हैं किलकारियाँ गूंज रही हैं ब्रह्माण्ड में   \n",
       "130079  धरने पर किसानो ने कहा कि अब समय आ गया है कि गन्ने की खेती किसानो के लिये नुकसान का सौदा हो गयी है ।    \n",
       "50146                  सड़क मलबे का ढेर होने से दुपहिया व चार पहिया वाहन चालकों को परेशान होना पड़ रहा है ।    \n",
       "\n",
       "        input_token_len  \n",
       "40665                28  \n",
       "48520                 6  \n",
       "138403               14  \n",
       "130079               29  \n",
       "50146                23  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd321d92-6f3a-40ee-ba4a-907be30ea244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    14000.000000\n",
       "mean        21.935000\n",
       "std         12.422581\n",
       "min          4.000000\n",
       "25%         14.000000\n",
       "50%         19.000000\n",
       "75%         27.000000\n",
       "max        308.000000\n",
       "Name: input_token_len, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['input_token_len'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5e933a2-ae5f-4c20-87b4-4dbb99b2c5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will use a token length of 64 since it will cover the vast majority of examples\n",
    "from datasets import Dataset\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ca6fab2-ae06-441f-807e-da87e843249b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'output', 'input_token_len', '__index_level_0__'],\n",
       "    num_rows: 14000\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d75fca39-9ccb-4bce-8a14-ca5d573cb60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the Dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class GrammarDataset(Dataset):\n",
    "    def __init__(self, dataset, tokenizer,print_text=False):         \n",
    "        self.dataset = dataset\n",
    "        self.pad_to_max_length = False\n",
    "        self.tokenizer = tokenizer\n",
    "        self.print_text = print_text\n",
    "        self.max_len = 64\n",
    "  \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "\n",
    "    def tokenize_data(self, example):\n",
    "        input_, target_ = example['input'], example['output']\n",
    "\n",
    "        # tokenize inputs\n",
    "        tokenized_inputs = tokenizer(input_, pad_to_max_length=self.pad_to_max_length, \n",
    "                                            max_length=self.max_len,\n",
    "                                            return_attention_mask=True)\n",
    "    \n",
    "        tokenized_targets = tokenizer(target_, pad_to_max_length=self.pad_to_max_length, \n",
    "                                            max_length=self.max_len,\n",
    "                                            return_attention_mask=True)\n",
    "\n",
    "        inputs={\"input_ids\": tokenized_inputs['input_ids'],\n",
    "            \"attention_mask\": tokenized_inputs['attention_mask'],\n",
    "            \"labels\": tokenized_targets['input_ids']\n",
    "        }\n",
    "        \n",
    "        return inputs\n",
    "\n",
    "  \n",
    "    def __getitem__(self, index):\n",
    "        inputs = self.tokenize_data(self.dataset[index])\n",
    "        \n",
    "        if self.print_text:\n",
    "            for k in inputs.keys():\n",
    "                print(k, len(inputs[k]))\n",
    "\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b8aa2940-f691-4bc5-9c05-d70ff42e05ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids 27\n",
      "attention_mask 27\n",
      "labels 27\n",
      "{'input_ids': [104, 75159, 1154, 7899, 106524, 3768, 1169, 16015, 1250, 2316, 1419, 1123, 7132, 64219, 2115, 1125, 30361, 1438, 1228, 106524, 1117, 10171, 1194, 1254, 7544, 492, 105], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [104, 75159, 1154, 7899, 106524, 3768, 1169, 16015, 1250, 2316, 1243, 1123, 7132, 64219, 2115, 1125, 30361, 1438, 1228, 106524, 1117, 10171, 1194, 1254, 7544, 492, 105]}\n"
     ]
    }
   ],
   "source": [
    "dataset = GrammarDataset(test_dataset, tokenizer, True)\n",
    "print(dataset[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfc0564-2706-4d95-8dfb-e9970a0e2a02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e6bd3fc-b11e-47a1-b473-10705ebe1d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Evaluator\n",
    "#!pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f50438a6-1ed2-460a-8bb0-307fa7b23806",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "rouge_metric = load_metric(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bf186c82-6bea-4bb3-b9f3-1b00df72ee70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Model\n",
    "#data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, padding='longest', return_tensors='pt')\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, padding='longest', return_tensors='pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b108ae3-2088-44fa-af0f-8b3583bd157d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining training related arguments\n",
    "batch_size = 8\n",
    "'''\n",
    "args = Seq2SeqTrainingArguments(output_dir=\"models/hindi/T5_muRIL_3\",\n",
    "                        evaluation_strategy=\"epoch\",\n",
    "                        per_device_train_batch_size=batch_size,\n",
    "                        per_device_eval_batch_size=batch_size,\n",
    "                        learning_rate=2e-5,\n",
    "                        num_train_epochs=2,\n",
    "                        weight_decay=0.1,\n",
    "                        save_total_limit=2,\n",
    "                        predict_with_generate=True,\n",
    "                        fp16 = True,\n",
    "                        gradient_accumulation_steps = 6,\n",
    "                        #eval_steps = 500,\n",
    "                        #save_steps = 2000,\n",
    "                        #dataloader_num_workers= 4,\n",
    "                        load_best_model_at_end=True,\n",
    "                        logging_dir=\"logs/hindi/T5_muRIL_3\")\n",
    "'''\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"models/hindi/T5_muRIL\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.1,\n",
    "    save_steps=10000,\n",
    "    num_train_epochs=5,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    #logging_dir=\"logs/hindi/T5_muRIL_3\"\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e2a430e6-c635-43bb-a305-357ac0773191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "#os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"false\"\n",
    "os.environ['TRANSFORMERS_NO_ADVISORY_WARNINGS'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bfbcd6b1-bdcb-4f9d-a7ca-cd6924d7e6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d9743c7-8b58-4bee-9ab1-2fcd8032b17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuda_amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "# defining trainer using 🤗\n",
    "trainer = Seq2SeqTrainer(model=model, \n",
    "                args=args, \n",
    "                train_dataset= GrammarDataset(train_dataset, tokenizer),\n",
    "                eval_dataset=GrammarDataset(test_dataset, tokenizer),\n",
    "                tokenizer=tokenizer,\n",
    "                data_collator=data_collator)\n",
    "                #compute_metrics=compute_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "50e692da-5dee-4325-b082-b660f82d1e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch\n",
    "#torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aaaea036-afff-4988-b9c3-605dace1b50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 126000\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 78750\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='78750' max='78750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [78750/78750 6:38:13, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.524600</td>\n",
       "      <td>0.324090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.444900</td>\n",
       "      <td>0.240954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.391500</td>\n",
       "      <td>0.194559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.356900</td>\n",
       "      <td>0.176006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.348300</td>\n",
       "      <td>0.169690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to models/hindi/T5_muRIL/checkpoint-10000\n",
      "Configuration saved in models/hindi/T5_muRIL/checkpoint-10000/config.json\n",
      "Model weights saved in models/hindi/T5_muRIL/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in models/hindi/T5_muRIL/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in models/hindi/T5_muRIL/checkpoint-10000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to models/hindi/T5_muRIL/checkpoint-20000\n",
      "Configuration saved in models/hindi/T5_muRIL/checkpoint-20000/config.json\n",
      "Model weights saved in models/hindi/T5_muRIL/checkpoint-20000/pytorch_model.bin\n",
      "tokenizer config file saved in models/hindi/T5_muRIL/checkpoint-20000/tokenizer_config.json\n",
      "Special tokens file saved in models/hindi/T5_muRIL/checkpoint-20000/special_tokens_map.json\n",
      "Saving model checkpoint to models/hindi/T5_muRIL/checkpoint-30000\n",
      "Configuration saved in models/hindi/T5_muRIL/checkpoint-30000/config.json\n",
      "Model weights saved in models/hindi/T5_muRIL/checkpoint-30000/pytorch_model.bin\n",
      "tokenizer config file saved in models/hindi/T5_muRIL/checkpoint-30000/tokenizer_config.json\n",
      "Special tokens file saved in models/hindi/T5_muRIL/checkpoint-30000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to models/hindi/T5_muRIL/checkpoint-40000\n",
      "Configuration saved in models/hindi/T5_muRIL/checkpoint-40000/config.json\n",
      "Model weights saved in models/hindi/T5_muRIL/checkpoint-40000/pytorch_model.bin\n",
      "tokenizer config file saved in models/hindi/T5_muRIL/checkpoint-40000/tokenizer_config.json\n",
      "Special tokens file saved in models/hindi/T5_muRIL/checkpoint-40000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to models/hindi/T5_muRIL/checkpoint-50000\n",
      "Configuration saved in models/hindi/T5_muRIL/checkpoint-50000/config.json\n",
      "Model weights saved in models/hindi/T5_muRIL/checkpoint-50000/pytorch_model.bin\n",
      "tokenizer config file saved in models/hindi/T5_muRIL/checkpoint-50000/tokenizer_config.json\n",
      "Special tokens file saved in models/hindi/T5_muRIL/checkpoint-50000/special_tokens_map.json\n",
      "Saving model checkpoint to models/hindi/T5_muRIL/checkpoint-60000\n",
      "Configuration saved in models/hindi/T5_muRIL/checkpoint-60000/config.json\n",
      "Model weights saved in models/hindi/T5_muRIL/checkpoint-60000/pytorch_model.bin\n",
      "tokenizer config file saved in models/hindi/T5_muRIL/checkpoint-60000/tokenizer_config.json\n",
      "Special tokens file saved in models/hindi/T5_muRIL/checkpoint-60000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to models/hindi/T5_muRIL/checkpoint-70000\n",
      "Configuration saved in models/hindi/T5_muRIL/checkpoint-70000/config.json\n",
      "Model weights saved in models/hindi/T5_muRIL/checkpoint-70000/pytorch_model.bin\n",
      "tokenizer config file saved in models/hindi/T5_muRIL/checkpoint-70000/tokenizer_config.json\n",
      "Special tokens file saved in models/hindi/T5_muRIL/checkpoint-70000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14000\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=78750, training_loss=0.4303435190352183, metrics={'train_runtime': 23896.2568, 'train_samples_per_second': 26.364, 'train_steps_per_second': 3.295, 'total_flos': 2.96756122281984e+16, 'train_loss': 0.4303435190352183, 'epoch': 5.0})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Wandb API Key: bcdbdd5ee9d76a20c90b5f2a246eb45f14b341a9\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"     #Disabling Wandb\n",
    "#model.resize_token_embeddings(len(tokenizer))\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4313cc0-2a52-490a-bdbd-097c6832a0b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e065a0b4-9437-4647-a581-407445c7bf42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3e746eaf-0ec9-4884-b86f-605a3e569776",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 126000\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 15750\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15750' max='15750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15750/15750 1:19:12, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.669900</td>\n",
       "      <td>0.476513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to models/hindi/T5_muRIL_3/checkpoint-10000\n",
      "Configuration saved in models/hindi/T5_muRIL_3/checkpoint-10000/config.json\n",
      "Model weights saved in models/hindi/T5_muRIL_3/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in models/hindi/T5_muRIL_3/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in models/hindi/T5_muRIL_3/checkpoint-10000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14000\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=15750, training_loss=0.7122194562639509, metrics={'train_runtime': 4755.8781, 'train_samples_per_second': 26.494, 'train_steps_per_second': 3.312, 'total_flos': 5930269812449280.0, 'train_loss': 0.7122194562639509, 'epoch': 1.0})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Wandb API Key: bcdbdd5ee9d76a20c90b5f2a246eb45f14b341a9\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"     #Disabling Wandb\n",
    "#model.resize_token_embeddings(len(tokenizer))\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2e3dab-c263-41e6-81e6-f241db21be94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9f5246-3f39-4d82-b4b6-a31f62d60a76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3432ba00-8cd4-4656-aae6-8b886eb97d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 126000\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 31500\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31500' max='31500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31500/31500 3:10:10, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.246400</td>\n",
       "      <td>1.125347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to models/hindi/T5_muRIL_3/checkpoint-2000\n",
      "Configuration saved in models/hindi/T5_muRIL_3/checkpoint-2000/config.json\n",
      "Model weights saved in models/hindi/T5_muRIL_3/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in models/hindi/T5_muRIL_3/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in models/hindi/T5_muRIL_3/checkpoint-2000/special_tokens_map.json\n",
      "Saving model checkpoint to models/hindi/T5_muRIL_3/checkpoint-4000\n",
      "Configuration saved in models/hindi/T5_muRIL_3/checkpoint-4000/config.json\n",
      "Model weights saved in models/hindi/T5_muRIL_3/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in models/hindi/T5_muRIL_3/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in models/hindi/T5_muRIL_3/checkpoint-4000/special_tokens_map.json\n",
      "Saving model checkpoint to models/hindi/T5_muRIL_3/checkpoint-6000\n",
      "Configuration saved in models/hindi/T5_muRIL_3/checkpoint-6000/config.json\n",
      "Model weights saved in models/hindi/T5_muRIL_3/checkpoint-6000/pytorch_model.bin\n",
      "tokenizer config file saved in models/hindi/T5_muRIL_3/checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in models/hindi/T5_muRIL_3/checkpoint-6000/special_tokens_map.json\n",
      "Saving model checkpoint to models/hindi/T5_muRIL_3/checkpoint-8000\n",
      "Configuration saved in models/hindi/T5_muRIL_3/checkpoint-8000/config.json\n",
      "Model weights saved in models/hindi/T5_muRIL_3/checkpoint-8000/pytorch_model.bin\n",
      "tokenizer config file saved in models/hindi/T5_muRIL_3/checkpoint-8000/tokenizer_config.json\n",
      "Special tokens file saved in models/hindi/T5_muRIL_3/checkpoint-8000/special_tokens_map.json\n",
      "Saving model checkpoint to models/hindi/T5_muRIL_3/checkpoint-10000\n",
      "Configuration saved in models/hindi/T5_muRIL_3/checkpoint-10000/config.json\n",
      "Model weights saved in models/hindi/T5_muRIL_3/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in models/hindi/T5_muRIL_3/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in models/hindi/T5_muRIL_3/checkpoint-10000/special_tokens_map.json\n",
      "Saving model checkpoint to models/hindi/T5_muRIL_3/checkpoint-12000\n",
      "Configuration saved in models/hindi/T5_muRIL_3/checkpoint-12000/config.json\n",
      "Model weights saved in models/hindi/T5_muRIL_3/checkpoint-12000/pytorch_model.bin\n",
      "tokenizer config file saved in models/hindi/T5_muRIL_3/checkpoint-12000/tokenizer_config.json\n",
      "Special tokens file saved in models/hindi/T5_muRIL_3/checkpoint-12000/special_tokens_map.json\n",
      "Saving model checkpoint to models/hindi/T5_muRIL_3/checkpoint-14000\n",
      "Configuration saved in models/hindi/T5_muRIL_3/checkpoint-14000/config.json\n",
      "Model weights saved in models/hindi/T5_muRIL_3/checkpoint-14000/pytorch_model.bin\n",
      "tokenizer config file saved in models/hindi/T5_muRIL_3/checkpoint-14000/tokenizer_config.json\n",
      "Special tokens file saved in models/hindi/T5_muRIL_3/checkpoint-14000/special_tokens_map.json\n",
      "Saving model checkpoint to models/hindi/T5_muRIL_3/checkpoint-16000\n",
      "Configuration saved in models/hindi/T5_muRIL_3/checkpoint-16000/config.json\n",
      "Model weights saved in models/hindi/T5_muRIL_3/checkpoint-16000/pytorch_model.bin\n",
      "tokenizer config file saved in models/hindi/T5_muRIL_3/checkpoint-16000/tokenizer_config.json\n",
      "Special tokens file saved in models/hindi/T5_muRIL_3/checkpoint-16000/special_tokens_map.json\n",
      "Saving model checkpoint to models/hindi/T5_muRIL_3/checkpoint-18000\n",
      "Configuration saved in models/hindi/T5_muRIL_3/checkpoint-18000/config.json\n",
      "Model weights saved in models/hindi/T5_muRIL_3/checkpoint-18000/pytorch_model.bin\n",
      "tokenizer config file saved in models/hindi/T5_muRIL_3/checkpoint-18000/tokenizer_config.json\n",
      "Special tokens file saved in models/hindi/T5_muRIL_3/checkpoint-18000/special_tokens_map.json\n",
      "Saving model checkpoint to models/hindi/T5_muRIL_3/checkpoint-20000\n",
      "Configuration saved in models/hindi/T5_muRIL_3/checkpoint-20000/config.json\n",
      "Model weights saved in models/hindi/T5_muRIL_3/checkpoint-20000/pytorch_model.bin\n",
      "tokenizer config file saved in models/hindi/T5_muRIL_3/checkpoint-20000/tokenizer_config.json\n",
      "Special tokens file saved in models/hindi/T5_muRIL_3/checkpoint-20000/special_tokens_map.json\n",
      "Saving model checkpoint to models/hindi/T5_muRIL_3/checkpoint-22000\n",
      "Configuration saved in models/hindi/T5_muRIL_3/checkpoint-22000/config.json\n",
      "Model weights saved in models/hindi/T5_muRIL_3/checkpoint-22000/pytorch_model.bin\n",
      "tokenizer config file saved in models/hindi/T5_muRIL_3/checkpoint-22000/tokenizer_config.json\n",
      "Special tokens file saved in models/hindi/T5_muRIL_3/checkpoint-22000/special_tokens_map.json\n",
      "Saving model checkpoint to models/hindi/T5_muRIL_3/checkpoint-24000\n",
      "Configuration saved in models/hindi/T5_muRIL_3/checkpoint-24000/config.json\n",
      "Model weights saved in models/hindi/T5_muRIL_3/checkpoint-24000/pytorch_model.bin\n",
      "tokenizer config file saved in models/hindi/T5_muRIL_3/checkpoint-24000/tokenizer_config.json\n",
      "Special tokens file saved in models/hindi/T5_muRIL_3/checkpoint-24000/special_tokens_map.json\n",
      "Saving model checkpoint to models/hindi/T5_muRIL_3/checkpoint-26000\n",
      "Configuration saved in models/hindi/T5_muRIL_3/checkpoint-26000/config.json\n",
      "Model weights saved in models/hindi/T5_muRIL_3/checkpoint-26000/pytorch_model.bin\n",
      "tokenizer config file saved in models/hindi/T5_muRIL_3/checkpoint-26000/tokenizer_config.json\n",
      "Special tokens file saved in models/hindi/T5_muRIL_3/checkpoint-26000/special_tokens_map.json\n",
      "Saving model checkpoint to models/hindi/T5_muRIL_3/checkpoint-28000\n",
      "Configuration saved in models/hindi/T5_muRIL_3/checkpoint-28000/config.json\n",
      "Model weights saved in models/hindi/T5_muRIL_3/checkpoint-28000/pytorch_model.bin\n",
      "tokenizer config file saved in models/hindi/T5_muRIL_3/checkpoint-28000/tokenizer_config.json\n",
      "Special tokens file saved in models/hindi/T5_muRIL_3/checkpoint-28000/special_tokens_map.json\n",
      "Saving model checkpoint to models/hindi/T5_muRIL_3/checkpoint-30000\n",
      "Configuration saved in models/hindi/T5_muRIL_3/checkpoint-30000/config.json\n",
      "Model weights saved in models/hindi/T5_muRIL_3/checkpoint-30000/pytorch_model.bin\n",
      "tokenizer config file saved in models/hindi/T5_muRIL_3/checkpoint-30000/tokenizer_config.json\n",
      "Special tokens file saved in models/hindi/T5_muRIL_3/checkpoint-30000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14000\n",
      "  Batch size = 4\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=31500, training_loss=1.3424053199404762, metrics={'train_runtime': 11415.222, 'train_samples_per_second': 11.038, 'train_steps_per_second': 2.759, 'total_flos': 5013459920793600.0, 'train_loss': 1.3424053199404762, 'epoch': 1.0})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Wandb API Key: bcdbdd5ee9d76a20c90b5f2a246eb45f14b341a9\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"     #Disabling Wandb\n",
    "#model.resize_token_embeddings(len(tokenizer))\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f4ed8776-52ca-4d06-9e15-158994267915",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch_device = 'cuda' if torch.cuda.is_available() else 'cpu' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b68254c3-619e-464f-bfa6-01c21279c6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to t5_gec_hindi_muRIL\n",
      "Configuration saved in t5_gec_hindi_muRIL/config.json\n",
      "Model weights saved in t5_gec_hindi_muRIL/pytorch_model.bin\n",
      "tokenizer config file saved in t5_gec_hindi_muRIL/tokenizer_config.json\n",
      "Special tokens file saved in t5_gec_hindi_muRIL/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "#Save the trained Model\n",
    "trainer.save_model('t5_gec_hindi_muRIL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627b9bd5-acdd-4728-8bb5-8ac6bb809b76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa6e472-f983-4018-97ea-fd020ae3ea39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!zip -r 't5_gec_hindi_muRIL_2.zip' 't5_gec_hindi_muRIL_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3895631b-8f35-4ea2-930f-ef9c56e17072",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da45d37b-cd1f-43e7-a4e2-bc18ef984b14",
   "metadata": {},
   "source": [
    "# Testing Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ea2de44-6fbe-40a6-ba4f-f074a82b6767",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing\n",
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration,AutoTokenizer\n",
    "model_name = 't5_gec_hindi_muRIL'\n",
    "torch_device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/muril-base-cased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98143e4e-6280-4ab1-96a5-2be73cad8d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer = AutoTokenizer.from_pretrained(\"surajp/RoBERTa-hindi-guj-san\")\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"google/muril-base-cased\")\n",
    "trained_model = T5ForConditionalGeneration.from_pretrained(model_name).to(torch_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dee6d65-83bc-4bb6-bdbc-8511c6becea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(197285, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(197285, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(197285, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=197285, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cde5ea1c-2854-458b-bd0e-288c372d6768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------+------------+\n",
      "|                               Modules                                | Parameters |\n",
      "+----------------------------------------------------------------------+------------+\n",
      "|                            shared.weight                             | 151514880  |\n",
      "|            encoder.block.0.layer.0.SelfAttention.q.weight            |   589824   |\n",
      "|            encoder.block.0.layer.0.SelfAttention.k.weight            |   589824   |\n",
      "|            encoder.block.0.layer.0.SelfAttention.v.weight            |   589824   |\n",
      "|            encoder.block.0.layer.0.SelfAttention.o.weight            |   589824   |\n",
      "| encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight |    384     |\n",
      "|              encoder.block.0.layer.0.layer_norm.weight               |    768     |\n",
      "|           encoder.block.0.layer.1.DenseReluDense.wi.weight           |  2359296   |\n",
      "|           encoder.block.0.layer.1.DenseReluDense.wo.weight           |  2359296   |\n",
      "|              encoder.block.0.layer.1.layer_norm.weight               |    768     |\n",
      "|            encoder.block.1.layer.0.SelfAttention.q.weight            |   589824   |\n",
      "|            encoder.block.1.layer.0.SelfAttention.k.weight            |   589824   |\n",
      "|            encoder.block.1.layer.0.SelfAttention.v.weight            |   589824   |\n",
      "|            encoder.block.1.layer.0.SelfAttention.o.weight            |   589824   |\n",
      "|              encoder.block.1.layer.0.layer_norm.weight               |    768     |\n",
      "|           encoder.block.1.layer.1.DenseReluDense.wi.weight           |  2359296   |\n",
      "|           encoder.block.1.layer.1.DenseReluDense.wo.weight           |  2359296   |\n",
      "|              encoder.block.1.layer.1.layer_norm.weight               |    768     |\n",
      "|            encoder.block.2.layer.0.SelfAttention.q.weight            |   589824   |\n",
      "|            encoder.block.2.layer.0.SelfAttention.k.weight            |   589824   |\n",
      "|            encoder.block.2.layer.0.SelfAttention.v.weight            |   589824   |\n",
      "|            encoder.block.2.layer.0.SelfAttention.o.weight            |   589824   |\n",
      "|              encoder.block.2.layer.0.layer_norm.weight               |    768     |\n",
      "|           encoder.block.2.layer.1.DenseReluDense.wi.weight           |  2359296   |\n",
      "|           encoder.block.2.layer.1.DenseReluDense.wo.weight           |  2359296   |\n",
      "|              encoder.block.2.layer.1.layer_norm.weight               |    768     |\n",
      "|            encoder.block.3.layer.0.SelfAttention.q.weight            |   589824   |\n",
      "|            encoder.block.3.layer.0.SelfAttention.k.weight            |   589824   |\n",
      "|            encoder.block.3.layer.0.SelfAttention.v.weight            |   589824   |\n",
      "|            encoder.block.3.layer.0.SelfAttention.o.weight            |   589824   |\n",
      "|              encoder.block.3.layer.0.layer_norm.weight               |    768     |\n",
      "|           encoder.block.3.layer.1.DenseReluDense.wi.weight           |  2359296   |\n",
      "|           encoder.block.3.layer.1.DenseReluDense.wo.weight           |  2359296   |\n",
      "|              encoder.block.3.layer.1.layer_norm.weight               |    768     |\n",
      "|            encoder.block.4.layer.0.SelfAttention.q.weight            |   589824   |\n",
      "|            encoder.block.4.layer.0.SelfAttention.k.weight            |   589824   |\n",
      "|            encoder.block.4.layer.0.SelfAttention.v.weight            |   589824   |\n",
      "|            encoder.block.4.layer.0.SelfAttention.o.weight            |   589824   |\n",
      "|              encoder.block.4.layer.0.layer_norm.weight               |    768     |\n",
      "|           encoder.block.4.layer.1.DenseReluDense.wi.weight           |  2359296   |\n",
      "|           encoder.block.4.layer.1.DenseReluDense.wo.weight           |  2359296   |\n",
      "|              encoder.block.4.layer.1.layer_norm.weight               |    768     |\n",
      "|            encoder.block.5.layer.0.SelfAttention.q.weight            |   589824   |\n",
      "|            encoder.block.5.layer.0.SelfAttention.k.weight            |   589824   |\n",
      "|            encoder.block.5.layer.0.SelfAttention.v.weight            |   589824   |\n",
      "|            encoder.block.5.layer.0.SelfAttention.o.weight            |   589824   |\n",
      "|              encoder.block.5.layer.0.layer_norm.weight               |    768     |\n",
      "|           encoder.block.5.layer.1.DenseReluDense.wi.weight           |  2359296   |\n",
      "|           encoder.block.5.layer.1.DenseReluDense.wo.weight           |  2359296   |\n",
      "|              encoder.block.5.layer.1.layer_norm.weight               |    768     |\n",
      "|            encoder.block.6.layer.0.SelfAttention.q.weight            |   589824   |\n",
      "|            encoder.block.6.layer.0.SelfAttention.k.weight            |   589824   |\n",
      "|            encoder.block.6.layer.0.SelfAttention.v.weight            |   589824   |\n",
      "|            encoder.block.6.layer.0.SelfAttention.o.weight            |   589824   |\n",
      "|              encoder.block.6.layer.0.layer_norm.weight               |    768     |\n",
      "|           encoder.block.6.layer.1.DenseReluDense.wi.weight           |  2359296   |\n",
      "|           encoder.block.6.layer.1.DenseReluDense.wo.weight           |  2359296   |\n",
      "|              encoder.block.6.layer.1.layer_norm.weight               |    768     |\n",
      "|            encoder.block.7.layer.0.SelfAttention.q.weight            |   589824   |\n",
      "|            encoder.block.7.layer.0.SelfAttention.k.weight            |   589824   |\n",
      "|            encoder.block.7.layer.0.SelfAttention.v.weight            |   589824   |\n",
      "|            encoder.block.7.layer.0.SelfAttention.o.weight            |   589824   |\n",
      "|              encoder.block.7.layer.0.layer_norm.weight               |    768     |\n",
      "|           encoder.block.7.layer.1.DenseReluDense.wi.weight           |  2359296   |\n",
      "|           encoder.block.7.layer.1.DenseReluDense.wo.weight           |  2359296   |\n",
      "|              encoder.block.7.layer.1.layer_norm.weight               |    768     |\n",
      "|            encoder.block.8.layer.0.SelfAttention.q.weight            |   589824   |\n",
      "|            encoder.block.8.layer.0.SelfAttention.k.weight            |   589824   |\n",
      "|            encoder.block.8.layer.0.SelfAttention.v.weight            |   589824   |\n",
      "|            encoder.block.8.layer.0.SelfAttention.o.weight            |   589824   |\n",
      "|              encoder.block.8.layer.0.layer_norm.weight               |    768     |\n",
      "|           encoder.block.8.layer.1.DenseReluDense.wi.weight           |  2359296   |\n",
      "|           encoder.block.8.layer.1.DenseReluDense.wo.weight           |  2359296   |\n",
      "|              encoder.block.8.layer.1.layer_norm.weight               |    768     |\n",
      "|            encoder.block.9.layer.0.SelfAttention.q.weight            |   589824   |\n",
      "|            encoder.block.9.layer.0.SelfAttention.k.weight            |   589824   |\n",
      "|            encoder.block.9.layer.0.SelfAttention.v.weight            |   589824   |\n",
      "|            encoder.block.9.layer.0.SelfAttention.o.weight            |   589824   |\n",
      "|              encoder.block.9.layer.0.layer_norm.weight               |    768     |\n",
      "|           encoder.block.9.layer.1.DenseReluDense.wi.weight           |  2359296   |\n",
      "|           encoder.block.9.layer.1.DenseReluDense.wo.weight           |  2359296   |\n",
      "|              encoder.block.9.layer.1.layer_norm.weight               |    768     |\n",
      "|           encoder.block.10.layer.0.SelfAttention.q.weight            |   589824   |\n",
      "|           encoder.block.10.layer.0.SelfAttention.k.weight            |   589824   |\n",
      "|           encoder.block.10.layer.0.SelfAttention.v.weight            |   589824   |\n",
      "|           encoder.block.10.layer.0.SelfAttention.o.weight            |   589824   |\n",
      "|              encoder.block.10.layer.0.layer_norm.weight              |    768     |\n",
      "|          encoder.block.10.layer.1.DenseReluDense.wi.weight           |  2359296   |\n",
      "|          encoder.block.10.layer.1.DenseReluDense.wo.weight           |  2359296   |\n",
      "|              encoder.block.10.layer.1.layer_norm.weight              |    768     |\n",
      "|           encoder.block.11.layer.0.SelfAttention.q.weight            |   589824   |\n",
      "|           encoder.block.11.layer.0.SelfAttention.k.weight            |   589824   |\n",
      "|           encoder.block.11.layer.0.SelfAttention.v.weight            |   589824   |\n",
      "|           encoder.block.11.layer.0.SelfAttention.o.weight            |   589824   |\n",
      "|              encoder.block.11.layer.0.layer_norm.weight              |    768     |\n",
      "|          encoder.block.11.layer.1.DenseReluDense.wi.weight           |  2359296   |\n",
      "|          encoder.block.11.layer.1.DenseReluDense.wo.weight           |  2359296   |\n",
      "|              encoder.block.11.layer.1.layer_norm.weight              |    768     |\n",
      "|                   encoder.final_layer_norm.weight                    |    768     |\n",
      "|            decoder.block.0.layer.0.SelfAttention.q.weight            |   589824   |\n",
      "|            decoder.block.0.layer.0.SelfAttention.k.weight            |   589824   |\n",
      "|            decoder.block.0.layer.0.SelfAttention.v.weight            |   589824   |\n",
      "|            decoder.block.0.layer.0.SelfAttention.o.weight            |   589824   |\n",
      "| decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight |    384     |\n",
      "|              decoder.block.0.layer.0.layer_norm.weight               |    768     |\n",
      "|           decoder.block.0.layer.1.EncDecAttention.q.weight           |   589824   |\n",
      "|           decoder.block.0.layer.1.EncDecAttention.k.weight           |   589824   |\n",
      "|           decoder.block.0.layer.1.EncDecAttention.v.weight           |   589824   |\n",
      "|           decoder.block.0.layer.1.EncDecAttention.o.weight           |   589824   |\n",
      "|              decoder.block.0.layer.1.layer_norm.weight               |    768     |\n",
      "|           decoder.block.0.layer.2.DenseReluDense.wi.weight           |  2359296   |\n",
      "|           decoder.block.0.layer.2.DenseReluDense.wo.weight           |  2359296   |\n",
      "|              decoder.block.0.layer.2.layer_norm.weight               |    768     |\n",
      "|            decoder.block.1.layer.0.SelfAttention.q.weight            |   589824   |\n",
      "|            decoder.block.1.layer.0.SelfAttention.k.weight            |   589824   |\n",
      "|            decoder.block.1.layer.0.SelfAttention.v.weight            |   589824   |\n",
      "|            decoder.block.1.layer.0.SelfAttention.o.weight            |   589824   |\n",
      "|              decoder.block.1.layer.0.layer_norm.weight               |    768     |\n",
      "|           decoder.block.1.layer.1.EncDecAttention.q.weight           |   589824   |\n",
      "|           decoder.block.1.layer.1.EncDecAttention.k.weight           |   589824   |\n",
      "|           decoder.block.1.layer.1.EncDecAttention.v.weight           |   589824   |\n",
      "|           decoder.block.1.layer.1.EncDecAttention.o.weight           |   589824   |\n",
      "|              decoder.block.1.layer.1.layer_norm.weight               |    768     |\n",
      "|           decoder.block.1.layer.2.DenseReluDense.wi.weight           |  2359296   |\n",
      "|           decoder.block.1.layer.2.DenseReluDense.wo.weight           |  2359296   |\n",
      "|              decoder.block.1.layer.2.layer_norm.weight               |    768     |\n",
      "|            decoder.block.2.layer.0.SelfAttention.q.weight            |   589824   |\n",
      "|            decoder.block.2.layer.0.SelfAttention.k.weight            |   589824   |\n",
      "|            decoder.block.2.layer.0.SelfAttention.v.weight            |   589824   |\n",
      "|            decoder.block.2.layer.0.SelfAttention.o.weight            |   589824   |\n",
      "|              decoder.block.2.layer.0.layer_norm.weight               |    768     |\n",
      "|           decoder.block.2.layer.1.EncDecAttention.q.weight           |   589824   |\n",
      "|           decoder.block.2.layer.1.EncDecAttention.k.weight           |   589824   |\n",
      "|           decoder.block.2.layer.1.EncDecAttention.v.weight           |   589824   |\n",
      "|           decoder.block.2.layer.1.EncDecAttention.o.weight           |   589824   |\n",
      "|              decoder.block.2.layer.1.layer_norm.weight               |    768     |\n",
      "|           decoder.block.2.layer.2.DenseReluDense.wi.weight           |  2359296   |\n",
      "|           decoder.block.2.layer.2.DenseReluDense.wo.weight           |  2359296   |\n",
      "|              decoder.block.2.layer.2.layer_norm.weight               |    768     |\n",
      "|            decoder.block.3.layer.0.SelfAttention.q.weight            |   589824   |\n",
      "|            decoder.block.3.layer.0.SelfAttention.k.weight            |   589824   |\n",
      "|            decoder.block.3.layer.0.SelfAttention.v.weight            |   589824   |\n",
      "|            decoder.block.3.layer.0.SelfAttention.o.weight            |   589824   |\n",
      "|              decoder.block.3.layer.0.layer_norm.weight               |    768     |\n",
      "|           decoder.block.3.layer.1.EncDecAttention.q.weight           |   589824   |\n",
      "|           decoder.block.3.layer.1.EncDecAttention.k.weight           |   589824   |\n",
      "|           decoder.block.3.layer.1.EncDecAttention.v.weight           |   589824   |\n",
      "|           decoder.block.3.layer.1.EncDecAttention.o.weight           |   589824   |\n",
      "|              decoder.block.3.layer.1.layer_norm.weight               |    768     |\n",
      "|           decoder.block.3.layer.2.DenseReluDense.wi.weight           |  2359296   |\n",
      "|           decoder.block.3.layer.2.DenseReluDense.wo.weight           |  2359296   |\n",
      "|              decoder.block.3.layer.2.layer_norm.weight               |    768     |\n",
      "|            decoder.block.4.layer.0.SelfAttention.q.weight            |   589824   |\n",
      "|            decoder.block.4.layer.0.SelfAttention.k.weight            |   589824   |\n",
      "|            decoder.block.4.layer.0.SelfAttention.v.weight            |   589824   |\n",
      "|            decoder.block.4.layer.0.SelfAttention.o.weight            |   589824   |\n",
      "|              decoder.block.4.layer.0.layer_norm.weight               |    768     |\n",
      "|           decoder.block.4.layer.1.EncDecAttention.q.weight           |   589824   |\n",
      "|           decoder.block.4.layer.1.EncDecAttention.k.weight           |   589824   |\n",
      "|           decoder.block.4.layer.1.EncDecAttention.v.weight           |   589824   |\n",
      "|           decoder.block.4.layer.1.EncDecAttention.o.weight           |   589824   |\n",
      "|              decoder.block.4.layer.1.layer_norm.weight               |    768     |\n",
      "|           decoder.block.4.layer.2.DenseReluDense.wi.weight           |  2359296   |\n",
      "|           decoder.block.4.layer.2.DenseReluDense.wo.weight           |  2359296   |\n",
      "|              decoder.block.4.layer.2.layer_norm.weight               |    768     |\n",
      "|            decoder.block.5.layer.0.SelfAttention.q.weight            |   589824   |\n",
      "|            decoder.block.5.layer.0.SelfAttention.k.weight            |   589824   |\n",
      "|            decoder.block.5.layer.0.SelfAttention.v.weight            |   589824   |\n",
      "|            decoder.block.5.layer.0.SelfAttention.o.weight            |   589824   |\n",
      "|              decoder.block.5.layer.0.layer_norm.weight               |    768     |\n",
      "|           decoder.block.5.layer.1.EncDecAttention.q.weight           |   589824   |\n",
      "|           decoder.block.5.layer.1.EncDecAttention.k.weight           |   589824   |\n",
      "|           decoder.block.5.layer.1.EncDecAttention.v.weight           |   589824   |\n",
      "|           decoder.block.5.layer.1.EncDecAttention.o.weight           |   589824   |\n",
      "|              decoder.block.5.layer.1.layer_norm.weight               |    768     |\n",
      "|           decoder.block.5.layer.2.DenseReluDense.wi.weight           |  2359296   |\n",
      "|           decoder.block.5.layer.2.DenseReluDense.wo.weight           |  2359296   |\n",
      "|              decoder.block.5.layer.2.layer_norm.weight               |    768     |\n",
      "|            decoder.block.6.layer.0.SelfAttention.q.weight            |   589824   |\n",
      "|            decoder.block.6.layer.0.SelfAttention.k.weight            |   589824   |\n",
      "|            decoder.block.6.layer.0.SelfAttention.v.weight            |   589824   |\n",
      "|            decoder.block.6.layer.0.SelfAttention.o.weight            |   589824   |\n",
      "|              decoder.block.6.layer.0.layer_norm.weight               |    768     |\n",
      "|           decoder.block.6.layer.1.EncDecAttention.q.weight           |   589824   |\n",
      "|           decoder.block.6.layer.1.EncDecAttention.k.weight           |   589824   |\n",
      "|           decoder.block.6.layer.1.EncDecAttention.v.weight           |   589824   |\n",
      "|           decoder.block.6.layer.1.EncDecAttention.o.weight           |   589824   |\n",
      "|              decoder.block.6.layer.1.layer_norm.weight               |    768     |\n",
      "|           decoder.block.6.layer.2.DenseReluDense.wi.weight           |  2359296   |\n",
      "|           decoder.block.6.layer.2.DenseReluDense.wo.weight           |  2359296   |\n",
      "|              decoder.block.6.layer.2.layer_norm.weight               |    768     |\n",
      "|            decoder.block.7.layer.0.SelfAttention.q.weight            |   589824   |\n",
      "|            decoder.block.7.layer.0.SelfAttention.k.weight            |   589824   |\n",
      "|            decoder.block.7.layer.0.SelfAttention.v.weight            |   589824   |\n",
      "|            decoder.block.7.layer.0.SelfAttention.o.weight            |   589824   |\n",
      "|              decoder.block.7.layer.0.layer_norm.weight               |    768     |\n",
      "|           decoder.block.7.layer.1.EncDecAttention.q.weight           |   589824   |\n",
      "|           decoder.block.7.layer.1.EncDecAttention.k.weight           |   589824   |\n",
      "|           decoder.block.7.layer.1.EncDecAttention.v.weight           |   589824   |\n",
      "|           decoder.block.7.layer.1.EncDecAttention.o.weight           |   589824   |\n",
      "|              decoder.block.7.layer.1.layer_norm.weight               |    768     |\n",
      "|           decoder.block.7.layer.2.DenseReluDense.wi.weight           |  2359296   |\n",
      "|           decoder.block.7.layer.2.DenseReluDense.wo.weight           |  2359296   |\n",
      "|              decoder.block.7.layer.2.layer_norm.weight               |    768     |\n",
      "|            decoder.block.8.layer.0.SelfAttention.q.weight            |   589824   |\n",
      "|            decoder.block.8.layer.0.SelfAttention.k.weight            |   589824   |\n",
      "|            decoder.block.8.layer.0.SelfAttention.v.weight            |   589824   |\n",
      "|            decoder.block.8.layer.0.SelfAttention.o.weight            |   589824   |\n",
      "|              decoder.block.8.layer.0.layer_norm.weight               |    768     |\n",
      "|           decoder.block.8.layer.1.EncDecAttention.q.weight           |   589824   |\n",
      "|           decoder.block.8.layer.1.EncDecAttention.k.weight           |   589824   |\n",
      "|           decoder.block.8.layer.1.EncDecAttention.v.weight           |   589824   |\n",
      "|           decoder.block.8.layer.1.EncDecAttention.o.weight           |   589824   |\n",
      "|              decoder.block.8.layer.1.layer_norm.weight               |    768     |\n",
      "|           decoder.block.8.layer.2.DenseReluDense.wi.weight           |  2359296   |\n",
      "|           decoder.block.8.layer.2.DenseReluDense.wo.weight           |  2359296   |\n",
      "|              decoder.block.8.layer.2.layer_norm.weight               |    768     |\n",
      "|            decoder.block.9.layer.0.SelfAttention.q.weight            |   589824   |\n",
      "|            decoder.block.9.layer.0.SelfAttention.k.weight            |   589824   |\n",
      "|            decoder.block.9.layer.0.SelfAttention.v.weight            |   589824   |\n",
      "|            decoder.block.9.layer.0.SelfAttention.o.weight            |   589824   |\n",
      "|              decoder.block.9.layer.0.layer_norm.weight               |    768     |\n",
      "|           decoder.block.9.layer.1.EncDecAttention.q.weight           |   589824   |\n",
      "|           decoder.block.9.layer.1.EncDecAttention.k.weight           |   589824   |\n",
      "|           decoder.block.9.layer.1.EncDecAttention.v.weight           |   589824   |\n",
      "|           decoder.block.9.layer.1.EncDecAttention.o.weight           |   589824   |\n",
      "|              decoder.block.9.layer.1.layer_norm.weight               |    768     |\n",
      "|           decoder.block.9.layer.2.DenseReluDense.wi.weight           |  2359296   |\n",
      "|           decoder.block.9.layer.2.DenseReluDense.wo.weight           |  2359296   |\n",
      "|              decoder.block.9.layer.2.layer_norm.weight               |    768     |\n",
      "|           decoder.block.10.layer.0.SelfAttention.q.weight            |   589824   |\n",
      "|           decoder.block.10.layer.0.SelfAttention.k.weight            |   589824   |\n",
      "|           decoder.block.10.layer.0.SelfAttention.v.weight            |   589824   |\n",
      "|           decoder.block.10.layer.0.SelfAttention.o.weight            |   589824   |\n",
      "|              decoder.block.10.layer.0.layer_norm.weight              |    768     |\n",
      "|          decoder.block.10.layer.1.EncDecAttention.q.weight           |   589824   |\n",
      "|          decoder.block.10.layer.1.EncDecAttention.k.weight           |   589824   |\n",
      "|          decoder.block.10.layer.1.EncDecAttention.v.weight           |   589824   |\n",
      "|          decoder.block.10.layer.1.EncDecAttention.o.weight           |   589824   |\n",
      "|              decoder.block.10.layer.1.layer_norm.weight              |    768     |\n",
      "|          decoder.block.10.layer.2.DenseReluDense.wi.weight           |  2359296   |\n",
      "|          decoder.block.10.layer.2.DenseReluDense.wo.weight           |  2359296   |\n",
      "|              decoder.block.10.layer.2.layer_norm.weight              |    768     |\n",
      "|           decoder.block.11.layer.0.SelfAttention.q.weight            |   589824   |\n",
      "|           decoder.block.11.layer.0.SelfAttention.k.weight            |   589824   |\n",
      "|           decoder.block.11.layer.0.SelfAttention.v.weight            |   589824   |\n",
      "|           decoder.block.11.layer.0.SelfAttention.o.weight            |   589824   |\n",
      "|              decoder.block.11.layer.0.layer_norm.weight              |    768     |\n",
      "|          decoder.block.11.layer.1.EncDecAttention.q.weight           |   589824   |\n",
      "|          decoder.block.11.layer.1.EncDecAttention.k.weight           |   589824   |\n",
      "|          decoder.block.11.layer.1.EncDecAttention.v.weight           |   589824   |\n",
      "|          decoder.block.11.layer.1.EncDecAttention.o.weight           |   589824   |\n",
      "|              decoder.block.11.layer.1.layer_norm.weight              |    768     |\n",
      "|          decoder.block.11.layer.2.DenseReluDense.wi.weight           |  2359296   |\n",
      "|          decoder.block.11.layer.2.DenseReluDense.wo.weight           |  2359296   |\n",
      "|              decoder.block.11.layer.2.layer_norm.weight              |    768     |\n",
      "|                   decoder.final_layer_norm.weight                    |    768     |\n",
      "+----------------------------------------------------------------------+------------+\n",
      "Total Trainable Params: 349744128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "349744128"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: continue\n",
    "        param = parameter.numel()\n",
    "        table.add_row([name, param])\n",
    "        total_params+=param\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params\n",
    "\n",
    "count_parameters(trained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6e20830-2f49-4050-b1cd-67ebdb5a4534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size: 1334.168MB\n"
     ]
    }
   ],
   "source": [
    "param_size = 0\n",
    "for param in trained_model.parameters():\n",
    "    param_size += param.nelement() * param.element_size()\n",
    "buffer_size = 0\n",
    "for buffer in trained_model.buffers():\n",
    "    buffer_size += buffer.nelement() * buffer.element_size()\n",
    "\n",
    "size_all_mb = (param_size + buffer_size) / 1024**2\n",
    "print('model size: {:.3f}MB'.format(size_all_mb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9669013c-f34f-44b1-a35c-f265f106a427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_grammar(input_text,num_return_sequences):\n",
    "    #batch = tokenizer([input_text],truncation=True,padding='max_length',max_length=64, return_tensors=\"pt\").to(torch_device)\n",
    "    batch = tokenizer([input_text],truncation=True,padding='max_length',max_length=64, return_tensors=\"pt\",return_token_type_ids=False).to(device)\n",
    "    #print(batch)\n",
    "    #translated = model1.generate(**batch,max_length=64,num_beams=4, num_return_sequences=num_return_sequences, temperature=1.5)\n",
    "    translated= trained_model.generate(**batch,max_length=64,num_beams=4, num_return_sequences=num_return_sequences, temperature=1.5)\n",
    "    #print(\"here\")\n",
    "    tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "    return tgt_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b786ccc2-8dea-4c4d-b60c-c242ef187a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(T5ForConditionalGeneration.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2dc10f7d-909a-4d2b-917a-475e43619610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Sentence: अँगरेज़ी सहभाषा के रूप में व्यवहत्त होनी चाहिए थी परंतु आज भी उसकी वर्चस्व सर्वत्र स्थापित है ।\n",
      "Correct Seentence: अँगरेज़ी सहभाषा के रूप में व्यवहत्त होनी चाहिए थी परंतु आज भी उसका वर्चस्व सर्वत्र स्थापित है । \n",
      "Predicted Sentence: अँगरेज़ी सहभाषा के रूप में व्यवहारत होनी चाहिए थी परंतु आज भी उसकी वर्चस्व सर्वत्र स्थापित है ।\n"
     ]
    }
   ],
   "source": [
    "text = test_df['input'].iat[0]\n",
    "correct = test_df['output'].iat[0]\n",
    "print(\"Incorrect Sentence:\", text)\n",
    "print(\"Correct Seentence:\",correct)\n",
    "l = len(correct)\n",
    "predicted_s = correct_grammar(text, num_return_sequences=4)[0]\n",
    "print(\"Predicted Sentence:\",predicted_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "33497c92-ccc5-4eba-89d9-004161a5e100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Sentence: प्रत्येक शिक्षक जानता हैं कि उसके मासिक वेतन का कुछ अंश घूस में जा रहा हैं ।\n",
      "Correct Seentence: प्रत्येक शिक्षक जानता है कि उसके मासिक वेतन का कुछ अंश घूस में जा रहा है । \n",
      "Predicted Sentence: प्रत्येक शिक्षक जानता है कि उसके मासिक वेतन का कुछ अंश घूस में जा रहा है ।\n"
     ]
    }
   ],
   "source": [
    "text = test_df['input'].iat[13]\n",
    "correct = test_df['output'].iat[13]\n",
    "print(\"Incorrect Sentence:\", text)\n",
    "print(\"Correct Seentence:\",correct)\n",
    "l = len(correct)\n",
    "predicted_s = correct_grammar(text, num_return_sequences=2)[0]\n",
    "p = len(predicted_s)\n",
    "'''\n",
    "if(p>l):\n",
    "    predicted_s = predicted_s[:l]\n",
    "elif (p<l-4):\n",
    "    predicted_s = text\n",
    "'''\n",
    "\n",
    "print(\"Predicted Sentence:\",predicted_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3f8b0823-1f45-41f2-a239-c4b724f58309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Sentence: इस सबमें अहम बात मुस्लिम मतदाताओं का रुझान हैं ।\n",
      "Correct Seentence: इस सबमें अहम बात मुस्लिम मतदाताओं का रुझान है । \n",
      "Predicted Sentence: इस सबमें अहम बात मुस्लिम मतदाताओं का रुझान है ।\n"
     ]
    }
   ],
   "source": [
    "text = test_df['input'].iat[43]\n",
    "correct = test_df['output'].iat[43]\n",
    "print(\"Incorrect Sentence:\", text)\n",
    "print(\"Correct Seentence:\",correct)\n",
    "l = len(correct)\n",
    "predicted_s = correct_grammar(text, num_return_sequences=2)[0]\n",
    "if(p>l):\n",
    "    predicted_s = predicted_s[:l]\n",
    "\n",
    "print(\"Predicted Sentence:\",predicted_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "79771c80-b79f-4ac2-8086-4eb0a0d82051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Sentence: तथे गौशाला का\n",
      "Correct Seentence: तथा गौशाला का\n",
      "Predicted Sentence: तथा गौशाला का\n"
     ]
    }
   ],
   "source": [
    "text = test_df['input'].iat[1]\n",
    "correct = test_df['output'].iat[1]\n",
    "print(\"Incorrect Sentence:\", text)\n",
    "print(\"Correct Seentence:\",correct)\n",
    "l = len(correct)\n",
    "predicted_s = correct_grammar(text, num_return_sequences=4)[0][:l]\n",
    "print(\"Predicted Sentence:\",predicted_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ed1ae34f-0274-43ec-afed-f0ce7e723612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Sentence: अँगरेज़ी सहभाषा के रूप में व्यवहत्त होनी चाहिए थी परंतु आज भी उसकी वर्चस्व सर्वत्र स्थापित है ।\n",
      "Correct Seentence: अँगरेज़ी सहभाषा के रूप में व्यवहत्त होनी चाहिए थी परंतु आज भी उसका वर्चस्व सर्वत्र स्थापित है । \n",
      "Predicted Sentence: अँगरेज़ी सहभाषा के रूप में व्यवहारत होनी चाहिए थी परंतु आज भी उसकी वर्चस्व सर्वत्र स्थापित है ।\n"
     ]
    }
   ],
   "source": [
    "text = test_df['input'].iat[0]\n",
    "correct = test_df['output'].iat[0]\n",
    "print(\"Incorrect Sentence:\", text)\n",
    "print(\"Correct Seentence:\",correct)\n",
    "l = len(correct)\n",
    "predicted_s = correct_grammar(text, num_return_sequences=2)[0]\n",
    "p = len(predicted_s)\n",
    "if(p>l):\n",
    "    predicted_s = predicted_s[:l]\n",
    "\n",
    "print(\"Predicted Sentence:\",predicted_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a3c96d0d-6d65-42bc-8faa-30a3b931c57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Sentence: राष्ट्रीय जनता दल हरियाणा आज महिला आरक्षण विधेयक के विरोध में प्रदेश सचिव विजय सिंह कारगवाल के तृत्व में अंबेडकर पार्क के समीप जोदार प्रदर्शन किया तथा कांग्रेस अध्यक्षा सोनिया गांधी व भाजपा की वरिष्ठ त्री सुषमा स्वराज का पुतला फूंका ।\n",
      "Correct Seentence: राष्ट्रीय जनता दल हरियाणा ने आज महिला आरक्षण विधेयक के विरोध में प्रदेश सचिव विजय सिंह कारगवाल के नेतृत्व में अंबेडकर पार्क के समीप जोदार प्रदर्शन किया तथा कांग्रेस अध्यक्षा सोनिया गांधी व भाजपा की वरिष्ठ नेत्री सुषमा स्वराज का पुतला फूंका । \n",
      "Predicted Sentence: राष्ट्रीय जनता दल हरियाणा आज महिला आरक्षण विधेयक के विरोध में प्रदेश सचिव विजय सिंह ने कारगवाल के नेतृत्व में अंबेडकर पार्क के समीप जोदार प्रदर्शन किया तथा कांग्रेस अध्यक्षा सोनिया गांधी व भाजपा की वरिष्ठ त्री सुषमा स्वराज का पुतला फूंका ।\n"
     ]
    }
   ],
   "source": [
    "text = test_df['input'].iat[50]\n",
    "correct = test_df['output'].iat[50]\n",
    "print(\"Incorrect Sentence:\", text)\n",
    "print(\"Correct Seentence:\",correct)\n",
    "predicted_s = correct_grammar(text, num_return_sequences=1)[0]\n",
    "l = len(correct)\n",
    "p = len(predicted_s)\n",
    "if(p>l):\n",
    "    predicted_s = predicted_s[:l]\n",
    "\n",
    "print(\"Predicted Sentence:\",predicted_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9f05b016-c983-4167-a2f7-c5f1736de779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Sentence: ज़ाहिर है जब मैंने लिखूंगा तो वो मेरे ही व्यक्तिगत विचार कहलायेंगे किसी संस्थान के नहीं ।\n",
      "Correct Seentence: ज़ाहिर है जब मैं लिखूंगा तो वो मेरे ही व्यक्तिगत विचार कहलायेंगे किसी संस्थान के नहीं । \n",
      "Predicted Sentence: ज़ाहिर है जब मैं लिखूंगा तो वो मेरे ही व्यक्तिगत विचार कहलायेंगे किसी संस्थान के नहीं ।\n"
     ]
    }
   ],
   "source": [
    "text = test_df['input'].iat[60]\n",
    "correct = test_df['output'].iat[60]\n",
    "print(\"Incorrect Sentence:\", text)\n",
    "print(\"Correct Seentence:\",correct)\n",
    "predicted_s = correct_grammar(text, num_return_sequences=1)[0]\n",
    "l = len(correct)\n",
    "p = len(predicted_s)\n",
    "if(p>l):\n",
    "    predicted_s = predicted_s[:l]\n",
    "print(\"Predicted Sentence:\",predicted_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7cf190-899c-4fc6-9954-59ba79ef6614",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d488748e-8345-4b94-baf3-84925a29ba2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Sentence: गनीमत हैं गणेशशंकर विद्यार्थी ने २०० रुपये का मनीआर्डर भेजकर अशफ़ाक़ की मजार पर छत डलवा कर उसे धूप के साये से बचा लिया ।\n",
      "Correct Seentence: गनीमत है गणेशशंकर विद्यार्थी ने २०० रुपये का मनीआर्डर भेजकर अशफ़ाक़ की मजार पर छत डलवा कर उसे धूप के साये से बचा लिया । \n",
      "Predicted Sentence: गनीमत है गणेशशंकर विद्यार्थी ने २०० रुपये का मनीआर्डर भेजकर अशफ़ाक़ की मजार पर छत डलवा कर उसे धूप के साये से बचा लिया ।\n"
     ]
    }
   ],
   "source": [
    "text = test_df['input'].iat[51]\n",
    "correct = test_df['output'].iat[51]\n",
    "print(\"Incorrect Sentence:\", text)\n",
    "print(\"Correct Seentence:\",correct)\n",
    "predicted_s = correct_grammar(text, num_return_sequences=1)[0]\n",
    "print(\"Predicted Sentence:\",predicted_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a2adc94a-4fc3-4eb6-b336-574d99c230eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Sentence: हम पास खींच लेते हैंं ।\n",
      "Correct Seentence: हम पास खींच लेते हैं । \n",
      "Predicted Sentence: हम पास खींच लेते हैं । \n"
     ]
    }
   ],
   "source": [
    "text = test_df['input'].iat[20]\n",
    "correct = test_df['output'].iat[20]\n",
    "print(\"Incorrect Sentence:\", text)\n",
    "print(\"Correct Seentence:\",correct)\n",
    "predicted_s = correct_grammar(text, num_return_sequences=1)[0]\n",
    "p=len(predicted_s)\n",
    "l = len(text)\n",
    "if(p>l):\n",
    "    predicted_s = predicted_s[:l]\n",
    "print(\"Predicted Sentence:\",predicted_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b37d9f-25df-483f-a3c3-29603e854408",
   "metadata": {},
   "source": [
    "# Performance Analysis\n",
    "1. BLEU Score\n",
    "2. GLEU Score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "18317b87-03d3-4d73-ae22-9cf8cb8e1db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14000, 3)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "da058ef4-524c-4808-a1ba-bbd143f534d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>input_token_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40665</th>\n",
       "      <td>अँगरेज़ी सहभाषा के रूप में व्यवहत्त होनी चाहिए थी परंतु आज भी उसकी वर्चस्व सर्वत्र स्थापित है ।</td>\n",
       "      <td>अँगरेज़ी सहभाषा के रूप में व्यवहत्त होनी चाहिए थी परंतु आज भी उसका वर्चस्व सर्वत्र स्थापित है ।</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48520</th>\n",
       "      <td>तथे गौशाला का</td>\n",
       "      <td>तथा गौशाला का</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138403</th>\n",
       "      <td>बच्चे खेल रहे है किलकारियाँ गूंज रही है ब्रह्माण्ड में</td>\n",
       "      <td>बच्चे खेल रहे हैं किलकारियाँ गूंज रही हैं ब्रह्माण्ड में</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130079</th>\n",
       "      <td>धरने पर किसानो ने कहा कि अब समय आ गया हैं कि गन्ने की खेती किसानो के लिये नुकसान का सौदा हो गयी हैं ।</td>\n",
       "      <td>धरने पर किसानो ने कहा कि अब समय आ गया है कि गन्ने की खेती किसानो के लिये नुकसान का सौदा हो गयी है ।</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50146</th>\n",
       "      <td>सड़क मलबे का ढेर होने से दुपहिया व चार पहिया वाहन चालकों को परेशान होना पड़ रहा हैं ।</td>\n",
       "      <td>सड़क मलबे का ढेर होने से दुपहिया व चार पहिया वाहन चालकों को परेशान होना पड़ रहा है ।</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                        input  \\\n",
       "40665         अँगरेज़ी सहभाषा के रूप में व्यवहत्त होनी चाहिए थी परंतु आज भी उसकी वर्चस्व सर्वत्र स्थापित है ।   \n",
       "48520                                                                                           तथे गौशाला का   \n",
       "138403                                                 बच्चे खेल रहे है किलकारियाँ गूंज रही है ब्रह्माण्ड में   \n",
       "130079  धरने पर किसानो ने कहा कि अब समय आ गया हैं कि गन्ने की खेती किसानो के लिये नुकसान का सौदा हो गयी हैं ।   \n",
       "50146                   सड़क मलबे का ढेर होने से दुपहिया व चार पहिया वाहन चालकों को परेशान होना पड़ रहा हैं ।   \n",
       "\n",
       "                                                                                                      output  \\\n",
       "40665       अँगरेज़ी सहभाषा के रूप में व्यवहत्त होनी चाहिए थी परंतु आज भी उसका वर्चस्व सर्वत्र स्थापित है ।    \n",
       "48520                                                                                          तथा गौशाला का   \n",
       "138403                                              बच्चे खेल रहे हैं किलकारियाँ गूंज रही हैं ब्रह्माण्ड में   \n",
       "130079  धरने पर किसानो ने कहा कि अब समय आ गया है कि गन्ने की खेती किसानो के लिये नुकसान का सौदा हो गयी है ।    \n",
       "50146                  सड़क मलबे का ढेर होने से दुपहिया व चार पहिया वाहन चालकों को परेशान होना पड़ रहा है ।    \n",
       "\n",
       "        input_token_len  \n",
       "40665                28  \n",
       "48520                 6  \n",
       "138403               14  \n",
       "130079               29  \n",
       "50146                23  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c922895e-82d6-43db-a2c8-113bacd42372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_test = pd.read_csv('DATA/etoori_test.csv')\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab40e4eb-00a5-429e-a837-ed75ea61cc2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enc_input</th>\n",
       "      <th>dec_input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>इसके अलावा माइकल शूमाकर द्वारा चलाई गई एक फरार...</td>\n",
       "      <td>इसके अलावा माइकल शूमाकर द्वारा चलाई गई एक फरार...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>यह मन को काबू में करने वाली मुद्रा हैं इसीलिए ...</td>\n",
       "      <td>यह मन को काबू में करने वाली मुद्रा है इसीलिए इ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>आप पुस्तक पढ़ने में तल्लीन हैं और बच्चा उसनेाँ...</td>\n",
       "      <td>आप पुस्तक पढ़ने में तल्लीन हैं और बच्चा वहाँ प...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>परिवार के मुताबिक धमाकों में हिस्सा लेने वाले ...</td>\n",
       "      <td>परिवार के मुताबिक धमाकों में हिस्सा लेने वाले ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>उनकी वो वाली बात भी अनिश्चित रहती हैं ।</td>\n",
       "      <td>उनकी वो वाली बात भी अनिश्चित रहती है ।</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           enc_input  \\\n",
       "0  इसके अलावा माइकल शूमाकर द्वारा चलाई गई एक फरार...   \n",
       "1  यह मन को काबू में करने वाली मुद्रा हैं इसीलिए ...   \n",
       "2  आप पुस्तक पढ़ने में तल्लीन हैं और बच्चा उसनेाँ...   \n",
       "3  परिवार के मुताबिक धमाकों में हिस्सा लेने वाले ...   \n",
       "4            उनकी वो वाली बात भी अनिश्चित रहती हैं ।   \n",
       "\n",
       "                                           dec_input  \n",
       "0  इसके अलावा माइकल शूमाकर द्वारा चलाई गई एक फरार...  \n",
       "1  यह मन को काबू में करने वाली मुद्रा है इसीलिए इ...  \n",
       "2  आप पुस्तक पढ़ने में तल्लीन हैं और बच्चा वहाँ प...  \n",
       "3  परिवार के मुताबिक धमाकों में हिस्सा लेने वाले ...  \n",
       "4            उनकी वो वाली बात भी अनिश्चित रहती है ।   "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9216427e-77e4-4d58-a4c1-0fd582745e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Sentence: इसके अलावा माइकल शूमाकर द्वारा चलाई गई एक फरारी कार भी को मिलियन डॉलर क्लब में माना जा रहा है ।\n",
      "Correct Seentence: इसके अलावा माइकल शूमाकर द्वारा चलाई गई एक फरारी कार को भी मिलियन डॉलर क्लब में माना जा रहा है । \n",
      "Predicted Sentence: इसके अलावा माइकल शूमाकर द्वारा चलाई गई एक फरारी कार को भी मिलियन डॉलर क्लब में माना जा रहा है ।\n"
     ]
    }
   ],
   "source": [
    "text = df_test['enc_input'].iat[0]\n",
    "correct = df_test['dec_input'].iat[0]\n",
    "print(\"Incorrect Sentence:\", text)\n",
    "print(\"Correct Seentence:\",correct)\n",
    "predicted_s = correct_grammar(text, num_return_sequences=1)[0]\n",
    "l = len(correct)\n",
    "p = len(predicted_s)\n",
    "if(p>l):\n",
    "    predicted_s = predicted_s[:l]\n",
    "\n",
    "print(\"Predicted Sentence:\",predicted_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7fa5d601-9ba5-4961-8b1c-cb658cbcfdd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.26 s, sys: 84.4 ms, total: 1.34 s\n",
      "Wall time: 1.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predicted_s = correct_grammar(text, num_return_sequences=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d972ce-dab2-46ac-9de8-f0ffcfb53f85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ba007951-7c5e-4d99-8ca6-e9a4aa81d026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Sentence: यह मन को काबू में करने वाली मुद्रा हैं इसीलिए इसे चित्त हस्त मुद्रा योग कहते हैंं ।\n",
      "Correct Seentence: यह मन को काबू में करने वाली मुद्रा है इसीलिए इसे चित्त हस्त मुद्रा योग कहते हैं । \n",
      "Predicted Sentence: यह मन को काबू में करने वाली मुद्रा है इसीलिए इसे चित्त हस्त मुद्रा योग कहते हैं ।\n"
     ]
    }
   ],
   "source": [
    "text = df_test['enc_input'].iat[1]\n",
    "correct = df_test['dec_input'].iat[1]\n",
    "print(\"Incorrect Sentence:\", text)\n",
    "print(\"Correct Seentence:\",correct)\n",
    "predicted_s = correct_grammar(text, num_return_sequences=1)[0]\n",
    "l = len(correct)\n",
    "p = len(predicted_s)\n",
    "if(p>l):\n",
    "    predicted_s = predicted_s[:l]\n",
    "print(\"Predicted Sentence:\",predicted_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0b3169-ccf8-4ce1-adf8-4dd112c41f20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9c0c0e87-c89e-4143-bacf-d6fe15b9cca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Sentence: आप पुस्तक पढ़ने में तल्लीन हैं और बच्चा उसनेाँ पर शोर मचा रहा है ।\n",
      "Correct Seentence: आप पुस्तक पढ़ने में तल्लीन हैं और बच्चा वहाँ पर शोर मचा रहा है । \n",
      "Predicted Sentence: आप पुस्तक पढ़ने में तल्लीन हैं और बच्चा वहाँ पर शोर मचा रहा है ।\n"
     ]
    }
   ],
   "source": [
    "text = df_test['enc_input'].iat[2]\n",
    "correct = df_test['dec_input'].iat[2]\n",
    "print(\"Incorrect Sentence:\", text)\n",
    "print(\"Correct Seentence:\",correct)\n",
    "predicted_s = correct_grammar(text, num_return_sequences=1)[0]\n",
    "l = len(correct)\n",
    "p = len(predicted_s)\n",
    "if(p>l):\n",
    "    predicted_s = predicted_s[:l]\n",
    "print(\"Predicted Sentence:\",predicted_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6f233a47-440e-49b7-ba4f-b952be54da5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Sentence: परिवार के मुताबिक धमाकों में हिस्सा लेने वाले कोई दूसरे लोग थे और ये गलत पहचान का मामला हैं ।\n",
      "Correct Seentence: परिवार के मुताबिक धमाकों में हिस्सा लेने वाले कोई दूसरे लोग थे और ये गलत पहचान का मामला है । \n",
      "Predicted Sentence: परिवार के मुताबिक धमाकों में हिस्सा लेने वाले कोई दूसरे लोग थे और ये गलत पहचान का मामला है ।\n"
     ]
    }
   ],
   "source": [
    "text = df_test['enc_input'].iat[3]\n",
    "correct = df_test['dec_input'].iat[3]\n",
    "print(\"Incorrect Sentence:\", text)\n",
    "print(\"Correct Seentence:\",correct)\n",
    "predicted_s = correct_grammar(text, num_return_sequences=1)[0]\n",
    "l = len(correct)\n",
    "p = len(predicted_s)\n",
    "if(p>l):\n",
    "    predicted_s = predicted_s[:l]\n",
    "print(\"Predicted Sentence:\",predicted_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7ff4d00c-6d49-4e6e-b4f9-a765967fa1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Sentence: उनकी वो वाली बात भी अनिश्चित रहती हैं ।\n",
      "Correct Seentence: उनकी वो वाली बात भी अनिश्चित रहती है । \n",
      "Predicted Sentence: उनकी वो वाली बात भी अनिश्चित रहती है ।\n"
     ]
    }
   ],
   "source": [
    "text = df_test['enc_input'].iat[4]\n",
    "correct = df_test['dec_input'].iat[4]\n",
    "print(\"Incorrect Sentence:\", text)\n",
    "print(\"Correct Seentence:\",correct)\n",
    "predicted_s = correct_grammar(text, num_return_sequences=1)[0]\n",
    "l = len(correct)\n",
    "p = len(predicted_s)\n",
    "if(p>l):\n",
    "    predicted_s = predicted_s[:l]\n",
    "print(\"Predicted Sentence:\",predicted_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0ad90991-9465-4991-9562-bd6e88cfe5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Sentence: मैंने ललित हूँ ।\n",
      "Correct Seentence: मैं ललित हूँ । \n",
      "Predicted Sentence: मैं ललित हूँ । \n"
     ]
    }
   ],
   "source": [
    "text = df_test['enc_input'].iat[9]\n",
    "correct = df_test['dec_input'].iat[9]\n",
    "print(\"Incorrect Sentence:\", text)\n",
    "print(\"Correct Seentence:\",correct)\n",
    "predicted_s = correct_grammar(text, num_return_sequences=1)[0]\n",
    "l = len(correct)\n",
    "p = len(predicted_s)\n",
    "if(p>l):\n",
    "    predicted_s = predicted_s[:l]\n",
    "print(\"Predicted Sentence:\",predicted_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f63ceef-8b22-4af4-85b7-3b8ea69b275b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ffee1d-4065-4509-98cf-069cb233593b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf1c130-a68b-4bf1-86d9-d677f8ed9e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.translate.bleu_score as bleu\n",
    "BLEU = []\n",
    "index = []\n",
    "test_data = df_test.head(10000)\n",
    "np.random.seed(1)\n",
    "for ind,i in tqdm(test_data.iterrows(),position=0):\n",
    "    try:\n",
    "        text = str(i.enc_input)\n",
    "        #pred = predict(str(i.enc_input),model)[0].split()\n",
    "        pred = correct_grammar(text, num_return_sequences=1)[0]\n",
    "        act = [str(i.dec_input).split()]\n",
    "        pred_s = str(pred).split()\n",
    "        #print(act)\n",
    "        #print(pred_s)\n",
    "        b = bleu.sentence_bleu(act,pred_s)\n",
    "        BLEU.append(b)\n",
    "    except:\n",
    "        index.append(ind)\n",
    "        continue\n",
    "print(\"BELU = \", np.mean(BLEU))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f19ddaa2-1873-4cab-9974-353a53fdc8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:13,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score =  0.8984656084656084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.gleu_score import sentence_gleu\n",
    "GLEU_val_emb = []\n",
    "test_data = df_test.head(10)\n",
    "print(test_data.shape)\n",
    "for ind,i in tqdm(test_data.iterrows(),position=0):\n",
    "    try:\n",
    "        text = str(i.enc_input)\n",
    "        #pred = predict(str(i.enc_input),model)[0].split()\n",
    "        pred = correct_grammar(text, num_return_sequences=1)[0]\n",
    "        l = len(text)\n",
    "        p = len(pred)\n",
    "        if(p>l):\n",
    "            pred = pred[:l]\n",
    "            \n",
    "        act = [str(i.dec_input).split()]\n",
    "        pred_s = str(pred).split()\n",
    "    \n",
    "        #print(act)\n",
    "        #print(pred_s)\n",
    "        b = sentence_gleu(act,pred_s)\n",
    "        #print(b)\n",
    "        GLEU_val_emb.append(b)\n",
    "    except:\n",
    "        continue\n",
    "print(\"GELU Score = \",np.mean(GLEU_val_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cb825de7-9bcd-4d6e-8ba4-433f7ac00ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  1  data point 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [21:58,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  1001  data point 0.9150283140478553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2001it [42:44,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  2001  data point 0.9204379715628371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3001it [1:01:56,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  3001  data point 0.9182989341695741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4001it [1:20:27,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  4001  data point 0.9186494493296361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5001it [1:38:55,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  5001  data point 0.91909503414758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6001it [1:57:23,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  6001  data point 0.918329036146066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7001it [2:16:38,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  7001  data point 0.9192907337567936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8001it [2:35:05,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  8001  data point 0.9201028812376454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9001it [2:53:42,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score for  9001  data point 0.9205000001846352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [3:12:33,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score =  0.9208625332430048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.gleu_score import sentence_gleu\n",
    "GLEU_val_emb = []\n",
    "test_data = df_test.head(10000)\n",
    "print(test_data.shape)\n",
    "for ind,i in tqdm(test_data.iterrows(),position=0):\n",
    "    try:\n",
    "        text = str(i.enc_input)\n",
    "        #pred = predict(str(i.enc_input),model)[0].split()\n",
    "        pred = correct_grammar(text, num_return_sequences=1)[0]\n",
    "        l = len(text)\n",
    "        p = len(pred)\n",
    "        if(p>l):\n",
    "            pred = pred[:l]\n",
    "            \n",
    "        act = [str(i.dec_input).split()]\n",
    "        pred_s = str(pred).split()\n",
    "        b = sentence_gleu(act,pred_s)\n",
    "        GLEU_val_emb.append(b)\n",
    "        if(ind%1000 ==0):\n",
    "            print(\"GELU Score for \",ind+1,\" data point\",np.mean(GLEU_val_emb))\n",
    "    except:\n",
    "        continue\n",
    "print(\"GELU Score = \",np.mean(GLEU_val_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8f776a52-2f84-4b17-a268-62f049e9cc11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GELU Score =  0.9208625332430048\n"
     ]
    }
   ],
   "source": [
    "print(\"GELU Score = \",np.mean(GLEU_val_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "17fdf583-24db-48c5-b68e-32a44294e3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [3:10:43,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F0.5 Score =  0.9521005068789202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "FScore_val_emb = []\n",
    "test_data = df_test.head(10000)\n",
    "print(test_data.shape)\n",
    "\n",
    "for ind,i in tqdm(test_data.iterrows(),position=0):\n",
    "    try:\n",
    "        #pred = predict(str(i.enc_input),model)[0].split()\n",
    "        #act = [str(i.dec_output).split()]\n",
    "        \n",
    "        act = str(i.dec_input)\n",
    "        #pred = predict(str(i.enc_input),model)[0]\n",
    "        text = str(i.enc_input)\n",
    "        pred = correct_grammar(text, num_return_sequences=1)[0]\n",
    "        \n",
    "        #b =sentence_gleu(act,pred)\n",
    "        recall,precision,f_beta = rouge_n(act,pred)\n",
    "        #print(recall,precision,f_beta)\n",
    "        \n",
    "        #print(\"BELU Score\",b)\n",
    "        FScore_val_emb.append(f_beta)\n",
    "    except:\n",
    "        continue\n",
    "print(\"F0.5 Score = \",np.mean(FScore_val_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1cbfaf65-fdef-498a-be31-5a7ae7ccdbf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F0.5 Score =  0.9521005068789202\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(\"F0.5 Score = \",np.mean(FScore_val_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970fa4e2-367c-4cd2-ba3d-83042f2ce2a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3252f34-628a-4e12-9569-b81228062c6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
