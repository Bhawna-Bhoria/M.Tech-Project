{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "359c36e6-9058-4580-8c08-afdcc6e7166d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ENCODER DECODER MODEL FOR WORD LEVEL EMBEDDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41168d79-e491-4903-99aa-2816ceb9b9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOADING THE REQUIRED LIBRARIES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm import tqdm \n",
    "import tensorflow as tf\n",
    "from  tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from  sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c65967b5-534d-45ed-9333-bed5684fa811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enc_input</th>\n",
       "      <th>dec_input</th>\n",
       "      <th>dec_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>and he took in my favorite subject like soccer</td>\n",
       "      <td>and he took in my favorite subjects like soccer</td>\n",
       "      <td>and he took in my favorite subjects like soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>actually who let me know about lang  8 was him</td>\n",
       "      <td>actually he was the one who let me know about ...</td>\n",
       "      <td>actually he was the one who let me know about ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>his kanji is ability is much better than me</td>\n",
       "      <td>his kanji ability is much better than mine</td>\n",
       "      <td>his kanji ability is much better than mine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>we have known each other for only half a year ...</td>\n",
       "      <td>we have known each other for only half a year ...</td>\n",
       "      <td>we have known each other for only half a year ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i heard a sentence last night when i watched tv</td>\n",
       "      <td>i heard a sentence last night when i was watch...</td>\n",
       "      <td>i heard a sentence last night when i was watch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503896</th>\n",
       "      <td>i like thailand language because that pronounc...</td>\n",
       "      <td>i like thai because the pronunciation sounds cute</td>\n",
       "      <td>i like thai because the pronunciation sounds cute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503897</th>\n",
       "      <td>i ate kaomangai  rise with boild chikin  tomya...</td>\n",
       "      <td>i ate kaomangai  rice with boiled chickin  tom...</td>\n",
       "      <td>i ate kaomangai  rice with boiled chickin  tom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503898</th>\n",
       "      <td>i think it is important thing to become to lik...</td>\n",
       "      <td>i think it is important to like coriander in o...</td>\n",
       "      <td>i think it is important to like coriander in o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503899</th>\n",
       "      <td>yesterday i went to umeda station to date</td>\n",
       "      <td>i went to umeda station for dating yesterday</td>\n",
       "      <td>i went to umeda station for dating yesterday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503900</th>\n",
       "      <td>it said she want to make the meeting time at e...</td>\n",
       "      <td>she said she want to change the meeting time t...</td>\n",
       "      <td>she said she want to change the meeting time t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>503901 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                enc_input  \\\n",
       "0          and he took in my favorite subject like soccer   \n",
       "1          actually who let me know about lang  8 was him   \n",
       "2             his kanji is ability is much better than me   \n",
       "3       we have known each other for only half a year ...   \n",
       "4         i heard a sentence last night when i watched tv   \n",
       "...                                                   ...   \n",
       "503896  i like thailand language because that pronounc...   \n",
       "503897  i ate kaomangai  rise with boild chikin  tomya...   \n",
       "503898  i think it is important thing to become to lik...   \n",
       "503899          yesterday i went to umeda station to date   \n",
       "503900  it said she want to make the meeting time at e...   \n",
       "\n",
       "                                                dec_input  \\\n",
       "0         and he took in my favorite subjects like soccer   \n",
       "1       actually he was the one who let me know about ...   \n",
       "2              his kanji ability is much better than mine   \n",
       "3       we have known each other for only half a year ...   \n",
       "4       i heard a sentence last night when i was watch...   \n",
       "...                                                   ...   \n",
       "503896  i like thai because the pronunciation sounds cute   \n",
       "503897  i ate kaomangai  rice with boiled chickin  tom...   \n",
       "503898  i think it is important to like coriander in o...   \n",
       "503899       i went to umeda station for dating yesterday   \n",
       "503900  she said she want to change the meeting time t...   \n",
       "\n",
       "                                               dec_output  \n",
       "0         and he took in my favorite subjects like soccer  \n",
       "1       actually he was the one who let me know about ...  \n",
       "2              his kanji ability is much better than mine  \n",
       "3       we have known each other for only half a year ...  \n",
       "4       i heard a sentence last night when i was watch...  \n",
       "...                                                   ...  \n",
       "503896  i like thai because the pronunciation sounds cute  \n",
       "503897  i ate kaomangai  rice with boiled chickin  tom...  \n",
       "503898  i think it is important to like coriander in o...  \n",
       "503899       i went to umeda station for dating yesterday  \n",
       "503900  she said she want to change the meeting time t...  \n",
       "\n",
       "[503901 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## LOADING THE PROCESSED DATASET  \n",
    "\n",
    "df= pd.read_csv(\"DATA/processed_data_lang8.csv\")\n",
    "df.columns = [\"enc_input\",\"dec_input\"] \n",
    "df[\"dec_output\"] = df.dec_input\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71e080e6-0bf4-4066-84c4-0b7a4ca95880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enc_input</th>\n",
       "      <th>dec_input</th>\n",
       "      <th>dec_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>and he took in my favorite subject like soccer</td>\n",
       "      <td>&lt;start&gt; and he took in my favorite subjects li...</td>\n",
       "      <td>and he took in my favorite subjects like socce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>actually who let me know about lang  8 was him</td>\n",
       "      <td>&lt;start&gt; actually he was the one who let me kno...</td>\n",
       "      <td>actually he was the one who let me know about ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>his kanji is ability is much better than me</td>\n",
       "      <td>&lt;start&gt; his kanji ability is much better than ...</td>\n",
       "      <td>his kanji ability is much better than mine &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>we have known each other for only half a year ...</td>\n",
       "      <td>&lt;start&gt; we have known each other for only half...</td>\n",
       "      <td>we have known each other for only half a year ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i heard a sentence last night when i watched tv</td>\n",
       "      <td>&lt;start&gt; i heard a sentence last night when i w...</td>\n",
       "      <td>i heard a sentence last night when i was watch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503896</th>\n",
       "      <td>i like thailand language because that pronounc...</td>\n",
       "      <td>&lt;start&gt; i like thai because the pronunciation ...</td>\n",
       "      <td>i like thai because the pronunciation sounds c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503897</th>\n",
       "      <td>i ate kaomangai  rise with boild chikin  tomya...</td>\n",
       "      <td>&lt;start&gt; i ate kaomangai  rice with boiled chic...</td>\n",
       "      <td>i ate kaomangai  rice with boiled chickin  tom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503898</th>\n",
       "      <td>i think it is important thing to become to lik...</td>\n",
       "      <td>&lt;start&gt; i think it is important to like corian...</td>\n",
       "      <td>i think it is important to like coriander in o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503899</th>\n",
       "      <td>yesterday i went to umeda station to date</td>\n",
       "      <td>&lt;start&gt; i went to umeda station for dating yes...</td>\n",
       "      <td>i went to umeda station for dating yesterday &lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503900</th>\n",
       "      <td>it said she want to make the meeting time at e...</td>\n",
       "      <td>&lt;start&gt; she said she want to change the meetin...</td>\n",
       "      <td>she said she want to change the meeting time t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>503901 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                enc_input  \\\n",
       "0          and he took in my favorite subject like soccer   \n",
       "1          actually who let me know about lang  8 was him   \n",
       "2             his kanji is ability is much better than me   \n",
       "3       we have known each other for only half a year ...   \n",
       "4         i heard a sentence last night when i watched tv   \n",
       "...                                                   ...   \n",
       "503896  i like thailand language because that pronounc...   \n",
       "503897  i ate kaomangai  rise with boild chikin  tomya...   \n",
       "503898  i think it is important thing to become to lik...   \n",
       "503899          yesterday i went to umeda station to date   \n",
       "503900  it said she want to make the meeting time at e...   \n",
       "\n",
       "                                                dec_input  \\\n",
       "0       <start> and he took in my favorite subjects li...   \n",
       "1       <start> actually he was the one who let me kno...   \n",
       "2       <start> his kanji ability is much better than ...   \n",
       "3       <start> we have known each other for only half...   \n",
       "4       <start> i heard a sentence last night when i w...   \n",
       "...                                                   ...   \n",
       "503896  <start> i like thai because the pronunciation ...   \n",
       "503897  <start> i ate kaomangai  rice with boiled chic...   \n",
       "503898  <start> i think it is important to like corian...   \n",
       "503899  <start> i went to umeda station for dating yes...   \n",
       "503900  <start> she said she want to change the meetin...   \n",
       "\n",
       "                                               dec_output  \n",
       "0       and he took in my favorite subjects like socce...  \n",
       "1       actually he was the one who let me know about ...  \n",
       "2        his kanji ability is much better than mine <end>  \n",
       "3       we have known each other for only half a year ...  \n",
       "4       i heard a sentence last night when i was watch...  \n",
       "...                                                   ...  \n",
       "503896  i like thai because the pronunciation sounds c...  \n",
       "503897  i ate kaomangai  rice with boiled chickin  tom...  \n",
       "503898  i think it is important to like coriander in o...  \n",
       "503899  i went to umeda station for dating yesterday <...  \n",
       "503900  she said she want to change the meeting time t...  \n",
       "\n",
       "[503901 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding start and end token\n",
    "## THE INPUTS TO THE DECODER REQUIRES SPECIAL TOKENS FOR THE START AND THE END SO WE ARE GOING TO USE \n",
    "## <start> AS BEGINING TOKEN\n",
    "## <end>  AS END TOKEN\n",
    "\n",
    "df[\"dec_input\"]= \"<start> \" + df[\"dec_input\"]\n",
    "df[\"dec_output\"] =  df[\"dec_output\"] + \" <end>\" \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dbbdfd9-97fb-4f03-bc7e-daab9bdc53c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(503901, 3)\n",
      "(100780, 3)\n"
     ]
    }
   ],
   "source": [
    "# Splitting And Sampling around 100k datapoints\n",
    "#THE TOTAL DATASET HAS 500K DATAPOINTS WHICH WILL TAKE MUCH HIGHER TRAINING TIME. THEREFORE I AM SAMPLING ONE-FIFTH OF THE TOTAL DATASET\n",
    "\n",
    "#df_sampled = pd.concat((df[df.enc_input].sample(frac= 0.2,random_state=1)))\n",
    "df_sampled = df.sample(frac = 0.2)\n",
    "print(df.shape)\n",
    "print(df_sampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d8bc948-cc71-4302-b457-c15aaef88fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ONCE THE DATA IS SAMPLED WE ARE SPLITTIND THE DATA IN TO TRAIN AND TEST\n",
    "\n",
    "df_train ,df_val = train_test_split(df_sampled,test_size=0.2,random_state = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a118dea5-c7bb-467b-9384-e18296642ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enc_input</th>\n",
       "      <th>dec_input</th>\n",
       "      <th>dec_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>230600</th>\n",
       "      <td>so i need to have a practice in writing englis...</td>\n",
       "      <td>&lt;start&gt; so i need to at least practice writing...</td>\n",
       "      <td>so i need to at least practice writing in engl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59864</th>\n",
       "      <td>my colleague joined in j  parc in order to use...</td>\n",
       "      <td>&lt;start&gt; my colleague joinedj  parc in order to...</td>\n",
       "      <td>my colleague joinedj  parc in order to use the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472638</th>\n",
       "      <td>when i asked my american friends what i should...</td>\n",
       "      <td>&lt;start&gt; when i asked my american friends what ...</td>\n",
       "      <td>when i asked my american friends what i should...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391091</th>\n",
       "      <td>the main character is so beautiful like a real...</td>\n",
       "      <td>&lt;start&gt; the main character is so beautiful lik...</td>\n",
       "      <td>the main character is so beautiful like a real...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>you know the earthquake was too bad for my family</td>\n",
       "      <td>&lt;start&gt; you know the earthquake affected my fa...</td>\n",
       "      <td>you know the earthquake affected my family ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379723</th>\n",
       "      <td>if i dropped out to learn english again i coul...</td>\n",
       "      <td>&lt;start&gt; if i had quit my english studies again...</td>\n",
       "      <td>if i had quit my english studies again i could...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3980</th>\n",
       "      <td>my flight determined as previous attached file</td>\n",
       "      <td>&lt;start&gt; my flight is confirmed as per the atta...</td>\n",
       "      <td>my flight is confirmed as per the attached fil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197260</th>\n",
       "      <td>i like to watch tv programme  week of sports  ...</td>\n",
       "      <td>&lt;start&gt; i like to watch the tv programme  week...</td>\n",
       "      <td>i like to watch the tv programme  week of spor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318828</th>\n",
       "      <td>you can buy things or making a reservation for...</td>\n",
       "      <td>&lt;start&gt; you can buy things or make reservation...</td>\n",
       "      <td>you can buy things or make reservations at a r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59191</th>\n",
       "      <td>i decided to buy white colored wools</td>\n",
       "      <td>&lt;start&gt; i decided that the color  to use would...</td>\n",
       "      <td>i decided that the color  to use would be  whi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80624 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                enc_input  \\\n",
       "230600  so i need to have a practice in writing englis...   \n",
       "59864   my colleague joined in j  parc in order to use...   \n",
       "472638  when i asked my american friends what i should...   \n",
       "391091  the main character is so beautiful like a real...   \n",
       "550     you know the earthquake was too bad for my family   \n",
       "...                                                   ...   \n",
       "379723  if i dropped out to learn english again i coul...   \n",
       "3980       my flight determined as previous attached file   \n",
       "197260  i like to watch tv programme  week of sports  ...   \n",
       "318828  you can buy things or making a reservation for...   \n",
       "59191                i decided to buy white colored wools   \n",
       "\n",
       "                                                dec_input  \\\n",
       "230600  <start> so i need to at least practice writing...   \n",
       "59864   <start> my colleague joinedj  parc in order to...   \n",
       "472638  <start> when i asked my american friends what ...   \n",
       "391091  <start> the main character is so beautiful lik...   \n",
       "550     <start> you know the earthquake affected my fa...   \n",
       "...                                                   ...   \n",
       "379723  <start> if i had quit my english studies again...   \n",
       "3980    <start> my flight is confirmed as per the atta...   \n",
       "197260  <start> i like to watch the tv programme  week...   \n",
       "318828  <start> you can buy things or make reservation...   \n",
       "59191   <start> i decided that the color  to use would...   \n",
       "\n",
       "                                               dec_output  \n",
       "230600  so i need to at least practice writing in engl...  \n",
       "59864   my colleague joinedj  parc in order to use the...  \n",
       "472638  when i asked my american friends what i should...  \n",
       "391091  the main character is so beautiful like a real...  \n",
       "550     you know the earthquake affected my family ver...  \n",
       "...                                                   ...  \n",
       "379723  if i had quit my english studies again i could...  \n",
       "3980    my flight is confirmed as per the attached fil...  \n",
       "197260  i like to watch the tv programme  week of spor...  \n",
       "318828  you can buy things or make reservations at a r...  \n",
       "59191   i decided that the color  to use would be  whi...  \n",
       "\n",
       "[80624 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## IN THE COLUMN WHICH HAS DECODER INPUTS ADDING \"<end>\" TOKEN TO BE LEARNED BY THE TOKENIZER\n",
    "\n",
    "df_train[\"dec_input\"].iloc[0]  = df_train.iloc[0][\"dec_input\"] + \" <end>\"\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a04ea613-5671-42ee-9ab8-805a563390b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enc_input</th>\n",
       "      <th>dec_input</th>\n",
       "      <th>dec_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>293263</th>\n",
       "      <td>by 17  30 the departure time for the party</td>\n",
       "      <td>&lt;start&gt; 17  30 is the departure time for the p...</td>\n",
       "      <td>17  30 is the departure time for the party &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354268</th>\n",
       "      <td>now i want to form new band</td>\n",
       "      <td>&lt;start&gt; now i want to form a new band</td>\n",
       "      <td>now i want to form a new band &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382132</th>\n",
       "      <td>the company shows their confidence that people...</td>\n",
       "      <td>&lt;start&gt; the company is confident that people w...</td>\n",
       "      <td>the company is confident that people will beco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226942</th>\n",
       "      <td>i am thinking what i am going to create</td>\n",
       "      <td>&lt;start&gt; i am thinking of what to create</td>\n",
       "      <td>i am thinking of what to create &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230979</th>\n",
       "      <td>nowdays i have been even putting on long johns</td>\n",
       "      <td>&lt;start&gt; lately i have even been putting on lon...</td>\n",
       "      <td>lately i have even been putting on long johns ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>the examination fee cost  150</td>\n",
       "      <td>&lt;start&gt; the examination fee is  150</td>\n",
       "      <td>the examination fee is  150 &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477273</th>\n",
       "      <td>especially daily l watch so many movie</td>\n",
       "      <td>&lt;start&gt; iwatch so many movies daily</td>\n",
       "      <td>iwatch so many movies daily &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312392</th>\n",
       "      <td>i carried them within my bag and walked about ...</td>\n",
       "      <td>&lt;start&gt; i carried them in my bag and walked ab...</td>\n",
       "      <td>i carried them in my bag and walked about 30 m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138563</th>\n",
       "      <td>but i do not use its well</td>\n",
       "      <td>&lt;start&gt; but i do not use them well</td>\n",
       "      <td>but i do not use them well &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134060</th>\n",
       "      <td>this film let me think a lot</td>\n",
       "      <td>&lt;start&gt; this film made me think a lot</td>\n",
       "      <td>this film made me think a lot &lt;end&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20156 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                enc_input  \\\n",
       "293263         by 17  30 the departure time for the party   \n",
       "354268                        now i want to form new band   \n",
       "382132  the company shows their confidence that people...   \n",
       "226942            i am thinking what i am going to create   \n",
       "230979     nowdays i have been even putting on long johns   \n",
       "...                                                   ...   \n",
       "525                         the examination fee cost  150   \n",
       "477273             especially daily l watch so many movie   \n",
       "312392  i carried them within my bag and walked about ...   \n",
       "138563                          but i do not use its well   \n",
       "134060                       this film let me think a lot   \n",
       "\n",
       "                                                dec_input  \\\n",
       "293263  <start> 17  30 is the departure time for the p...   \n",
       "354268              <start> now i want to form a new band   \n",
       "382132  <start> the company is confident that people w...   \n",
       "226942            <start> i am thinking of what to create   \n",
       "230979  <start> lately i have even been putting on lon...   \n",
       "...                                                   ...   \n",
       "525                   <start> the examination fee is  150   \n",
       "477273                <start> iwatch so many movies daily   \n",
       "312392  <start> i carried them in my bag and walked ab...   \n",
       "138563                 <start> but i do not use them well   \n",
       "134060              <start> this film made me think a lot   \n",
       "\n",
       "                                               dec_output  \n",
       "293263   17  30 is the departure time for the party <end>  \n",
       "354268                now i want to form a new band <end>  \n",
       "382132  the company is confident that people will beco...  \n",
       "226942              i am thinking of what to create <end>  \n",
       "230979  lately i have even been putting on long johns ...  \n",
       "...                                                   ...  \n",
       "525                     the examination fee is  150 <end>  \n",
       "477273                  iwatch so many movies daily <end>  \n",
       "312392  i carried them in my bag and walked about 30 m...  \n",
       "138563                   but i do not use them well <end>  \n",
       "134060                this film made me think a lot <end>  \n",
       "\n",
       "[20156 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## VALIDATION DATA\n",
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12fb571f-2a53-45f9-9863-d5cca86bf074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enc_input</th>\n",
       "      <th>dec_input</th>\n",
       "      <th>dec_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>144491</th>\n",
       "      <td>to give one to me</td>\n",
       "      <td>&lt;start&gt; to give me one</td>\n",
       "      <td>to give me one &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455893</th>\n",
       "      <td>normally a couple of colleagues gather togethe...</td>\n",
       "      <td>&lt;start&gt; normally a couple of colleagues gather...</td>\n",
       "      <td>normally a couple of colleagues gather togethe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13942</th>\n",
       "      <td>after i came back home i drunk a cup of alcohol</td>\n",
       "      <td>&lt;start&gt; after i came back home i drank a cup o...</td>\n",
       "      <td>after i came back home i drank a cup of alcoho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128993</th>\n",
       "      <td>then she gave each one of them a blue ribbon w...</td>\n",
       "      <td>&lt;start&gt; then she gave each one of them a blue ...</td>\n",
       "      <td>then she gave each one of them a blue ribbon w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402709</th>\n",
       "      <td>now i forget these things and i enjoy studying...</td>\n",
       "      <td>&lt;start&gt; now i can forget these things and i en...</td>\n",
       "      <td>now i can forget these things and i enjoy stud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352451</th>\n",
       "      <td>even though i have not written for while thank...</td>\n",
       "      <td>&lt;start&gt; even though i have not written for whi...</td>\n",
       "      <td>even though i have not written for while thank...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191225</th>\n",
       "      <td>today he picked me up to his selected restaurant</td>\n",
       "      <td>&lt;start&gt; today he picked me up at the restauran...</td>\n",
       "      <td>today he picked me up at the restaurant that h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179487</th>\n",
       "      <td>all of my friends are thinking of which univer...</td>\n",
       "      <td>&lt;start&gt; all of my friends are thinking about w...</td>\n",
       "      <td>all of my friends are thinking about which uni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38491</th>\n",
       "      <td>i dare not to mention when exactly they start ...</td>\n",
       "      <td>&lt;start&gt; i do not dare to mention when exactly ...</td>\n",
       "      <td>i do not dare to mention when exactly they sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388440</th>\n",
       "      <td>does anybody tried it before</td>\n",
       "      <td>&lt;start&gt; has anybody tried it before</td>\n",
       "      <td>has anybody tried it before &lt;end&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                enc_input  \\\n",
       "144491                                  to give one to me   \n",
       "455893  normally a couple of colleagues gather togethe...   \n",
       "13942     after i came back home i drunk a cup of alcohol   \n",
       "128993  then she gave each one of them a blue ribbon w...   \n",
       "402709  now i forget these things and i enjoy studying...   \n",
       "...                                                   ...   \n",
       "352451  even though i have not written for while thank...   \n",
       "191225   today he picked me up to his selected restaurant   \n",
       "179487  all of my friends are thinking of which univer...   \n",
       "38491   i dare not to mention when exactly they start ...   \n",
       "388440                       does anybody tried it before   \n",
       "\n",
       "                                                dec_input  \\\n",
       "144491                             <start> to give me one   \n",
       "455893  <start> normally a couple of colleagues gather...   \n",
       "13942   <start> after i came back home i drank a cup o...   \n",
       "128993  <start> then she gave each one of them a blue ...   \n",
       "402709  <start> now i can forget these things and i en...   \n",
       "...                                                   ...   \n",
       "352451  <start> even though i have not written for whi...   \n",
       "191225  <start> today he picked me up at the restauran...   \n",
       "179487  <start> all of my friends are thinking about w...   \n",
       "38491   <start> i do not dare to mention when exactly ...   \n",
       "388440                <start> has anybody tried it before   \n",
       "\n",
       "                                               dec_output  \n",
       "144491                               to give me one <end>  \n",
       "455893  normally a couple of colleagues gather togethe...  \n",
       "13942   after i came back home i drank a cup of alcoho...  \n",
       "128993  then she gave each one of them a blue ribbon w...  \n",
       "402709  now i can forget these things and i enjoy stud...  \n",
       "...                                                   ...  \n",
       "352451  even though i have not written for while thank...  \n",
       "191225  today he picked me up at the restaurant that h...  \n",
       "179487  all of my friends are thinking about which uni...  \n",
       "38491   i do not dare to mention when exactly they sta...  \n",
       "388440                  has anybody tried it before <end>  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## HERE I AM SAMPLING 1000 POINTS FROM THE DATAFRAME AS TEST DATA WHICH ARE NOT PRESEENT IN THE TRAIN AND VALIDAION DATA\n",
    "np.random.seed(5) \n",
    "df_test = df.loc[np.random.choice(np.array([x for x in df.index.values if x not in df_sampled.index.values]),1000,replace= False,)]\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ea083bb-9189-4dde-891b-167fbc2cb76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4febba4d-091d-4309-a280-790f319efd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TOKENIZER FOR ENCODER INPUT\n",
    "tk_inp = Tokenizer()\n",
    "tk_inp.fit_on_texts(df_train.enc_input.apply(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "242b37cb-d354-4ffa-8ff7-8dfb6144e5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOKENIZER FOR DECODER INPUT\n",
    "tk_out = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n' )\n",
    "tk_out.fit_on_texts(df_train.dec_input.apply(str))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5d99c6e8-cf21-4597-86dc-abe6023320ac",
   "metadata": {},
   "source": [
    "Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b595141-a5c3-47b8-a84d-d7d64c708717",
   "metadata": {},
   "outputs": [],
   "source": [
    "## THIS CLASS CONVERTS TEXT DATA TO INTEGER SEQUENCES AND RETURNS THE PADDED SEQUENCES\n",
    "\n",
    "class Dataset :\n",
    "    def __init__(self, data , tk_inp ,tk_out, max_len):\n",
    "        ## SETTING THE REQUIRED ATTRIBUTES\n",
    "        self.encoder_inp = data[\"enc_input\"].apply(str).values\n",
    "        self.decoder_inp = data[\"dec_input\"].apply(str).values\n",
    "        self.decoder_out = data[\"dec_output\"].apply(str).values\n",
    "        self.tk_inp = tk_inp\n",
    "        self.tk_out = tk_out\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __getitem__(self,i):\n",
    "        # INPUT SEQUENCES\n",
    "        self.encoder_seq = self.tk_inp.texts_to_sequences([self.encoder_inp[i]])\n",
    "        # DECODER INPUT SEQUENCES \n",
    "        self.decoder_inp_seq = self.tk_out.texts_to_sequences([self.decoder_inp[i]])\n",
    "        # DECODER INPUT SEQUENCES\n",
    "        self.decoder_out_seq = self.tk_out.texts_to_sequences([self.decoder_out[i]])\n",
    "        \n",
    "        # PADDING THE ENCODER INPUT SEQUENCES\n",
    "        self.encoder_seq = pad_sequences(self.encoder_seq, padding=\"post\",maxlen = self.max_len)\n",
    "        # PADDING THE DECODER INPUT SEQUENCES\n",
    "        self.decoder_inp_seq = pad_sequences(self.decoder_inp_seq, padding=\"post\",maxlen = self.max_len)\n",
    "        # PADDING DECODER OUTPUT SEQUENCES\n",
    "        self.decoder_out_seq = pad_sequences(self.decoder_out_seq ,padding=\"post\", maxlen = self.max_len)\n",
    "\n",
    "        ##  RETURNING THE ENCODER INPUT , DECODER INPUT , AND DECODER OUTPUT\n",
    "        return self.encoder_seq ,  self.decoder_inp_seq,  self.decoder_out_seq\n",
    "    \n",
    "    def __len__(self):\n",
    "        # RETURN THE LEN OF INPUT ENDODER\n",
    "        return len(self.encoder_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2138832a-05b4-43aa-ac36-29b2fbde06c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## THIS CLASS CONVERTES THE DATASET INTO THE REQUIRED BATCH SIZE\n",
    "\n",
    "class Dataloader(tf.keras.utils.Sequence):\n",
    "    def __init__(self,batch_size,dataset):\n",
    "        # INTIALIZING THE REQUIRED VARIABLES \n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.totl_points = self.dataset.encoder_inp.shape[0]\n",
    "        \n",
    "    def __getitem__(self,i):\n",
    "        # STATING THE START AND STOP VATIABLE CONTAINGING INDEX VALUES FOR EACH BATCH\n",
    "        start = i * self.batch_size\n",
    "        stop = (i+1)*self.batch_size\n",
    "        \n",
    "        # PLACEHOLDERS FOR BATCHED DATA\n",
    "        batch_enc =[]\n",
    "        batch_dec_input = []\n",
    "        batch_dec_out =[]\n",
    "\n",
    "        for j in range(start,stop): \n",
    "            \n",
    "            a,b,c = self.dataset[j] \n",
    "            batch_enc.append(a[0]) \n",
    "            batch_dec_input.append(b[0])\n",
    "            batch_dec_out.append(c[0]) \n",
    "        \n",
    "        # Conveting list to array   \n",
    "        batch_enc = (np.array(batch_enc)) \n",
    "        batch_dec_input = np.array(batch_dec_input)\n",
    "        batch_dec_out = np.array(batch_dec_out)\n",
    "        \n",
    "        ## RETURNING BATCHED DATA IN REQUIRED FORM\n",
    "        return [batch_enc , batch_dec_input],batch_dec_out\n",
    "    \n",
    "    def __len__(self):\n",
    "        # Returning the number of batches\n",
    "        return int(self.totl_points/self.batch_size)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "56d57354-58ac-4de3-a47c-f33e0d351cb7",
   "metadata": {},
   "source": [
    "NOTE: WE ARE TAKING THE MAXIMUM LENGHT EQUAL TO 35 WHICH IS 99 PERCENTILE OF THE WORD LENGTH DISTRUBUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2f03182-7513-4279-b2fa-d41d845fdc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FORMING OBJECTS OF DATASET AND DATALOADER FOR TRAIN DATASET\n",
    "train_dataset = Dataset(df_train,tk_inp,tk_out,35)\n",
    "train_dataloader = Dataloader( batch_size = 512, dataset=train_dataset)\n",
    "\n",
    "# FORMING OBJECTS OF DATASET AND DATALOADER FOR VALIDATION DATASET\n",
    "val_dataset = Dataset(df_val , tk_inp,tk_out,35)\n",
    "val_dataloader = Dataloader(batch_size=512 , dataset=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04bc61d5-434d-4093-ae21-620e8cb8a210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENCODER DECODER MODEL\n",
    "## LOADING THE TENSORFLOW LIBRARIES\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87782bbc-0634-4b93-adc8-b62616563113",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DEFINING THE ENCODER LAYER AS A FUNCTION\n",
    "\n",
    "def encoder(input_shape,vocab, emb_output, lstm_units, enc_input):\n",
    "    '''THIS FUNCTION TAKES IN THE SEQUENCES AND RETURNS THE ENCODER OUTPUT'''\n",
    "    ## FIRST LAYER : EMBEDDING LAYER\n",
    "    enc_emb = layers.Embedding(vocab, emb_output,mask_zero = True,input_length=input_shape)(enc_input)\n",
    "    ## SECOND LAYER : LSTM LAYER\n",
    "    enc_lstm , enc_state_h,enc_state_c = layers.LSTM(units= lstm_units,return_sequences=True,return_state=True)(enc_emb)\n",
    "    ## RETURNING THE LSTM OUTPUTS AND STATES\n",
    "    return enc_lstm , enc_state_h,enc_state_c\n",
    "\n",
    "\n",
    "## DEFINING THE DECODER LAYER AS A FUNCTION \n",
    "def decoder(input_shape,vocab, emb_output, lstm_units,enc_states, dec_input):\n",
    "  ## FIRST LAYER : EMBEDDING LAYER\n",
    "  dec_emb = layers.Embedding(vocab, emb_output , mask_zero = True,input_length=input_shape)(dec_input)\n",
    "  ## SECONG LAYER : LSTM LAYER\n",
    "  dec_lstm, dec_state_h,dec_state_c = layers.LSTM(units=lstm_units,return_sequences=True,return_state=True)(dec_emb,initial_state= enc_states)\n",
    "  ## RETURNING THE LSTM OUTPUTS AND STATES\n",
    "  return dec_lstm, dec_state_h,dec_state_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8bfbc8f9-f05b-49fe-b11e-3dccb9173ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-17 19:22:37.186700: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-10-17 19:22:37.186743: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-10-17 19:22:37.187130: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "## DEFINING THE MODEL ARCHITECTURE\n",
    "\n",
    "# INPUT LAYER\n",
    "enc_input = layers.Input(shape=(35))\n",
    "# ENCODER DEFINED FORM FUNCTON ABOVE\n",
    "enc_lstm , enc_state_h,enc_state_c = encoder(35,len(tk_inp.word_index)+1 , 300 ,256, enc_input )\n",
    "\n",
    "\n",
    "# DECODER INPUT LAYER\n",
    "dec_input = layers.Input(shape = (35))\n",
    "# DECODER DEFINEA FROM ABOVE FUNCTION\n",
    "dec_lstm , dec_state_h,dec_state_c = decoder(35,len(tk_out.word_index)+1 , 300 , 256 , [enc_state_h,enc_state_c],dec_input)\n",
    "# DENCSE LAYER CONNECTOD TO DECODER OUTPUT\n",
    "dense = layers.Dense(len(tk_out.word_index)+1,activation=\"softmax\")(dec_lstm)\n",
    "\n",
    "# MODEL DEFINING\n",
    "model  = Model(inputs=[enc_input,dec_input],outputs=dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48b2f95a-a722-445f-88a1-08fdc71153e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 35)]         0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 35)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 35, 300)      9455100     ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 35, 300)      7971600     ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 35, 256),    570368      ['embedding[0][0]']              \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, 35, 256),    570368      ['embedding_1[0][0]',            \n",
      "                                 (None, 256),                     'lstm[0][1]',                   \n",
      "                                 (None, 256)]                     'lstm[0][2]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 35, 26572)    6829004     ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 25,396,440\n",
      "Trainable params: 25,396,440\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# MODEL SUMMARY\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d14fedf-7d65-4c41-8ae4-bfa38d2670b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DEFINING THE CALLBACKS\n",
    "callback =[ tf.keras.callbacks.ModelCheckpoint( \"/model_save/word_trainable_embedding_best.h5\",save_best_only=True,mode=\"min\" ,save_weights_only=True),\n",
    "           tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=5,verbose=1,min_delta=0.0001)\n",
    "]\n",
    "\n",
    "## STORING THE NUMBER OF STEPS IN ONE EPOCH FOR TRAIN AND VALIDATION DATASET\n",
    "train_steps = train_dataloader.__len__()\n",
    "val_steps  = val_dataloader.__len__()\n",
    "\n",
    "# COMPILING THE MODEL\n",
    "model.compile(optimizer=\"adam\",loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f5ecc41-d661-402f-abac-85f8f5e6a6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1fa13a13-6929-4a18-a851-6db2bc6ef61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# The GPU id to use, \"0\" to  \"7\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,3,4,5,7\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0e0ba1-dbd7-4acd-83db-dffaac650672",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e8adea63-b064-4f70-bcb9-6bf4c3f682a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark_Wordlevel.ipynb  EDA.ipynb                             \u001b[0m\u001b[01;34mmodel_save\u001b[0m/\n",
      "\u001b[01;34mDATA\u001b[0m/                      eng_word_trainable_embedding_besh.h5  resouces.txt\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8c213e02-cd4d-49e8-b8c1-34979c11bfda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "157/157 [==============================] - 260s 2s/step - loss: 1.6543 - val_loss: 1.5936\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 250s 2s/step - loss: 1.5365 - val_loss: 1.5031\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 250s 2s/step - loss: 1.4311 - val_loss: 1.4304\n",
      "Epoch 4/50\n",
      "157/157 [==============================] - 250s 2s/step - loss: 1.3408 - val_loss: 1.3729\n",
      "Epoch 5/50\n",
      "157/157 [==============================] - 250s 2s/step - loss: 1.2603 - val_loss: 1.3260\n",
      "Epoch 6/50\n",
      "157/157 [==============================] - 250s 2s/step - loss: 1.1857 - val_loss: 1.2840\n",
      "Epoch 7/50\n",
      "157/157 [==============================] - 250s 2s/step - loss: 1.1183 - val_loss: 1.2530\n",
      "Epoch 8/50\n",
      "157/157 [==============================] - 249s 2s/step - loss: 1.0566 - val_loss: 1.2280\n",
      "Epoch 9/50\n",
      "157/157 [==============================] - 249s 2s/step - loss: 1.0001 - val_loss: 1.2075\n",
      "Epoch 10/50\n",
      "157/157 [==============================] - 249s 2s/step - loss: 0.9465 - val_loss: 1.1905\n",
      "Epoch 11/50\n",
      "157/157 [==============================] - 248s 2s/step - loss: 0.8964 - val_loss: 1.1770\n",
      "Epoch 12/50\n",
      "157/157 [==============================] - 249s 2s/step - loss: 0.8501 - val_loss: 1.1664\n",
      "Epoch 13/50\n",
      "157/157 [==============================] - 250s 2s/step - loss: 0.8060 - val_loss: 1.1589\n",
      "Epoch 14/50\n",
      "157/157 [==============================] - 252s 2s/step - loss: 0.7653 - val_loss: 1.1520\n",
      "Epoch 15/50\n",
      "157/157 [==============================] - 252s 2s/step - loss: 0.7261 - val_loss: 1.1502\n",
      "Epoch 16/50\n",
      "157/157 [==============================] - 251s 2s/step - loss: 0.6901 - val_loss: 1.1478\n",
      "Epoch 17/50\n",
      "157/157 [==============================] - 250s 2s/step - loss: 0.6563 - val_loss: 1.1464\n",
      "Epoch 18/50\n",
      "157/157 [==============================] - 250s 2s/step - loss: 0.6247 - val_loss: 1.1513\n",
      "Epoch 19/50\n",
      "157/157 [==============================] - 251s 2s/step - loss: 0.5944 - val_loss: 1.1494\n",
      "Epoch 20/50\n",
      "157/157 [==============================] - 257s 2s/step - loss: 0.5667 - val_loss: 1.1529\n",
      "Epoch 21/50\n",
      "157/157 [==============================] - 263s 2s/step - loss: 0.5409 - val_loss: 1.1573\n",
      "Epoch 22/50\n",
      "157/157 [==============================] - 291s 2s/step - loss: 0.5163 - val_loss: 1.1652\n",
      "Epoch 00022: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8a643b78d0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## FITTING THE MODEL\n",
    "model.fit(train_dataloader,steps_per_epoch=train_steps,epochs=50,validation_data = val_dataloader,validation_steps =val_steps,callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bdfe52-e2f4-438c-b347-ec7b65736004",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db51deac-b147-41b4-8099-fca67ff78973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: pydotplus 2.0.2\n",
      "Uninstalling pydotplus-2.0.2:\n",
      "  Would remove:\n",
      "    /DATA/gupta92/.local/lib/python3.7/site-packages/pydotplus-2.0.2.dist-info/*\n",
      "    /DATA/gupta92/.local/lib/python3.7/site-packages/pydotplus/*\n",
      "Proceed (Y/n)? ^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip uninstall pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64da6e73-09ff-4c2e-80ed-5ced1428e78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pydot\n",
    "!pip install pydotplus\n",
    "!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbd23b2-1d9f-441c-8c50-92a1fa113ae8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3efd7de4-605c-44e7-87e7-484905510a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model,show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e074cab9-d446-4baa-b09c-e5065dff99ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOADING THE WEIGHTS FOR BEST MODEL\n",
    "#model.load_weights(\"model_save/word_trainable_embedding/besh.h5\")\n",
    "model.built = True\n",
    "model.load_weights(\"eng_word_trainable_embedding_besh.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "25cda283-0a02-43cb-b887-02882afa5f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "## THIS FUNCTION IS USED IN THE INFERENCE TIME TO PREDICT THE RESULTS GIVEN THE INPUT TEXT\n",
    "\n",
    "def predict(inp , model):\n",
    "    ##  TAKES INPUT AS TEXT AND THE MODEL\n",
    "\n",
    "    # CONVERT TEXT INPUT TO SEQUENCES \n",
    "    seq = tk_inp.texts_to_sequences([inp])\n",
    "    # PADDING THE SEQUENCE\n",
    "    seq = pad_sequences(seq,maxlen = 35,padding=\"post\")\n",
    "    ## INITIAL STATES FOR ENCODER\n",
    "    state = [tf.zeros(shape=(1,256)),tf.zeros(shape= (1,256))]\n",
    "\n",
    "    # SEQUENCE TO EMBEDDING\n",
    "    enc_emb  = model.layers[2](seq)\n",
    "    # PASSING EMBBEDDED SEQUENCES TO LSTM LAYER\n",
    "    enc_output,state_h,state_c= model.layers[4](enc_emb,state)\n",
    "\n",
    "    # PLACE HOLDER FOR PREDECTED WORDS\n",
    "    pred = []\n",
    "    # PLACE HOLDER FOR STATES \n",
    "    input_state = [state_h,state_c]\n",
    "    # CURRENT VECTOR TO BE PASSED TO DECODER \n",
    "    current_vec = tf.ones((1,1))\n",
    "    \n",
    "    for i in range(35): # FOR i UP TO 35 (MAX LENGTH)\n",
    "        ## CONVERT THE CURRENT VECTOR SEQUENCE WORD TO EMBEDDINGS\n",
    "        dec_emb  = model.layers[3](current_vec)\n",
    "        ## PASSING EMBEDDED VECTOR TO DECODER LSTM LAYER\n",
    "        dec_output,dec_state_h,dec_state_c = model.layers[5](dec_emb , input_state)\n",
    "        # PASSING DECODER OUTPUT TO DENSE LAYER\n",
    "        dense = model.layers[6](dec_output)\n",
    "\n",
    "        # SELECTING INDEX OF MAXIMUM DENSE OUTPUT AS CURRENT VECTOR\n",
    "        current_vec = np.argmax(dense ,axis = -1)\n",
    "        # UPDATING THE INPUT STATES\n",
    "        input_state = [dec_state_h,dec_state_c]\n",
    "\n",
    "        # APPENDING THE ACTUAL TEXT TO \"pred\" VARIABLE\n",
    "        pred.append(tk_out.index_word[current_vec[0][0]])\n",
    "        ## IF THE CURRENT VECTOR IS \"<end>\" BREAK THE LOOP\n",
    "        if tk_out.index_word[current_vec[0][0]]==\"<end>\":\n",
    "            break\n",
    "    ## RETURN THE JOINED STRING IN LIST \"pred\"\n",
    "    return \" \".join(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "619d8a7f-3c98-49c8-924b-f085dc4fab75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT SENTENCE ===>  today is the first day in a week\n",
      "PREDICTED SENTENCE ===>  today is the first day a week <end>\n",
      "ACTUAL SENTENCE ===>  today is the first day of the week <end>\n"
     ]
    }
   ],
   "source": [
    "# Prediction on Test Set\n",
    "print(\"INPUT SENTENCE ===> \",df_test.enc_input.values[19])\n",
    "print(\"PREDICTED SENTENCE ===> \",predict(df_test.enc_input.values[19],model))\n",
    "print(\"ACTUAL SENTENCE ===> \",df_test.dec_output.values[19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3c37db6e-046c-46e9-9a88-80924c8fd3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT SENTENCE ===>  hello it is the first time for me to write an english article on this site\n",
      "PREDICTED SENTENCE ===>  hello it is the first time i have written this website for english <end>\n",
      "ACTUAL SENTENCE ===>  hello it is the first time i have written an english article on this site <end>\n"
     ]
    }
   ],
   "source": [
    "print(\"INPUT SENTENCE ===> \",df_test.enc_input.values[50])\n",
    "print(\"PREDICTED SENTENCE ===> \",predict(df_test.enc_input.values[50],model))\n",
    "print(\"ACTUAL SENTENCE ===> \",df_test.dec_output.values[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7888c001-2206-4e3b-9bd2-7607b48fbefa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%time` not found.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Inference Time\n",
    "predict(df_test.enc_input.values[50],model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "20160977-9bd7-4a81-80ea-d3208c703076",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BELU SCore\n",
    "import nltk.translate.bleu_score as bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8e850c5b-c966-4bef-aae9-36f48e7fef59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2000it [06:19,  5.27it/s]\n"
     ]
    }
   ],
   "source": [
    "# VALIDATION BELU SCORE\n",
    "BLEU_val_emb = []\n",
    "test_data = df_val.loc[np.random.choice(df_val.index,size = 2000)]\n",
    "for ind,i in tqdm(test_data.iterrows(),position=0):\n",
    "    try:\n",
    "        pred = predict(str(i.enc_input),model).split()\n",
    "        act = [str(i.dec_output).split()]\n",
    "        b =bleu.sentence_bleu(act,pred)\n",
    "        BLEU_val_emb.append(b)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "448bb5d0-6243-4efc-9b82-de4464a2e475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BELU Score =  0.1294694307316595\n"
     ]
    }
   ],
   "source": [
    "print(\"BELU Score = \",np.mean(BLEU_val_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53393657-2f77-49f4-842a-300da1afc188",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8019it [21:21,  6.00it/s]"
     ]
    }
   ],
   "source": [
    "# VALIDATION BELU SCORE\n",
    "BLEU_val_emb = []\n",
    "test_data = df_val\n",
    "for ind,i in tqdm(test_data.iterrows(),position=0):\n",
    "    try:\n",
    "        pred = predict(str(i.enc_input),model).split()\n",
    "        act = [str(i.dec_output).split()]\n",
    "        b =bleu.sentence_bleu(act,pred)\n",
    "        BLEU_val_emb.append(b)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be688094-d1a6-4b65-aa8f-28303efed57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"BELU Score = \",np.mean(BLEU_val_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ff82f0-a117-4600-81e9-345368a888a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
